{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RH1ibVhPsryG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basketball Free-throw form correction using YOLOV8 and LSTM"
      ],
      "metadata": {
        "id": "jwP8e3R7JVPw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Approach:\n",
        "\n",
        "\n",
        "1.   Use YOLOV8 Pose model to extract the XY coordinates of different joints\n",
        "2.   Calculate angles the arm, legs and hip subtend with the ground\n",
        "3.   Train LSTM model with angles different bones subtend with the ground per each frame\n",
        "4.   Use a new video to detect faults in the shooting form\n",
        "\n"
      ],
      "metadata": {
        "id": "CbEWBcjtJowu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Install ultralytics (YOLO V8)"
      ],
      "metadata": {
        "id": "vJwvfvCqKaI2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRClE2baVA3L",
        "outputId": "e5b0af8b-31f2-4337-e31c-8722af2a2f42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.0.231-py3-none-any.whl (663 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.2/663.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.16.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Collecting thop>=0.1.1 (from ultralytics)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2023.11.17)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: thop, ultralytics\n",
            "Successfully installed thop-0.1.1.post2209072238 ultralytics-8.0.231\n"
          ]
        }
      ],
      "source": [
        "! pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import torch\n",
        "import time\n",
        "import imageio\n",
        "from ultralytics import YOLO\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#add the DetectKeypoint .py file in cwd\n",
        "from detection_keypoint import DetectKeypoint"
      ],
      "metadata": {
        "id": "t1p75aVwhGFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mount the google drive"
      ],
      "metadata": {
        "id": "aGZ1w-aUKy0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q21Ymn8YV5VJ",
        "outputId": "d2a98b9b-c850-42e3-8d6a-679fc682411c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create a list of all the videos to be extracted"
      ],
      "metadata": {
        "id": "9ZyFFjZXK61N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "make_temp=['ankur-make-1','ankur-make-2','ankur-make-3','ankur-make-4','ankur-make-5','ankur-make-6','ankur-make-7','ankur-make-8','mahesh_make1','mahesh_make2','mahesh_make3','mahesh_make6','mahesh_make8','mahesh_make9','mahesh_make10','mahesh_make12','mahesh_make13','mahesh_make14','mahesh_make15','mahesh_make16','mahesh_make17','mahesh_make18','mahesh_make19','mahesh_make20','mahesh_make21','mahesh_make22','mahesh_make23','mahesh_make24','mahesh_make25']\n",
        "video_list_make=[]\n",
        "for i in make_temp:\n",
        "  video_list_make.append(i+'.mp4')\n",
        "video_list_make\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxmsfXOLaiWE",
        "outputId": "6778ee5e-2762-4b59-a29b-03d21cfb02a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ankur-make-1.mp4',\n",
              " 'ankur-make-2.mp4',\n",
              " 'ankur-make-3.mp4',\n",
              " 'ankur-make-4.mp4',\n",
              " 'ankur-make-5.mp4',\n",
              " 'ankur-make-6.mp4',\n",
              " 'ankur-make-7.mp4',\n",
              " 'ankur-make-8.mp4',\n",
              " 'mahesh_make1.mp4',\n",
              " 'mahesh_make2.mp4',\n",
              " 'mahesh_make3.mp4',\n",
              " 'mahesh_make6.mp4',\n",
              " 'mahesh_make8.mp4',\n",
              " 'mahesh_make9.mp4',\n",
              " 'mahesh_make10.mp4',\n",
              " 'mahesh_make12.mp4',\n",
              " 'mahesh_make13.mp4',\n",
              " 'mahesh_make14.mp4',\n",
              " 'mahesh_make15.mp4',\n",
              " 'mahesh_make16.mp4',\n",
              " 'mahesh_make17.mp4',\n",
              " 'mahesh_make18.mp4',\n",
              " 'mahesh_make19.mp4',\n",
              " 'mahesh_make20.mp4',\n",
              " 'mahesh_make21.mp4',\n",
              " 'mahesh_make22.mp4',\n",
              " 'mahesh_make23.mp4',\n",
              " 'mahesh_make24.mp4',\n",
              " 'mahesh_make25.mp4']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_list_miss=[str(i)+'.mp4' for i in range(1,24)]\n",
        "video_list_miss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AICa8Comaih6",
        "outputId": "0dc36c1c-f27f-4d46-e3e8-c12284cfb5bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1.mp4',\n",
              " '2.mp4',\n",
              " '3.mp4',\n",
              " '4.mp4',\n",
              " '5.mp4',\n",
              " '6.mp4',\n",
              " '7.mp4',\n",
              " '8.mp4',\n",
              " '9.mp4',\n",
              " '10.mp4',\n",
              " '11.mp4',\n",
              " '12.mp4',\n",
              " '13.mp4',\n",
              " '14.mp4',\n",
              " '15.mp4',\n",
              " '16.mp4',\n",
              " '17.mp4',\n",
              " '18.mp4',\n",
              " '19.mp4',\n",
              " '20.mp4',\n",
              " '21.mp4',\n",
              " '22.mp4',\n",
              " '23.mp4']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Use YOLOv8 model to extract joint coordinates for Makes"
      ],
      "metadata": {
        "id": "csZcuikzLBrx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shot_array=[]\n",
        "detection_keypoint = DetectKeypoint()\n",
        "df_xy_coord_fin=pd.DataFrame()\n",
        "joints_extracted_from_pose=34\n",
        "#Download and add the yolov8n-pose.pt model to your CWD\n",
        "model = YOLO('yolov8n-pose.pt')\n",
        "for i in video_list_make:\n",
        "\n",
        "  # Load the YOLO model\n",
        "  xy_coord_array=np.array([])\n",
        "  xy_coord_array=np.zeros(joints_extracted_from_pose)\n",
        "\n",
        "  # Open the video file\n",
        "  video_path = \"/content/drive/MyDrive/Shots/Shot Makes/\"+i\n",
        "  print(video_path)\n",
        "  cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "  # Create a video writer to save the output\n",
        "  writer = imageio.get_writer(\"output.mp4\", mode=\"I\")\n",
        "\n",
        "  # Loop through the video frames. Pass each frame to detection_keypoint, which extracts XY coordinates of 34 joints\n",
        "  while cap.isOpened():\n",
        "      # Read a frame from the video\n",
        "      success, frame = cap.read()\n",
        "\n",
        "      if success:\n",
        "        start_time = time.time()\n",
        "        # Run pose detection on the frame\n",
        "\n",
        "        results = detection_keypoint(frame)\n",
        "        results_keypoint = detection_keypoint.get_xy_keypoint(results)\n",
        "\n",
        "        body_part_xy=np.array(results_keypoint)\n",
        "\n",
        "        # Create an array with XY coordinates for each frame\n",
        "        xy_coord_array=np.vstack((xy_coord_array,body_part_xy))\n",
        "\n",
        "        # Break the loop if 'q' is pressed\n",
        "        if cv2.waitKey(1) & 0xFF ==ord('q'):\n",
        "            break\n",
        "      else:\n",
        "          # Break the loop if the end of the video is reached\n",
        "          break\n",
        "\n",
        "  df_xs_coord=pd.DataFrame(xy_coord_array)\n",
        "  #label the video\n",
        "  df_xs_coord['video']=i\n",
        "  df_xs_coord['label']=1\n",
        "  #number each frame\n",
        "  df_xs_coord['frame_number']=range(1,len(xy_coord_array)+1)\n",
        "\n",
        "  df_xy_coord_fin = pd.concat([df_xy_coord_fin, df_xs_coord], ignore_index=True)\n",
        "  # Release the video capture object and close the display window\n",
        "  cap.release()\n",
        "  cv2.destroyAllWindows()\n",
        "\n",
        "  # Close the video writer\n",
        "  writer.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nFz-XR1Vhi7",
        "outputId": "5de721b2-8741-4868-bc20-5bc9b7ab1eb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m-pose.pt to 'yolov8m-pose.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50.8M/50.8M [00:00<00:00, 163MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n-pose.pt to 'yolov8n-pose.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.51M/6.51M [00:00<00:00, 63.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Shots/Shot Makes/ankur-make-1.mp4\n",
            "\n",
            "WARNING ⚠️ NMS time limit 0.550s exceeded\n",
            "0: 512x640 1 person, 135.3ms\n",
            "Speed: 16.9ms preprocess, 135.3ms inference, 698.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 29.7ms\n",
            "Speed: 5.5ms preprocess, 29.7ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 29.6ms\n",
            "Speed: 5.6ms preprocess, 29.6ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 29.6ms\n",
            "Speed: 5.7ms preprocess, 29.6ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 29.6ms\n",
            "Speed: 3.8ms preprocess, 29.6ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 29.6ms\n",
            "Speed: 7.5ms preprocess, 29.6ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 25.8ms\n",
            "Speed: 5.9ms preprocess, 25.8ms inference, 2.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 25.8ms\n",
            "Speed: 3.9ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 29.4ms\n",
            "Speed: 4.3ms preprocess, 29.4ms inference, 2.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 26.0ms\n",
            "Speed: 4.2ms preprocess, 26.0ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 25.8ms\n",
            "Speed: 3.9ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 26.3ms\n",
            "Speed: 3.9ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 24.9ms\n",
            "Speed: 8.6ms preprocess, 24.9ms inference, 2.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 22.2ms\n",
            "Speed: 6.0ms preprocess, 22.2ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 27.5ms\n",
            "Speed: 4.7ms preprocess, 27.5ms inference, 2.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 22.3ms\n",
            "Speed: 3.8ms preprocess, 22.3ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 22.2ms\n",
            "Speed: 3.8ms preprocess, 22.2ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 22.4ms\n",
            "Speed: 4.0ms preprocess, 22.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 22.2ms\n",
            "Speed: 4.0ms preprocess, 22.2ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 22.4ms\n",
            "Speed: 3.9ms preprocess, 22.4ms inference, 2.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 22.5ms\n",
            "Speed: 5.8ms preprocess, 22.5ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 22.3ms\n",
            "Speed: 4.0ms preprocess, 22.3ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 22.3ms\n",
            "Speed: 4.0ms preprocess, 22.3ms inference, 4.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 21.0ms\n",
            "Speed: 4.0ms preprocess, 21.0ms inference, 2.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 21.0ms\n",
            "Speed: 4.0ms preprocess, 21.0ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 21.0ms\n",
            "Speed: 4.6ms preprocess, 21.0ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 21.0ms\n",
            "Speed: 5.4ms preprocess, 21.0ms inference, 2.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 21.2ms\n",
            "Speed: 5.6ms preprocess, 21.2ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 21.0ms\n",
            "Speed: 4.2ms preprocess, 21.0ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 21.1ms\n",
            "Speed: 4.0ms preprocess, 21.1ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 21.1ms\n",
            "Speed: 4.0ms preprocess, 21.1ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 21.0ms\n",
            "Speed: 4.4ms preprocess, 21.0ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 21.1ms\n",
            "Speed: 3.8ms preprocess, 21.1ms inference, 3.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 21.2ms\n",
            "Speed: 6.2ms preprocess, 21.2ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 persons, 19.8ms\n",
            "Speed: 5.8ms preprocess, 19.8ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.9ms\n",
            "Speed: 4.7ms preprocess, 19.9ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.8ms\n",
            "Speed: 5.6ms preprocess, 19.8ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Makes/ankur-make-2.mp4\n",
            "\n",
            "0: 480x640 1 person, 83.6ms\n",
            "Speed: 6.4ms preprocess, 83.6ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.7ms\n",
            "Speed: 4.0ms preprocess, 19.7ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.7ms\n",
            "Speed: 3.5ms preprocess, 19.7ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 20.4ms\n",
            "Speed: 3.8ms preprocess, 20.4ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.7ms\n",
            "Speed: 4.1ms preprocess, 19.7ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.7ms\n",
            "Speed: 3.8ms preprocess, 19.7ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.7ms\n",
            "Speed: 5.2ms preprocess, 19.7ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.7ms\n",
            "Speed: 5.3ms preprocess, 19.7ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.7ms\n",
            "Speed: 5.3ms preprocess, 19.7ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.7ms\n",
            "Speed: 3.6ms preprocess, 19.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.6ms\n",
            "Speed: 3.7ms preprocess, 19.6ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.7ms\n",
            "Speed: 7.4ms preprocess, 19.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.7ms\n",
            "Speed: 3.8ms preprocess, 19.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.6ms\n",
            "Speed: 3.7ms preprocess, 19.6ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.7ms\n",
            "Speed: 3.5ms preprocess, 19.7ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.8ms\n",
            "Speed: 3.9ms preprocess, 19.8ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.6ms\n",
            "Speed: 3.8ms preprocess, 19.6ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 20.8ms\n",
            "Speed: 5.5ms preprocess, 20.8ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 20.8ms\n",
            "Speed: 5.2ms preprocess, 20.8ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 20.8ms\n",
            "Speed: 3.5ms preprocess, 20.8ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 20.8ms\n",
            "Speed: 4.0ms preprocess, 20.8ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.9ms\n",
            "Speed: 4.0ms preprocess, 19.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.9ms\n",
            "Speed: 4.3ms preprocess, 19.9ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 20.0ms\n",
            "Speed: 3.5ms preprocess, 20.0ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 20.0ms\n",
            "Speed: 3.5ms preprocess, 20.0ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 20.0ms\n",
            "Speed: 7.1ms preprocess, 20.0ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 21.7ms\n",
            "Speed: 3.6ms preprocess, 21.7ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 20.0ms\n",
            "Speed: 3.6ms preprocess, 20.0ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.6ms\n",
            "Speed: 4.9ms preprocess, 19.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.7ms\n",
            "Speed: 3.8ms preprocess, 19.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.6ms\n",
            "Speed: 3.5ms preprocess, 19.6ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.7ms\n",
            "Speed: 5.4ms preprocess, 19.7ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.6ms\n",
            "Speed: 5.3ms preprocess, 19.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.7ms\n",
            "Speed: 3.7ms preprocess, 19.7ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.6ms\n",
            "Speed: 4.4ms preprocess, 19.6ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.9ms\n",
            "Speed: 5.1ms preprocess, 19.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.6ms\n",
            "Speed: 4.1ms preprocess, 19.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Makes/ankur-make-3.mp4\n",
            "\n",
            "0: 480x640 1 person, 21.4ms\n",
            "Speed: 6.0ms preprocess, 21.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.7ms\n",
            "Speed: 3.9ms preprocess, 19.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.6ms\n",
            "Speed: 3.4ms preprocess, 19.6ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.7ms\n",
            "Speed: 3.8ms preprocess, 19.7ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.6ms\n",
            "Speed: 3.8ms preprocess, 19.6ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 22.4ms\n",
            "Speed: 5.7ms preprocess, 22.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.6ms\n",
            "Speed: 3.6ms preprocess, 19.6ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.7ms\n",
            "Speed: 3.5ms preprocess, 19.7ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 23.1ms\n",
            "Speed: 3.4ms preprocess, 23.1ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.6ms\n",
            "Speed: 3.5ms preprocess, 19.6ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.6ms\n",
            "Speed: 3.6ms preprocess, 19.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.8ms\n",
            "Speed: 3.3ms preprocess, 19.8ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.8ms\n",
            "Speed: 3.8ms preprocess, 19.8ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 20.2ms\n",
            "Speed: 3.7ms preprocess, 20.2ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 20.3ms\n",
            "Speed: 4.0ms preprocess, 20.3ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 20.3ms\n",
            "Speed: 3.7ms preprocess, 20.3ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 20.2ms\n",
            "Speed: 3.7ms preprocess, 20.2ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.9ms\n",
            "Speed: 3.6ms preprocess, 19.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.9ms\n",
            "Speed: 3.4ms preprocess, 19.9ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 20.0ms\n",
            "Speed: 3.6ms preprocess, 20.0ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 20.0ms\n",
            "Speed: 3.6ms preprocess, 20.0ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.9ms\n",
            "Speed: 3.5ms preprocess, 19.9ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 20.0ms\n",
            "Speed: 3.5ms preprocess, 20.0ms inference, 6.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.9ms\n",
            "Speed: 3.9ms preprocess, 19.9ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 20.0ms\n",
            "Speed: 3.6ms preprocess, 20.0ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.9ms\n",
            "Speed: 3.5ms preprocess, 19.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 20.0ms\n",
            "Speed: 3.7ms preprocess, 20.0ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 20.0ms\n",
            "Speed: 3.5ms preprocess, 20.0ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 20.0ms\n",
            "Speed: 4.7ms preprocess, 20.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.9ms\n",
            "Speed: 4.4ms preprocess, 19.9ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.9ms\n",
            "Speed: 3.5ms preprocess, 19.9ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.7ms\n",
            "Speed: 3.6ms preprocess, 19.7ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 20.1ms\n",
            "Speed: 3.6ms preprocess, 20.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.7ms\n",
            "Speed: 3.7ms preprocess, 19.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.6ms\n",
            "Speed: 3.8ms preprocess, 19.6ms inference, 5.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.7ms\n",
            "Speed: 4.1ms preprocess, 19.7ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.7ms\n",
            "Speed: 3.4ms preprocess, 19.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.6ms\n",
            "Speed: 3.5ms preprocess, 19.6ms inference, 9.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.7ms\n",
            "Speed: 3.6ms preprocess, 19.7ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.7ms\n",
            "Speed: 3.5ms preprocess, 19.7ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 22.9ms\n",
            "Speed: 3.5ms preprocess, 22.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.6ms\n",
            "Speed: 3.4ms preprocess, 19.6ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.6ms\n",
            "Speed: 3.6ms preprocess, 19.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.7ms\n",
            "Speed: 3.7ms preprocess, 19.7ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 20.6ms\n",
            "Speed: 5.0ms preprocess, 20.6ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.8ms\n",
            "Speed: 4.7ms preprocess, 19.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.6ms\n",
            "Speed: 3.9ms preprocess, 19.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 20.5ms\n",
            "Speed: 3.8ms preprocess, 20.5ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Makes/ankur-make-4.mp4\n",
            "\n",
            "0: 576x640 1 person, 241.3ms\n",
            "Speed: 4.0ms preprocess, 241.3ms inference, 2.8ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 47.2ms\n",
            "Speed: 4.9ms preprocess, 47.2ms inference, 6.2ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 47.6ms\n",
            "Speed: 5.2ms preprocess, 47.6ms inference, 4.6ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 67.0ms\n",
            "Speed: 14.8ms preprocess, 67.0ms inference, 2.6ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 45.0ms\n",
            "Speed: 6.8ms preprocess, 45.0ms inference, 2.2ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 37.1ms\n",
            "Speed: 5.1ms preprocess, 37.1ms inference, 2.2ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 42.5ms\n",
            "Speed: 14.3ms preprocess, 42.5ms inference, 2.1ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 40.1ms\n",
            "Speed: 9.5ms preprocess, 40.1ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 43.5ms\n",
            "Speed: 13.9ms preprocess, 43.5ms inference, 2.2ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 38.4ms\n",
            "Speed: 17.5ms preprocess, 38.4ms inference, 9.2ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 54.2ms\n",
            "Speed: 13.0ms preprocess, 54.2ms inference, 2.3ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 68.5ms\n",
            "Speed: 10.7ms preprocess, 68.5ms inference, 12.1ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 48.9ms\n",
            "Speed: 14.4ms preprocess, 48.9ms inference, 2.2ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 37.2ms\n",
            "Speed: 5.1ms preprocess, 37.2ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 59.7ms\n",
            "Speed: 8.8ms preprocess, 59.7ms inference, 3.4ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 70.5ms\n",
            "Speed: 12.4ms preprocess, 70.5ms inference, 2.4ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 53.1ms\n",
            "Speed: 5.4ms preprocess, 53.1ms inference, 4.8ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 37.3ms\n",
            "Speed: 8.5ms preprocess, 37.3ms inference, 2.2ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 93.9ms\n",
            "Speed: 17.2ms preprocess, 93.9ms inference, 5.8ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 96.4ms\n",
            "Speed: 26.3ms preprocess, 96.4ms inference, 13.2ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 65.0ms\n",
            "Speed: 4.3ms preprocess, 65.0ms inference, 6.1ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 38.9ms\n",
            "Speed: 4.6ms preprocess, 38.9ms inference, 18.7ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 52.8ms\n",
            "Speed: 12.2ms preprocess, 52.8ms inference, 2.3ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 40.3ms\n",
            "Speed: 12.0ms preprocess, 40.3ms inference, 11.0ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 41.3ms\n",
            "Speed: 13.9ms preprocess, 41.3ms inference, 8.3ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 38.0ms\n",
            "Speed: 6.1ms preprocess, 38.0ms inference, 5.4ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 50.7ms\n",
            "Speed: 9.6ms preprocess, 50.7ms inference, 2.3ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 58.6ms\n",
            "Speed: 7.8ms preprocess, 58.6ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 40.8ms\n",
            "Speed: 13.0ms preprocess, 40.8ms inference, 2.4ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 39.2ms\n",
            "Speed: 7.0ms preprocess, 39.2ms inference, 2.9ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 39.4ms\n",
            "Speed: 10.1ms preprocess, 39.4ms inference, 3.5ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 46.4ms\n",
            "Speed: 7.5ms preprocess, 46.4ms inference, 5.2ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 82.6ms\n",
            "Speed: 7.1ms preprocess, 82.6ms inference, 31.5ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 40.7ms\n",
            "Speed: 4.7ms preprocess, 40.7ms inference, 2.2ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 51.5ms\n",
            "Speed: 6.5ms preprocess, 51.5ms inference, 2.1ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 40.3ms\n",
            "Speed: 15.1ms preprocess, 40.3ms inference, 2.1ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 73.6ms\n",
            "Speed: 19.8ms preprocess, 73.6ms inference, 10.4ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 40.9ms\n",
            "Speed: 30.3ms preprocess, 40.9ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 40.2ms\n",
            "Speed: 16.6ms preprocess, 40.2ms inference, 5.2ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 41.3ms\n",
            "Speed: 20.3ms preprocess, 41.3ms inference, 2.1ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 41.7ms\n",
            "Speed: 4.1ms preprocess, 41.7ms inference, 2.6ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 51.0ms\n",
            "Speed: 13.6ms preprocess, 51.0ms inference, 6.4ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 43.1ms\n",
            "Speed: 4.2ms preprocess, 43.1ms inference, 3.6ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 47.4ms\n",
            "Speed: 4.6ms preprocess, 47.4ms inference, 3.3ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 41.2ms\n",
            "Speed: 7.1ms preprocess, 41.2ms inference, 2.4ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 43.1ms\n",
            "Speed: 5.7ms preprocess, 43.1ms inference, 2.4ms postprocess per image at shape (1, 3, 576, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Makes/ankur-make-5.mp4\n",
            "\n",
            "0: 448x640 1 person, 145.7ms\n",
            "Speed: 6.1ms preprocess, 145.7ms inference, 4.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 28.7ms\n",
            "Speed: 3.4ms preprocess, 28.7ms inference, 2.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 30.7ms\n",
            "Speed: 5.7ms preprocess, 30.7ms inference, 2.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 29.9ms\n",
            "Speed: 5.0ms preprocess, 29.9ms inference, 2.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 29.8ms\n",
            "Speed: 7.8ms preprocess, 29.8ms inference, 2.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 29.2ms\n",
            "Speed: 4.5ms preprocess, 29.2ms inference, 7.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 44.2ms\n",
            "Speed: 10.7ms preprocess, 44.2ms inference, 2.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 37.2ms\n",
            "Speed: 6.8ms preprocess, 37.2ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 28.7ms\n",
            "Speed: 3.9ms preprocess, 28.7ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 37.0ms\n",
            "Speed: 3.5ms preprocess, 37.0ms inference, 2.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 28.6ms\n",
            "Speed: 3.6ms preprocess, 28.6ms inference, 9.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 38.6ms\n",
            "Speed: 3.5ms preprocess, 38.6ms inference, 2.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 28.7ms\n",
            "Speed: 3.8ms preprocess, 28.7ms inference, 2.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 33.5ms\n",
            "Speed: 13.4ms preprocess, 33.5ms inference, 2.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 43.6ms\n",
            "Speed: 3.3ms preprocess, 43.6ms inference, 7.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 35.1ms\n",
            "Speed: 3.5ms preprocess, 35.1ms inference, 2.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 56.6ms\n",
            "Speed: 7.9ms preprocess, 56.6ms inference, 2.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 40.2ms\n",
            "Speed: 11.1ms preprocess, 40.2ms inference, 2.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 41.5ms\n",
            "Speed: 9.6ms preprocess, 41.5ms inference, 16.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 42.2ms\n",
            "Speed: 8.8ms preprocess, 42.2ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 52.7ms\n",
            "Speed: 6.3ms preprocess, 52.7ms inference, 2.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 31.5ms\n",
            "Speed: 3.7ms preprocess, 31.5ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 37.7ms\n",
            "Speed: 3.6ms preprocess, 37.7ms inference, 2.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 52.5ms\n",
            "Speed: 4.0ms preprocess, 52.5ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 28.6ms\n",
            "Speed: 9.7ms preprocess, 28.6ms inference, 5.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 32.1ms\n",
            "Speed: 3.4ms preprocess, 32.1ms inference, 9.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 36.0ms\n",
            "Speed: 3.5ms preprocess, 36.0ms inference, 2.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 34.1ms\n",
            "Speed: 4.6ms preprocess, 34.1ms inference, 2.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 37.0ms\n",
            "Speed: 3.5ms preprocess, 37.0ms inference, 6.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 29.2ms\n",
            "Speed: 3.7ms preprocess, 29.2ms inference, 2.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 28.2ms\n",
            "Speed: 4.6ms preprocess, 28.2ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 28.0ms\n",
            "Speed: 3.5ms preprocess, 28.0ms inference, 2.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 28.0ms\n",
            "Speed: 3.5ms preprocess, 28.0ms inference, 2.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 28.0ms\n",
            "Speed: 3.4ms preprocess, 28.0ms inference, 2.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 27.5ms\n",
            "Speed: 3.5ms preprocess, 27.5ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 25.3ms\n",
            "Speed: 3.9ms preprocess, 25.3ms inference, 2.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 29.4ms\n",
            "Speed: 4.5ms preprocess, 29.4ms inference, 2.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 25.2ms\n",
            "Speed: 3.5ms preprocess, 25.2ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 24.8ms\n",
            "Speed: 3.7ms preprocess, 24.8ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 24.9ms\n",
            "Speed: 3.6ms preprocess, 24.9ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Makes/ankur-make-6.mp4\n",
            "\n",
            "0: 512x640 1 person, 26.8ms\n",
            "Speed: 6.6ms preprocess, 26.8ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 25.9ms\n",
            "Speed: 4.3ms preprocess, 25.9ms inference, 2.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 25.9ms\n",
            "Speed: 4.2ms preprocess, 25.9ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 25.8ms\n",
            "Speed: 4.5ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 25.8ms\n",
            "Speed: 3.9ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 25.8ms\n",
            "Speed: 3.8ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 25.8ms\n",
            "Speed: 4.3ms preprocess, 25.8ms inference, 5.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 25.9ms\n",
            "Speed: 5.7ms preprocess, 25.9ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 25.8ms\n",
            "Speed: 4.1ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 25.8ms\n",
            "Speed: 7.0ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 25.8ms\n",
            "Speed: 3.7ms preprocess, 25.8ms inference, 3.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 21.3ms\n",
            "Speed: 4.0ms preprocess, 21.3ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 21.3ms\n",
            "Speed: 4.7ms preprocess, 21.3ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 21.4ms\n",
            "Speed: 4.2ms preprocess, 21.4ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 21.3ms\n",
            "Speed: 4.9ms preprocess, 21.3ms inference, 2.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 21.3ms\n",
            "Speed: 3.9ms preprocess, 21.3ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 21.4ms\n",
            "Speed: 4.1ms preprocess, 21.4ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 21.4ms\n",
            "Speed: 3.9ms preprocess, 21.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 21.3ms\n",
            "Speed: 3.9ms preprocess, 21.3ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 21.3ms\n",
            "Speed: 4.0ms preprocess, 21.3ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 21.3ms\n",
            "Speed: 4.1ms preprocess, 21.3ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 21.4ms\n",
            "Speed: 3.8ms preprocess, 21.4ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.9ms\n",
            "Speed: 3.9ms preprocess, 19.9ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.9ms\n",
            "Speed: 3.9ms preprocess, 19.9ms inference, 2.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.9ms\n",
            "Speed: 4.4ms preprocess, 19.9ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.9ms\n",
            "Speed: 4.5ms preprocess, 19.9ms inference, 3.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.9ms\n",
            "Speed: 3.9ms preprocess, 19.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.9ms\n",
            "Speed: 3.7ms preprocess, 19.9ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.9ms\n",
            "Speed: 4.0ms preprocess, 19.9ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.6ms\n",
            "Speed: 4.1ms preprocess, 19.6ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.6ms\n",
            "Speed: 3.8ms preprocess, 19.6ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 25.3ms\n",
            "Speed: 4.0ms preprocess, 25.3ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.6ms\n",
            "Speed: 3.7ms preprocess, 19.6ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.7ms\n",
            "Speed: 4.0ms preprocess, 19.7ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.6ms\n",
            "Speed: 3.9ms preprocess, 19.6ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.7ms\n",
            "Speed: 4.0ms preprocess, 19.7ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.6ms\n",
            "Speed: 4.2ms preprocess, 19.6ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 20.1ms\n",
            "Speed: 3.7ms preprocess, 20.1ms inference, 2.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.7ms\n",
            "Speed: 3.7ms preprocess, 19.7ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.6ms\n",
            "Speed: 3.6ms preprocess, 19.6ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.6ms\n",
            "Speed: 3.5ms preprocess, 19.6ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Makes/ankur-make-7.mp4\n",
            "\n",
            "0: 544x640 1 person, 85.9ms\n",
            "Speed: 4.1ms preprocess, 85.9ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.2ms\n",
            "Speed: 4.2ms preprocess, 20.2ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.0ms\n",
            "Speed: 4.2ms preprocess, 20.0ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.0ms\n",
            "Speed: 4.6ms preprocess, 20.0ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.0ms\n",
            "Speed: 4.0ms preprocess, 20.0ms inference, 4.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.0ms\n",
            "Speed: 4.2ms preprocess, 20.0ms inference, 2.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.0ms\n",
            "Speed: 4.1ms preprocess, 20.0ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.0ms\n",
            "Speed: 4.3ms preprocess, 20.0ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.0ms\n",
            "Speed: 4.1ms preprocess, 20.0ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.9ms\n",
            "Speed: 3.8ms preprocess, 19.9ms inference, 2.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.9ms\n",
            "Speed: 4.0ms preprocess, 19.9ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.1ms\n",
            "Speed: 4.4ms preprocess, 20.1ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.0ms\n",
            "Speed: 3.8ms preprocess, 20.0ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.9ms\n",
            "Speed: 4.2ms preprocess, 20.9ms inference, 2.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.1ms\n",
            "Speed: 4.8ms preprocess, 20.1ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.7ms\n",
            "Speed: 4.7ms preprocess, 19.7ms inference, 2.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.7ms\n",
            "Speed: 3.8ms preprocess, 19.7ms inference, 2.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.7ms\n",
            "Speed: 4.0ms preprocess, 19.7ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.7ms\n",
            "Speed: 4.0ms preprocess, 19.7ms inference, 2.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 21.0ms\n",
            "Speed: 4.5ms preprocess, 21.0ms inference, 2.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.7ms\n",
            "Speed: 4.2ms preprocess, 19.7ms inference, 2.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.7ms\n",
            "Speed: 5.4ms preprocess, 19.7ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.8ms\n",
            "Speed: 5.2ms preprocess, 19.8ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.7ms\n",
            "Speed: 4.8ms preprocess, 19.7ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.7ms\n",
            "Speed: 3.9ms preprocess, 19.7ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.7ms\n",
            "Speed: 6.0ms preprocess, 19.7ms inference, 2.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.7ms\n",
            "Speed: 3.8ms preprocess, 19.7ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.7ms\n",
            "Speed: 4.1ms preprocess, 19.7ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.7ms\n",
            "Speed: 3.9ms preprocess, 19.7ms inference, 3.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.7ms\n",
            "Speed: 4.8ms preprocess, 19.7ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.7ms\n",
            "Speed: 5.2ms preprocess, 19.7ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.7ms\n",
            "Speed: 5.5ms preprocess, 19.7ms inference, 5.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.7ms\n",
            "Speed: 4.3ms preprocess, 19.7ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.7ms\n",
            "Speed: 4.8ms preprocess, 19.7ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 22.8ms\n",
            "Speed: 6.5ms preprocess, 22.8ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.7ms\n",
            "Speed: 3.9ms preprocess, 19.7ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.7ms\n",
            "Speed: 4.3ms preprocess, 19.7ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.3ms\n",
            "Speed: 4.1ms preprocess, 20.3ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.7ms\n",
            "Speed: 4.3ms preprocess, 19.7ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.7ms\n",
            "Speed: 4.3ms preprocess, 19.7ms inference, 2.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 21.5ms\n",
            "Speed: 6.3ms preprocess, 21.5ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.7ms\n",
            "Speed: 4.0ms preprocess, 19.7ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.7ms\n",
            "Speed: 4.0ms preprocess, 19.7ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.7ms\n",
            "Speed: 4.2ms preprocess, 19.7ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Makes/ankur-make-8.mp4\n",
            "\n",
            "0: 480x640 1 person, 22.7ms\n",
            "Speed: 3.6ms preprocess, 22.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 25.8ms\n",
            "Speed: 11.5ms preprocess, 25.8ms inference, 7.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 29.7ms\n",
            "Speed: 3.6ms preprocess, 29.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 25.0ms\n",
            "Speed: 8.9ms preprocess, 25.0ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 21.9ms\n",
            "Speed: 3.5ms preprocess, 21.9ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 20.8ms\n",
            "Speed: 4.4ms preprocess, 20.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 21.4ms\n",
            "Speed: 5.7ms preprocess, 21.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 32.8ms\n",
            "Speed: 5.1ms preprocess, 32.8ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 31.5ms\n",
            "Speed: 3.6ms preprocess, 31.5ms inference, 11.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 33.8ms\n",
            "Speed: 3.6ms preprocess, 33.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 27.7ms\n",
            "Speed: 10.2ms preprocess, 27.7ms inference, 5.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 24.1ms\n",
            "Speed: 3.7ms preprocess, 24.1ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 23.6ms\n",
            "Speed: 5.3ms preprocess, 23.6ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 30.1ms\n",
            "Speed: 3.7ms preprocess, 30.1ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 32.9ms\n",
            "Speed: 3.7ms preprocess, 32.9ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 27.8ms\n",
            "Speed: 3.7ms preprocess, 27.8ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 23.8ms\n",
            "Speed: 6.5ms preprocess, 23.8ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 23.8ms\n",
            "Speed: 5.1ms preprocess, 23.8ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 27.7ms\n",
            "Speed: 8.7ms preprocess, 27.7ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 34.7ms\n",
            "Speed: 3.7ms preprocess, 34.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 29.9ms\n",
            "Speed: 3.7ms preprocess, 29.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 30.6ms\n",
            "Speed: 3.6ms preprocess, 30.6ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 27.3ms\n",
            "Speed: 3.9ms preprocess, 27.3ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 30.6ms\n",
            "Speed: 3.7ms preprocess, 30.6ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 25.1ms\n",
            "Speed: 4.6ms preprocess, 25.1ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 25.6ms\n",
            "Speed: 8.3ms preprocess, 25.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 31.9ms\n",
            "Speed: 5.5ms preprocess, 31.9ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 34.7ms\n",
            "Speed: 3.7ms preprocess, 34.7ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 36.5ms\n",
            "Speed: 3.8ms preprocess, 36.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 29.8ms\n",
            "Speed: 10.9ms preprocess, 29.8ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 30.0ms\n",
            "Speed: 3.6ms preprocess, 30.0ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 39.1ms\n",
            "Speed: 3.6ms preprocess, 39.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 37.3ms\n",
            "Speed: 3.8ms preprocess, 37.3ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 27.1ms\n",
            "Speed: 3.9ms preprocess, 27.1ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 32.2ms\n",
            "Speed: 3.7ms preprocess, 32.2ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 33.1ms\n",
            "Speed: 3.7ms preprocess, 33.1ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 30.3ms\n",
            "Speed: 3.5ms preprocess, 30.3ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 26.7ms\n",
            "Speed: 4.3ms preprocess, 26.7ms inference, 8.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 26.6ms\n",
            "Speed: 3.8ms preprocess, 26.6ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 26.6ms\n",
            "Speed: 8.7ms preprocess, 26.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 26.6ms\n",
            "Speed: 3.4ms preprocess, 26.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 26.5ms\n",
            "Speed: 9.6ms preprocess, 26.5ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 26.6ms\n",
            "Speed: 6.2ms preprocess, 26.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 26.3ms\n",
            "Speed: 5.1ms preprocess, 26.3ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Makes/mahesh_make1.mp4\n",
            "\n",
            "0: 384x640 1 person, 96.4ms\n",
            "Speed: 3.6ms preprocess, 96.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.0ms\n",
            "Speed: 3.3ms preprocess, 20.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.0ms\n",
            "Speed: 3.4ms preprocess, 20.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.5ms\n",
            "Speed: 2.9ms preprocess, 21.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.3ms\n",
            "Speed: 3.0ms preprocess, 20.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.1ms\n",
            "Speed: 2.7ms preprocess, 20.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.2ms\n",
            "Speed: 2.7ms preprocess, 20.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.9ms\n",
            "Speed: 3.0ms preprocess, 20.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.2ms\n",
            "Speed: 2.8ms preprocess, 20.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.1ms\n",
            "Speed: 3.1ms preprocess, 17.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.2ms\n",
            "Speed: 3.2ms preprocess, 17.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.8ms\n",
            "Speed: 3.2ms preprocess, 16.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.1ms\n",
            "Speed: 3.4ms preprocess, 20.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.8ms\n",
            "Speed: 3.4ms preprocess, 16.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 2.9ms preprocess, 16.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.2ms\n",
            "Speed: 3.1ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.7ms\n",
            "Speed: 3.8ms preprocess, 15.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.7ms\n",
            "Speed: 3.0ms preprocess, 15.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.0ms\n",
            "Speed: 2.9ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 3.0ms preprocess, 15.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 3.3ms preprocess, 15.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 2.9ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.9ms\n",
            "Speed: 2.8ms preprocess, 16.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.6ms\n",
            "Speed: 3.2ms preprocess, 18.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.1ms\n",
            "Speed: 2.9ms preprocess, 17.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.8ms\n",
            "Speed: 3.3ms preprocess, 16.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.8ms\n",
            "Speed: 3.0ms preprocess, 14.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.2ms\n",
            "Speed: 2.7ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.4ms\n",
            "Speed: 3.1ms preprocess, 14.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.4ms\n",
            "Speed: 3.3ms preprocess, 13.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.1ms\n",
            "Speed: 2.9ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.3ms\n",
            "Speed: 3.2ms preprocess, 16.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.7ms\n",
            "Speed: 4.1ms preprocess, 22.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 3.0ms preprocess, 16.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.2ms\n",
            "Speed: 6.2ms preprocess, 12.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.3ms\n",
            "Speed: 2.8ms preprocess, 16.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.3ms\n",
            "Speed: 2.7ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.3ms\n",
            "Speed: 2.9ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.3ms\n",
            "Speed: 3.3ms preprocess, 16.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.5ms\n",
            "Speed: 3.0ms preprocess, 15.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.1ms\n",
            "Speed: 2.9ms preprocess, 17.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.7ms\n",
            "Speed: 2.8ms preprocess, 16.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 2.9ms preprocess, 13.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.1ms\n",
            "Speed: 3.0ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Makes/mahesh_make2.mp4\n",
            "\n",
            "0: 640x640 1 person, 19.5ms\n",
            "Speed: 6.6ms preprocess, 19.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.5ms\n",
            "Speed: 5.5ms preprocess, 18.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.5ms\n",
            "Speed: 4.8ms preprocess, 18.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 43.8ms\n",
            "Speed: 4.6ms preprocess, 43.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.3ms\n",
            "Speed: 5.7ms preprocess, 18.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.3ms\n",
            "Speed: 5.0ms preprocess, 18.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.4ms\n",
            "Speed: 6.7ms preprocess, 18.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.5ms\n",
            "Speed: 7.7ms preprocess, 18.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.6ms\n",
            "Speed: 5.7ms preprocess, 18.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 19.4ms\n",
            "Speed: 10.9ms preprocess, 19.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 19.4ms\n",
            "Speed: 4.5ms preprocess, 19.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 19.4ms\n",
            "Speed: 4.8ms preprocess, 19.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 19.3ms\n",
            "Speed: 4.7ms preprocess, 19.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 19.5ms\n",
            "Speed: 4.6ms preprocess, 19.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 20.8ms\n",
            "Speed: 5.0ms preprocess, 20.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.6ms\n",
            "Speed: 5.2ms preprocess, 18.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.5ms\n",
            "Speed: 4.6ms preprocess, 18.5ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.6ms\n",
            "Speed: 4.7ms preprocess, 18.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.6ms\n",
            "Speed: 4.8ms preprocess, 18.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.6ms\n",
            "Speed: 6.3ms preprocess, 18.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.6ms\n",
            "Speed: 5.1ms preprocess, 18.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.6ms\n",
            "Speed: 4.4ms preprocess, 18.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 20.9ms\n",
            "Speed: 4.6ms preprocess, 20.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.6ms\n",
            "Speed: 4.5ms preprocess, 18.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.5ms\n",
            "Speed: 4.8ms preprocess, 18.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.5ms\n",
            "Speed: 4.8ms preprocess, 18.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.6ms\n",
            "Speed: 4.8ms preprocess, 18.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.9ms\n",
            "Speed: 5.9ms preprocess, 18.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.6ms\n",
            "Speed: 4.4ms preprocess, 18.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.6ms\n",
            "Speed: 4.9ms preprocess, 18.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.5ms\n",
            "Speed: 5.2ms preprocess, 18.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.6ms\n",
            "Speed: 4.6ms preprocess, 18.6ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.6ms\n",
            "Speed: 4.4ms preprocess, 18.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.5ms\n",
            "Speed: 4.6ms preprocess, 18.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.4ms\n",
            "Speed: 5.2ms preprocess, 18.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.4ms\n",
            "Speed: 5.6ms preprocess, 18.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.5ms\n",
            "Speed: 5.7ms preprocess, 18.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.6ms\n",
            "Speed: 4.9ms preprocess, 18.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.6ms\n",
            "Speed: 5.1ms preprocess, 18.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.6ms\n",
            "Speed: 5.0ms preprocess, 18.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.6ms\n",
            "Speed: 5.4ms preprocess, 18.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.6ms\n",
            "Speed: 9.6ms preprocess, 18.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.6ms\n",
            "Speed: 5.0ms preprocess, 18.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.6ms\n",
            "Speed: 4.7ms preprocess, 18.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.5ms\n",
            "Speed: 4.8ms preprocess, 18.5ms inference, 7.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.5ms\n",
            "Speed: 4.5ms preprocess, 18.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.5ms\n",
            "Speed: 4.3ms preprocess, 18.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.6ms\n",
            "Speed: 6.8ms preprocess, 18.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.6ms\n",
            "Speed: 4.3ms preprocess, 18.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.5ms\n",
            "Speed: 4.5ms preprocess, 18.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.9ms\n",
            "Speed: 4.9ms preprocess, 18.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 19.0ms\n",
            "Speed: 6.2ms preprocess, 19.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 19.0ms\n",
            "Speed: 5.5ms preprocess, 19.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 persons, 19.0ms\n",
            "Speed: 4.6ms preprocess, 19.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.7ms\n",
            "Speed: 4.6ms preprocess, 18.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.3ms\n",
            "Speed: 4.6ms preprocess, 18.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.3ms\n",
            "Speed: 7.3ms preprocess, 18.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.7ms\n",
            "Speed: 4.9ms preprocess, 18.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.3ms\n",
            "Speed: 5.5ms preprocess, 18.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Makes/mahesh_make3.mp4\n",
            "\n",
            "0: 384x640 1 person, 12.9ms\n",
            "Speed: 5.5ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.8ms\n",
            "Speed: 3.0ms preprocess, 12.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.9ms\n",
            "Speed: 2.9ms preprocess, 11.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.1ms\n",
            "Speed: 3.7ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.8ms\n",
            "Speed: 2.9ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.8ms\n",
            "Speed: 3.3ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 3.0ms preprocess, 14.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.6ms\n",
            "Speed: 3.2ms preprocess, 17.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.5ms\n",
            "Speed: 2.7ms preprocess, 17.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.2ms\n",
            "Speed: 3.2ms preprocess, 15.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.3ms\n",
            "Speed: 3.9ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.2ms\n",
            "Speed: 3.1ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.5ms\n",
            "Speed: 4.0ms preprocess, 17.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.4ms\n",
            "Speed: 2.7ms preprocess, 15.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.5ms\n",
            "Speed: 2.7ms preprocess, 15.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.8ms\n",
            "Speed: 2.6ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.8ms\n",
            "Speed: 2.8ms preprocess, 15.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.4ms\n",
            "Speed: 4.5ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 3.6ms preprocess, 14.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.9ms\n",
            "Speed: 3.9ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.8ms\n",
            "Speed: 3.4ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.8ms\n",
            "Speed: 3.1ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.8ms\n",
            "Speed: 3.5ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.0ms\n",
            "Speed: 3.2ms preprocess, 12.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.9ms\n",
            "Speed: 5.0ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.5ms\n",
            "Speed: 2.9ms preprocess, 17.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.9ms\n",
            "Speed: 3.5ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.2ms\n",
            "Speed: 3.7ms preprocess, 12.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.2ms\n",
            "Speed: 6.9ms preprocess, 18.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.3ms\n",
            "Speed: 3.5ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.3ms\n",
            "Speed: 3.8ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.2ms\n",
            "Speed: 2.5ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.7ms\n",
            "Speed: 2.7ms preprocess, 14.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 2.7ms preprocess, 14.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.6ms\n",
            "Speed: 2.7ms preprocess, 19.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.1ms\n",
            "Speed: 2.7ms preprocess, 16.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.8ms\n",
            "Speed: 2.8ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.8ms\n",
            "Speed: 2.7ms preprocess, 15.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.3ms\n",
            "Speed: 2.8ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.4ms\n",
            "Speed: 2.6ms preprocess, 15.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.3ms\n",
            "Speed: 2.6ms preprocess, 13.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.8ms\n",
            "Speed: 4.3ms preprocess, 12.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.6ms\n",
            "Speed: 2.8ms preprocess, 15.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.5ms\n",
            "Speed: 4.1ms preprocess, 19.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.4ms\n",
            "Speed: 3.8ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.3ms\n",
            "Speed: 4.2ms preprocess, 19.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.9ms\n",
            "Speed: 2.7ms preprocess, 13.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.0ms\n",
            "Speed: 2.4ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 2.6ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.3ms\n",
            "Speed: 3.2ms preprocess, 16.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.9ms\n",
            "Speed: 2.9ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.9ms\n",
            "Speed: 2.9ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.9ms\n",
            "Speed: 2.9ms preprocess, 15.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.8ms\n",
            "Speed: 3.4ms preprocess, 12.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.5ms\n",
            "Speed: 3.2ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.5ms\n",
            "Speed: 5.5ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.0ms\n",
            "Speed: 5.3ms preprocess, 18.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.7ms\n",
            "Speed: 3.5ms preprocess, 12.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.4ms\n",
            "Speed: 3.2ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.9ms\n",
            "Speed: 3.2ms preprocess, 13.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.7ms\n",
            "Speed: 2.7ms preprocess, 12.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Makes/mahesh_make6.mp4\n",
            "\n",
            "0: 384x640 2 persons, 18.9ms\n",
            "Speed: 5.0ms preprocess, 18.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 20.0ms\n",
            "Speed: 3.0ms preprocess, 20.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 20.0ms\n",
            "Speed: 2.5ms preprocess, 20.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 20.0ms\n",
            "Speed: 2.8ms preprocess, 20.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 20.0ms\n",
            "Speed: 3.0ms preprocess, 20.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 19.9ms\n",
            "Speed: 2.9ms preprocess, 19.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16.4ms\n",
            "Speed: 2.7ms preprocess, 16.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16.3ms\n",
            "Speed: 2.7ms preprocess, 16.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16.3ms\n",
            "Speed: 2.6ms preprocess, 16.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 19.7ms\n",
            "Speed: 2.7ms preprocess, 19.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16.2ms\n",
            "Speed: 2.6ms preprocess, 16.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16.2ms\n",
            "Speed: 2.8ms preprocess, 16.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.9ms\n",
            "Speed: 2.7ms preprocess, 13.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14.4ms\n",
            "Speed: 2.7ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 19.6ms\n",
            "Speed: 3.0ms preprocess, 19.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.8ms\n",
            "Speed: 2.8ms preprocess, 16.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 17.0ms\n",
            "Speed: 3.4ms preprocess, 17.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16.6ms\n",
            "Speed: 3.0ms preprocess, 16.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.7ms\n",
            "Speed: 2.7ms preprocess, 13.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.6ms\n",
            "Speed: 2.7ms preprocess, 15.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.1ms\n",
            "Speed: 5.0ms preprocess, 16.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.0ms\n",
            "Speed: 3.1ms preprocess, 15.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23.9ms\n",
            "Speed: 2.8ms preprocess, 23.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.4ms\n",
            "Speed: 2.8ms preprocess, 14.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23.7ms\n",
            "Speed: 2.7ms preprocess, 23.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.0ms\n",
            "Speed: 2.7ms preprocess, 19.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.1ms\n",
            "Speed: 2.9ms preprocess, 17.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.2ms\n",
            "Speed: 2.7ms preprocess, 16.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 7.8ms preprocess, 15.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.2ms\n",
            "Speed: 2.8ms preprocess, 18.2ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.9ms\n",
            "Speed: 3.2ms preprocess, 16.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Makes/mahesh_make8.mp4\n",
            "\n",
            "0: 384x640 1 person, 26.4ms\n",
            "Speed: 3.1ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.4ms\n",
            "Speed: 3.1ms preprocess, 19.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.2ms\n",
            "Speed: 3.2ms preprocess, 15.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.9ms\n",
            "Speed: 5.0ms preprocess, 19.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.2ms\n",
            "Speed: 2.8ms preprocess, 13.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.5ms\n",
            "Speed: 5.0ms preprocess, 16.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.7ms\n",
            "Speed: 2.8ms preprocess, 14.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.7ms\n",
            "Speed: 2.9ms preprocess, 14.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.8ms\n",
            "Speed: 3.2ms preprocess, 15.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.3ms\n",
            "Speed: 2.9ms preprocess, 13.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.9ms\n",
            "Speed: 2.9ms preprocess, 18.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.0ms\n",
            "Speed: 5.1ms preprocess, 18.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.2ms\n",
            "Speed: 3.2ms preprocess, 16.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 2.7ms preprocess, 14.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.3ms\n",
            "Speed: 3.1ms preprocess, 17.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.1ms\n",
            "Speed: 3.1ms preprocess, 19.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.0ms\n",
            "Speed: 4.7ms preprocess, 15.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.7ms\n",
            "Speed: 4.6ms preprocess, 17.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.5ms\n",
            "Speed: 3.2ms preprocess, 17.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.4ms\n",
            "Speed: 3.9ms preprocess, 16.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.8ms\n",
            "Speed: 2.9ms preprocess, 14.8ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 3.9ms preprocess, 15.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 2.7ms preprocess, 15.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.4ms\n",
            "Speed: 3.7ms preprocess, 15.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.2ms\n",
            "Speed: 5.7ms preprocess, 17.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.0ms\n",
            "Speed: 3.1ms preprocess, 20.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.9ms\n",
            "Speed: 4.9ms preprocess, 16.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.2ms\n",
            "Speed: 3.2ms preprocess, 15.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.2ms\n",
            "Speed: 2.8ms preprocess, 22.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Makes/mahesh_make9.mp4\n",
            "\n",
            "0: 384x640 2 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 26.7ms\n",
            "Speed: 2.6ms preprocess, 26.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 26.5ms\n",
            "Speed: 3.9ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 26.4ms\n",
            "Speed: 4.6ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 27.2ms\n",
            "Speed: 2.6ms preprocess, 27.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 23.8ms\n",
            "Speed: 2.7ms preprocess, 23.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 25.0ms\n",
            "Speed: 4.6ms preprocess, 25.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 25.6ms\n",
            "Speed: 2.9ms preprocess, 25.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 23.3ms\n",
            "Speed: 2.5ms preprocess, 23.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 20.3ms\n",
            "Speed: 2.8ms preprocess, 20.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 20.3ms\n",
            "Speed: 2.7ms preprocess, 20.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 23.4ms\n",
            "Speed: 2.7ms preprocess, 23.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 20.2ms\n",
            "Speed: 4.6ms preprocess, 20.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 19.3ms\n",
            "Speed: 2.7ms preprocess, 19.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.0ms\n",
            "Speed: 2.7ms preprocess, 22.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 18.8ms\n",
            "Speed: 2.7ms preprocess, 18.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 21.2ms\n",
            "Speed: 4.6ms preprocess, 21.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 18.8ms\n",
            "Speed: 3.1ms preprocess, 18.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.4ms\n",
            "Speed: 9.0ms preprocess, 21.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23.1ms\n",
            "Speed: 2.9ms preprocess, 23.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.9ms\n",
            "Speed: 2.6ms preprocess, 16.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.6ms\n",
            "Speed: 3.4ms preprocess, 17.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.8ms\n",
            "Speed: 2.7ms preprocess, 16.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.2ms\n",
            "Speed: 3.6ms preprocess, 18.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.2ms\n",
            "Speed: 2.7ms preprocess, 16.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.3ms\n",
            "Speed: 2.6ms preprocess, 16.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.1ms\n",
            "Speed: 2.9ms preprocess, 16.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.1ms\n",
            "Speed: 5.6ms preprocess, 17.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.9ms\n",
            "Speed: 2.8ms preprocess, 15.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.4ms\n",
            "Speed: 2.7ms preprocess, 14.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.3ms\n",
            "Speed: 2.5ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Makes/mahesh_make10.mp4\n",
            "\n",
            "0: 384x640 1 person, 14.3ms\n",
            "Speed: 4.1ms preprocess, 14.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.1ms\n",
            "Speed: 2.8ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.4ms\n",
            "Speed: 2.8ms preprocess, 14.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.0ms\n",
            "Speed: 3.1ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 3.1ms preprocess, 16.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.3ms\n",
            "Speed: 3.2ms preprocess, 17.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.3ms\n",
            "Speed: 5.7ms preprocess, 21.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.3ms\n",
            "Speed: 2.7ms preprocess, 14.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.3ms\n",
            "Speed: 2.8ms preprocess, 17.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 3.1ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.4ms\n",
            "Speed: 3.0ms preprocess, 22.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 2.9ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.1ms\n",
            "Speed: 2.9ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.5ms\n",
            "Speed: 2.7ms preprocess, 17.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.4ms\n",
            "Speed: 2.8ms preprocess, 15.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.3ms\n",
            "Speed: 2.8ms preprocess, 20.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.0ms\n",
            "Speed: 2.7ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.1ms\n",
            "Speed: 3.0ms preprocess, 16.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.7ms\n",
            "Speed: 2.9ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.7ms\n",
            "Speed: 5.5ms preprocess, 13.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.9ms\n",
            "Speed: 3.0ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.9ms\n",
            "Speed: 4.4ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.0ms\n",
            "Speed: 2.8ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.8ms\n",
            "Speed: 4.3ms preprocess, 12.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.3ms\n",
            "Speed: 2.7ms preprocess, 15.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.0ms\n",
            "Speed: 3.1ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.0ms\n",
            "Speed: 2.8ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.2ms\n",
            "Speed: 2.6ms preprocess, 15.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.4ms\n",
            "Speed: 3.0ms preprocess, 15.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.6ms\n",
            "Speed: 2.6ms preprocess, 12.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.8ms\n",
            "Speed: 3.7ms preprocess, 12.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.2ms\n",
            "Speed: 2.9ms preprocess, 15.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.8ms\n",
            "Speed: 2.8ms preprocess, 12.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.2ms\n",
            "Speed: 3.3ms preprocess, 13.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.8ms\n",
            "Speed: 2.9ms preprocess, 16.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.7ms\n",
            "Speed: 3.3ms preprocess, 14.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.2ms\n",
            "Speed: 2.6ms preprocess, 16.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.7ms\n",
            "Speed: 2.6ms preprocess, 17.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Makes/mahesh_make12.mp4\n",
            "\n",
            "0: 480x640 1 person, 31.9ms\n",
            "Speed: 5.0ms preprocess, 31.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 14.8ms\n",
            "Speed: 3.6ms preprocess, 14.8ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 14.4ms\n",
            "Speed: 4.5ms preprocess, 14.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 14.4ms\n",
            "Speed: 3.9ms preprocess, 14.4ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 15.8ms\n",
            "Speed: 5.2ms preprocess, 15.8ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 15.3ms\n",
            "Speed: 3.4ms preprocess, 15.3ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 18.8ms\n",
            "Speed: 3.7ms preprocess, 18.8ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 14.3ms\n",
            "Speed: 3.7ms preprocess, 14.3ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 14.4ms\n",
            "Speed: 5.5ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 17.3ms\n",
            "Speed: 5.3ms preprocess, 17.3ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 14.5ms\n",
            "Speed: 4.1ms preprocess, 14.5ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 14.3ms\n",
            "Speed: 4.2ms preprocess, 14.3ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 14.4ms\n",
            "Speed: 4.1ms preprocess, 14.4ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 14.4ms\n",
            "Speed: 4.0ms preprocess, 14.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 17.7ms\n",
            "Speed: 4.1ms preprocess, 17.7ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 17.6ms\n",
            "Speed: 3.9ms preprocess, 17.6ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 17.3ms\n",
            "Speed: 4.4ms preprocess, 17.3ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 18.6ms\n",
            "Speed: 4.4ms preprocess, 18.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 17.8ms\n",
            "Speed: 4.1ms preprocess, 17.8ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 17.9ms\n",
            "Speed: 3.6ms preprocess, 17.9ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 18.2ms\n",
            "Speed: 3.6ms preprocess, 18.2ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 18.3ms\n",
            "Speed: 4.0ms preprocess, 18.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 18.4ms\n",
            "Speed: 3.5ms preprocess, 18.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 18.1ms\n",
            "Speed: 3.6ms preprocess, 18.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 18.5ms\n",
            "Speed: 5.0ms preprocess, 18.5ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 18.5ms\n",
            "Speed: 4.0ms preprocess, 18.5ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 18.5ms\n",
            "Speed: 12.6ms preprocess, 18.5ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 21.1ms\n",
            "Speed: 5.4ms preprocess, 21.1ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 18.5ms\n",
            "Speed: 4.4ms preprocess, 18.5ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 18.5ms\n",
            "Speed: 7.1ms preprocess, 18.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 18.5ms\n",
            "Speed: 3.6ms preprocess, 18.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.0ms\n",
            "Speed: 3.3ms preprocess, 19.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 23.0ms\n",
            "Speed: 5.3ms preprocess, 23.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 18.9ms\n",
            "Speed: 3.6ms preprocess, 18.9ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 18.9ms\n",
            "Speed: 3.5ms preprocess, 18.9ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.2ms\n",
            "Speed: 3.4ms preprocess, 19.2ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 18.9ms\n",
            "Speed: 3.3ms preprocess, 18.9ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.8ms\n",
            "Speed: 3.4ms preprocess, 19.8ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.4ms\n",
            "Speed: 3.6ms preprocess, 19.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.4ms\n",
            "Speed: 3.8ms preprocess, 19.4ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.4ms\n",
            "Speed: 4.3ms preprocess, 19.4ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.4ms\n",
            "Speed: 5.9ms preprocess, 19.4ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.4ms\n",
            "Speed: 3.5ms preprocess, 19.4ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.4ms\n",
            "Speed: 3.4ms preprocess, 19.4ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.5ms\n",
            "Speed: 3.7ms preprocess, 19.5ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.7ms\n",
            "Speed: 3.7ms preprocess, 19.7ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.6ms\n",
            "Speed: 3.7ms preprocess, 19.6ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.7ms\n",
            "Speed: 3.8ms preprocess, 19.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 20.1ms\n",
            "Speed: 6.0ms preprocess, 20.1ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 20.3ms\n",
            "Speed: 4.3ms preprocess, 20.3ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 20.2ms\n",
            "Speed: 3.6ms preprocess, 20.2ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 20.2ms\n",
            "Speed: 3.8ms preprocess, 20.2ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.9ms\n",
            "Speed: 3.7ms preprocess, 19.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.9ms\n",
            "Speed: 3.9ms preprocess, 19.9ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 19.9ms\n",
            "Speed: 4.0ms preprocess, 19.9ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Makes/mahesh_make13.mp4\n",
            "\n",
            "0: 608x640 1 person, 98.0ms\n",
            "Speed: 5.2ms preprocess, 98.0ms inference, 1.6ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 25.9ms\n",
            "Speed: 5.0ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 25.9ms\n",
            "Speed: 5.1ms preprocess, 25.9ms inference, 1.8ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 25.8ms\n",
            "Speed: 4.2ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 25.8ms\n",
            "Speed: 4.4ms preprocess, 25.8ms inference, 1.8ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 24.8ms\n",
            "Speed: 5.0ms preprocess, 24.8ms inference, 1.7ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 23.5ms\n",
            "Speed: 4.2ms preprocess, 23.5ms inference, 2.5ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 23.4ms\n",
            "Speed: 5.2ms preprocess, 23.4ms inference, 1.6ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 26.1ms\n",
            "Speed: 4.3ms preprocess, 26.1ms inference, 2.4ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 22.8ms\n",
            "Speed: 4.5ms preprocess, 22.8ms inference, 2.5ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 22.8ms\n",
            "Speed: 4.4ms preprocess, 22.8ms inference, 2.1ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 22.4ms\n",
            "Speed: 4.6ms preprocess, 22.4ms inference, 1.9ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 22.5ms\n",
            "Speed: 5.6ms preprocess, 22.5ms inference, 2.3ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 20.7ms\n",
            "Speed: 6.3ms preprocess, 20.7ms inference, 2.2ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 20.7ms\n",
            "Speed: 6.4ms preprocess, 20.7ms inference, 2.2ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 20.4ms\n",
            "Speed: 5.0ms preprocess, 20.4ms inference, 1.9ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 20.5ms\n",
            "Speed: 4.6ms preprocess, 20.5ms inference, 2.4ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 20.5ms\n",
            "Speed: 10.0ms preprocess, 20.5ms inference, 1.6ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 20.4ms\n",
            "Speed: 4.4ms preprocess, 20.4ms inference, 2.2ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 20.4ms\n",
            "Speed: 5.8ms preprocess, 20.4ms inference, 2.2ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 20.4ms\n",
            "Speed: 6.4ms preprocess, 20.4ms inference, 2.1ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 20.4ms\n",
            "Speed: 4.2ms preprocess, 20.4ms inference, 1.7ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 20.4ms\n",
            "Speed: 4.2ms preprocess, 20.4ms inference, 2.7ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 20.5ms\n",
            "Speed: 5.2ms preprocess, 20.5ms inference, 1.9ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 20.4ms\n",
            "Speed: 5.6ms preprocess, 20.4ms inference, 2.9ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 20.5ms\n",
            "Speed: 6.5ms preprocess, 20.5ms inference, 2.2ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 20.6ms\n",
            "Speed: 6.4ms preprocess, 20.6ms inference, 2.2ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 20.1ms\n",
            "Speed: 4.5ms preprocess, 20.1ms inference, 1.8ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 20.1ms\n",
            "Speed: 6.1ms preprocess, 20.1ms inference, 1.8ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 20.0ms\n",
            "Speed: 4.5ms preprocess, 20.0ms inference, 1.8ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 19.9ms\n",
            "Speed: 5.3ms preprocess, 19.9ms inference, 1.8ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 19.9ms\n",
            "Speed: 4.5ms preprocess, 19.9ms inference, 2.5ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 19.9ms\n",
            "Speed: 4.4ms preprocess, 19.9ms inference, 1.8ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 19.8ms\n",
            "Speed: 8.0ms preprocess, 19.8ms inference, 2.1ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 19.8ms\n",
            "Speed: 4.5ms preprocess, 19.8ms inference, 2.1ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 19.8ms\n",
            "Speed: 4.4ms preprocess, 19.8ms inference, 2.3ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 19.8ms\n",
            "Speed: 5.2ms preprocess, 19.8ms inference, 1.8ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 20.1ms\n",
            "Speed: 6.0ms preprocess, 20.1ms inference, 2.2ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 19.8ms\n",
            "Speed: 12.7ms preprocess, 19.8ms inference, 1.8ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 20.2ms\n",
            "Speed: 5.0ms preprocess, 20.2ms inference, 2.1ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 19.8ms\n",
            "Speed: 4.8ms preprocess, 19.8ms inference, 1.9ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 19.8ms\n",
            "Speed: 5.9ms preprocess, 19.8ms inference, 2.4ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 20.5ms\n",
            "Speed: 7.8ms preprocess, 20.5ms inference, 1.7ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 19.8ms\n",
            "Speed: 7.2ms preprocess, 19.8ms inference, 1.7ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 19.8ms\n",
            "Speed: 8.6ms preprocess, 19.8ms inference, 2.5ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 19.9ms\n",
            "Speed: 4.8ms preprocess, 19.9ms inference, 2.1ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 19.9ms\n",
            "Speed: 6.4ms preprocess, 19.9ms inference, 4.6ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 19.8ms\n",
            "Speed: 4.8ms preprocess, 19.8ms inference, 2.1ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 19.8ms\n",
            "Speed: 4.5ms preprocess, 19.8ms inference, 1.8ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 19.8ms\n",
            "Speed: 4.6ms preprocess, 19.8ms inference, 2.4ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 19.8ms\n",
            "Speed: 4.7ms preprocess, 19.8ms inference, 2.2ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 19.8ms\n",
            "Speed: 6.9ms preprocess, 19.8ms inference, 2.9ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 20.0ms\n",
            "Speed: 9.2ms preprocess, 20.0ms inference, 1.6ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 19.8ms\n",
            "Speed: 6.4ms preprocess, 19.8ms inference, 2.7ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 21.7ms\n",
            "Speed: 9.0ms preprocess, 21.7ms inference, 2.6ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 19.9ms\n",
            "Speed: 4.5ms preprocess, 19.9ms inference, 1.7ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 19.8ms\n",
            "Speed: 10.7ms preprocess, 19.8ms inference, 2.0ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 27.6ms\n",
            "Speed: 4.4ms preprocess, 27.6ms inference, 3.2ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 29.9ms\n",
            "Speed: 5.0ms preprocess, 29.9ms inference, 4.5ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 26.1ms\n",
            "Speed: 5.2ms preprocess, 26.1ms inference, 3.8ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 26.0ms\n",
            "Speed: 6.7ms preprocess, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 20.5ms\n",
            "Speed: 7.1ms preprocess, 20.5ms inference, 2.4ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 24.8ms\n",
            "Speed: 11.8ms preprocess, 24.8ms inference, 2.1ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 20.9ms\n",
            "Speed: 7.3ms preprocess, 20.9ms inference, 4.4ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 24.8ms\n",
            "Speed: 5.5ms preprocess, 24.8ms inference, 2.0ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 21.5ms\n",
            "Speed: 7.0ms preprocess, 21.5ms inference, 2.1ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 21.5ms\n",
            "Speed: 11.5ms preprocess, 21.5ms inference, 2.4ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 21.9ms\n",
            "Speed: 4.6ms preprocess, 21.9ms inference, 1.9ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 608x640 1 person, 21.9ms\n",
            "Speed: 5.9ms preprocess, 21.9ms inference, 2.1ms postprocess per image at shape (1, 3, 608, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Makes/mahesh_make14.mp4\n",
            "\n",
            "0: 512x640 1 person, 24.8ms\n",
            "Speed: 3.8ms preprocess, 24.8ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 28.6ms\n",
            "Speed: 4.5ms preprocess, 28.6ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 30.5ms\n",
            "Speed: 3.8ms preprocess, 30.5ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 21.7ms\n",
            "Speed: 3.7ms preprocess, 21.7ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 22.0ms\n",
            "Speed: 6.4ms preprocess, 22.0ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 34.3ms\n",
            "Speed: 4.2ms preprocess, 34.3ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 23.3ms\n",
            "Speed: 7.3ms preprocess, 23.3ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 22.6ms\n",
            "Speed: 4.8ms preprocess, 22.6ms inference, 2.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 23.1ms\n",
            "Speed: 4.0ms preprocess, 23.1ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 23.4ms\n",
            "Speed: 4.3ms preprocess, 23.4ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 29.0ms\n",
            "Speed: 4.2ms preprocess, 29.0ms inference, 7.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 30.5ms\n",
            "Speed: 6.3ms preprocess, 30.5ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 36.9ms\n",
            "Speed: 3.9ms preprocess, 36.9ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 26.3ms\n",
            "Speed: 7.5ms preprocess, 26.3ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 32.5ms\n",
            "Speed: 4.0ms preprocess, 32.5ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 24.5ms\n",
            "Speed: 3.9ms preprocess, 24.5ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 24.5ms\n",
            "Speed: 4.5ms preprocess, 24.5ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 31.5ms\n",
            "Speed: 8.6ms preprocess, 31.5ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 30.3ms\n",
            "Speed: 10.6ms preprocess, 30.3ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 25.4ms\n",
            "Speed: 6.2ms preprocess, 25.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 25.8ms\n",
            "Speed: 4.1ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 40.2ms\n",
            "Speed: 3.8ms preprocess, 40.2ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 51.7ms\n",
            "Speed: 11.9ms preprocess, 51.7ms inference, 3.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 32.4ms\n",
            "Speed: 5.5ms preprocess, 32.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 29.5ms\n",
            "Speed: 8.7ms preprocess, 29.5ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 27.8ms\n",
            "Speed: 7.6ms preprocess, 27.8ms inference, 3.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 32.7ms\n",
            "Speed: 6.0ms preprocess, 32.7ms inference, 4.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 27.9ms\n",
            "Speed: 3.8ms preprocess, 27.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 28.5ms\n",
            "Speed: 6.1ms preprocess, 28.5ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 30.7ms\n",
            "Speed: 10.9ms preprocess, 30.7ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 32.3ms\n",
            "Speed: 3.9ms preprocess, 32.3ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 34.5ms\n",
            "Speed: 3.7ms preprocess, 34.5ms inference, 4.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 29.7ms\n",
            "Speed: 5.4ms preprocess, 29.7ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 32.0ms\n",
            "Speed: 3.6ms preprocess, 32.0ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 32.7ms\n",
            "Speed: 8.2ms preprocess, 32.7ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 29.8ms\n",
            "Speed: 3.9ms preprocess, 29.8ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 29.7ms\n",
            "Speed: 5.7ms preprocess, 29.7ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 29.6ms\n",
            "Speed: 8.8ms preprocess, 29.6ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 38.1ms\n",
            "Speed: 5.9ms preprocess, 38.1ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 30.2ms\n",
            "Speed: 3.8ms preprocess, 30.2ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 29.7ms\n",
            "Speed: 10.9ms preprocess, 29.7ms inference, 2.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 29.7ms\n",
            "Speed: 6.8ms preprocess, 29.7ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 36.7ms\n",
            "Speed: 11.5ms preprocess, 36.7ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 29.6ms\n",
            "Speed: 3.7ms preprocess, 29.6ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 29.9ms\n",
            "Speed: 11.5ms preprocess, 29.9ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 34.8ms\n",
            "Speed: 3.7ms preprocess, 34.8ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 29.7ms\n",
            "Speed: 3.9ms preprocess, 29.7ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 29.7ms\n",
            "Speed: 4.4ms preprocess, 29.7ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 29.7ms\n",
            "Speed: 9.0ms preprocess, 29.7ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 29.7ms\n",
            "Speed: 12.7ms preprocess, 29.7ms inference, 2.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 33.0ms\n",
            "Speed: 3.8ms preprocess, 33.0ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 29.6ms\n",
            "Speed: 3.6ms preprocess, 29.6ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 29.7ms\n",
            "Speed: 4.9ms preprocess, 29.7ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 27.1ms\n",
            "Speed: 5.8ms preprocess, 27.1ms inference, 2.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 30.4ms\n",
            "Speed: 4.9ms preprocess, 30.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 41.4ms\n",
            "Speed: 4.4ms preprocess, 41.4ms inference, 14.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 53.5ms\n",
            "Speed: 9.0ms preprocess, 53.5ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 persons, 41.9ms\n",
            "Speed: 15.9ms preprocess, 41.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 persons, 53.2ms\n",
            "Speed: 20.6ms preprocess, 53.2ms inference, 5.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 persons, 35.0ms\n",
            "Speed: 10.4ms preprocess, 35.0ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 persons, 29.1ms\n",
            "Speed: 3.7ms preprocess, 29.1ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Makes/mahesh_make15.mp4\n",
            "\n",
            "0: 384x640 1 person, 25.0ms\n",
            "Speed: 3.7ms preprocess, 25.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 23.8ms\n",
            "Speed: 7.3ms preprocess, 23.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23.8ms\n",
            "Speed: 3.3ms preprocess, 23.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 24.0ms\n",
            "Speed: 2.7ms preprocess, 24.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.9ms\n",
            "Speed: 2.8ms preprocess, 20.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.3ms\n",
            "Speed: 2.7ms preprocess, 20.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.3ms\n",
            "Speed: 4.2ms preprocess, 20.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.3ms\n",
            "Speed: 2.6ms preprocess, 20.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.3ms\n",
            "Speed: 2.8ms preprocess, 20.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.5ms\n",
            "Speed: 2.6ms preprocess, 16.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.4ms\n",
            "Speed: 2.7ms preprocess, 16.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16.5ms\n",
            "Speed: 2.5ms preprocess, 16.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.4ms\n",
            "Speed: 2.7ms preprocess, 16.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.2ms\n",
            "Speed: 2.9ms preprocess, 18.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.3ms\n",
            "Speed: 2.9ms preprocess, 16.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.7ms\n",
            "Speed: 2.7ms preprocess, 20.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.9ms\n",
            "Speed: 2.9ms preprocess, 17.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.8ms\n",
            "Speed: 2.7ms preprocess, 17.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.1ms\n",
            "Speed: 4.6ms preprocess, 16.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.8ms\n",
            "Speed: 2.6ms preprocess, 17.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.8ms\n",
            "Speed: 2.7ms preprocess, 14.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.0ms\n",
            "Speed: 2.8ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.1ms\n",
            "Speed: 3.6ms preprocess, 17.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.3ms\n",
            "Speed: 2.9ms preprocess, 14.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 2.4ms preprocess, 14.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.1ms\n",
            "Speed: 3.1ms preprocess, 19.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.0ms\n",
            "Speed: 3.2ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.5ms\n",
            "Speed: 2.9ms preprocess, 17.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.3ms\n",
            "Speed: 3.5ms preprocess, 20.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.2ms\n",
            "Speed: 2.8ms preprocess, 20.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.3ms\n",
            "Speed: 3.6ms preprocess, 19.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 3.5ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23.4ms\n",
            "Speed: 3.0ms preprocess, 23.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.5ms\n",
            "Speed: 5.3ms preprocess, 16.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.4ms\n",
            "Speed: 6.0ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.4ms\n",
            "Speed: 3.2ms preprocess, 13.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.8ms\n",
            "Speed: 3.1ms preprocess, 14.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.4ms\n",
            "Speed: 2.7ms preprocess, 14.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.3ms\n",
            "Speed: 2.7ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.5ms\n",
            "Speed: 4.0ms preprocess, 17.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.4ms\n",
            "Speed: 2.7ms preprocess, 15.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 2.8ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.5ms\n",
            "Speed: 5.0ms preprocess, 13.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.3ms\n",
            "Speed: 2.9ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 29.7ms\n",
            "Speed: 3.2ms preprocess, 29.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.4ms\n",
            "Speed: 3.7ms preprocess, 17.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.2ms\n",
            "Speed: 2.6ms preprocess, 16.2ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.0ms\n",
            "Speed: 5.8ms preprocess, 15.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.1ms\n",
            "Speed: 4.8ms preprocess, 16.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.2ms\n",
            "Speed: 3.5ms preprocess, 16.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.3ms\n",
            "Speed: 2.9ms preprocess, 13.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 3.8ms preprocess, 14.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.9ms\n",
            "Speed: 6.6ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.8ms\n",
            "Speed: 4.7ms preprocess, 14.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.4ms\n",
            "Speed: 3.9ms preprocess, 13.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.6ms\n",
            "Speed: 2.9ms preprocess, 17.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.4ms\n",
            "Speed: 3.2ms preprocess, 13.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.5ms\n",
            "Speed: 2.6ms preprocess, 17.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.9ms\n",
            "Speed: 4.5ms preprocess, 13.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 2.8ms preprocess, 15.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.3ms\n",
            "Speed: 2.9ms preprocess, 13.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.4ms\n",
            "Speed: 4.1ms preprocess, 13.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.2ms\n",
            "Speed: 3.3ms preprocess, 16.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.0ms\n",
            "Speed: 3.1ms preprocess, 22.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.4ms\n",
            "Speed: 3.1ms preprocess, 17.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.4ms\n",
            "Speed: 3.1ms preprocess, 13.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.9ms\n",
            "Speed: 2.9ms preprocess, 16.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.3ms\n",
            "Speed: 2.7ms preprocess, 13.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Makes/mahesh_make16.mp4\n",
            "\n",
            "0: 384x640 1 person, 16.1ms\n",
            "Speed: 4.0ms preprocess, 16.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.9ms\n",
            "Speed: 5.0ms preprocess, 15.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.6ms\n",
            "Speed: 2.8ms preprocess, 16.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.1ms\n",
            "Speed: 2.7ms preprocess, 19.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.7ms\n",
            "Speed: 2.7ms preprocess, 16.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.6ms\n",
            "Speed: 5.7ms preprocess, 16.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.0ms\n",
            "Speed: 2.9ms preprocess, 18.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.1ms\n",
            "Speed: 2.7ms preprocess, 16.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 3.0ms preprocess, 16.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.3ms\n",
            "Speed: 2.8ms preprocess, 17.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.3ms\n",
            "Speed: 2.7ms preprocess, 21.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.0ms\n",
            "Speed: 2.7ms preprocess, 21.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.5ms\n",
            "Speed: 6.6ms preprocess, 15.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.7ms\n",
            "Speed: 3.1ms preprocess, 15.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.8ms\n",
            "Speed: 7.9ms preprocess, 15.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.3ms\n",
            "Speed: 2.6ms preprocess, 15.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 2.8ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.4ms\n",
            "Speed: 9.1ms preprocess, 21.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.3ms\n",
            "Speed: 2.7ms preprocess, 18.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.9ms\n",
            "Speed: 2.6ms preprocess, 16.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 2.8ms preprocess, 15.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.6ms\n",
            "Speed: 2.7ms preprocess, 20.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 2.7ms preprocess, 15.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 2.9ms preprocess, 15.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 2.8ms preprocess, 15.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 4.1ms preprocess, 15.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 3.2ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 3.0ms preprocess, 15.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.1ms\n",
            "Speed: 2.6ms preprocess, 16.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 2.9ms preprocess, 14.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 2.7ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.6ms\n",
            "Speed: 4.2ms preprocess, 15.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 4.8ms preprocess, 14.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.6ms\n",
            "Speed: 3.0ms preprocess, 18.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.6ms\n",
            "Speed: 3.8ms preprocess, 15.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.0ms\n",
            "Speed: 2.7ms preprocess, 15.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 2.9ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 2.9ms preprocess, 14.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Makes/mahesh_make17.mp4\n",
            "\n",
            "0: 384x640 1 person, 14.7ms\n",
            "Speed: 3.8ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.4ms\n",
            "Speed: 2.8ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.4ms\n",
            "Speed: 3.0ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.0ms\n",
            "Speed: 3.2ms preprocess, 17.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.4ms\n",
            "Speed: 2.9ms preprocess, 22.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.1ms\n",
            "Speed: 5.3ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.6ms\n",
            "Speed: 2.8ms preprocess, 19.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.3ms\n",
            "Speed: 2.7ms preprocess, 17.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.6ms\n",
            "Speed: 2.8ms preprocess, 14.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 3.1ms preprocess, 14.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.1ms\n",
            "Speed: 2.8ms preprocess, 17.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 4.7ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.3ms\n",
            "Speed: 2.7ms preprocess, 14.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.6ms\n",
            "Speed: 2.6ms preprocess, 15.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.6ms\n",
            "Speed: 2.7ms preprocess, 22.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.4ms\n",
            "Speed: 2.8ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.0ms\n",
            "Speed: 2.7ms preprocess, 14.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.6ms\n",
            "Speed: 4.3ms preprocess, 13.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 3.0ms preprocess, 14.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.1ms\n",
            "Speed: 2.8ms preprocess, 14.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.0ms\n",
            "Speed: 4.6ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.4ms\n",
            "Speed: 2.9ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23.3ms\n",
            "Speed: 2.7ms preprocess, 23.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.9ms\n",
            "Speed: 3.2ms preprocess, 15.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.1ms\n",
            "Speed: 2.7ms preprocess, 16.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.4ms\n",
            "Speed: 3.1ms preprocess, 17.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.4ms\n",
            "Speed: 3.1ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.9ms\n",
            "Speed: 2.7ms preprocess, 20.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.7ms\n",
            "Speed: 2.8ms preprocess, 17.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.4ms\n",
            "Speed: 3.6ms preprocess, 13.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14.9ms\n",
            "Speed: 2.9ms preprocess, 14.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.1ms\n",
            "Speed: 3.7ms preprocess, 18.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.9ms\n",
            "Speed: 2.7ms preprocess, 13.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.2ms\n",
            "Speed: 9.0ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 3.3ms preprocess, 14.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 3.3ms preprocess, 15.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.9ms\n",
            "Speed: 2.9ms preprocess, 13.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.3ms\n",
            "Speed: 3.1ms preprocess, 17.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.7ms\n",
            "Speed: 3.5ms preprocess, 13.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.4ms\n",
            "Speed: 2.6ms preprocess, 15.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.6ms\n",
            "Speed: 2.9ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.9ms\n",
            "Speed: 2.8ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.0ms\n",
            "Speed: 2.9ms preprocess, 15.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.7ms\n",
            "Speed: 2.7ms preprocess, 15.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.5ms\n",
            "Speed: 2.8ms preprocess, 16.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.8ms\n",
            "Speed: 4.0ms preprocess, 22.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 3.0ms preprocess, 13.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.3ms\n",
            "Speed: 2.8ms preprocess, 13.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.6ms\n",
            "Speed: 2.9ms preprocess, 13.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.7ms\n",
            "Speed: 3.3ms preprocess, 18.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 2.7ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.5ms\n",
            "Speed: 2.9ms preprocess, 21.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.0ms\n",
            "Speed: 3.2ms preprocess, 17.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.9ms\n",
            "Speed: 2.8ms preprocess, 14.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.5ms\n",
            "Speed: 2.7ms preprocess, 18.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.4ms\n",
            "Speed: 3.8ms preprocess, 16.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.7ms\n",
            "Speed: 2.7ms preprocess, 18.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.3ms\n",
            "Speed: 2.8ms preprocess, 15.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.3ms\n",
            "Speed: 2.8ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.9ms\n",
            "Speed: 2.8ms preprocess, 18.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.6ms\n",
            "Speed: 2.7ms preprocess, 14.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.2ms\n",
            "Speed: 2.6ms preprocess, 20.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.3ms\n",
            "Speed: 4.3ms preprocess, 13.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.2ms\n",
            "Speed: 3.1ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Makes/mahesh_make18.mp4\n",
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 3.7ms preprocess, 14.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.6ms\n",
            "Speed: 2.7ms preprocess, 16.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.2ms\n",
            "Speed: 2.9ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 31.4ms\n",
            "Speed: 4.0ms preprocess, 31.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 24.8ms\n",
            "Speed: 2.8ms preprocess, 24.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.3ms\n",
            "Speed: 2.9ms preprocess, 13.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.3ms\n",
            "Speed: 2.7ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.1ms\n",
            "Speed: 2.7ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.9ms\n",
            "Speed: 2.5ms preprocess, 19.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 3.1ms preprocess, 15.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 2.6ms preprocess, 13.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.0ms\n",
            "Speed: 2.8ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.1ms\n",
            "Speed: 2.8ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.4ms\n",
            "Speed: 2.7ms preprocess, 21.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.0ms\n",
            "Speed: 2.9ms preprocess, 15.0ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.2ms\n",
            "Speed: 4.4ms preprocess, 13.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.1ms\n",
            "Speed: 2.8ms preprocess, 13.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.4ms\n",
            "Speed: 3.1ms preprocess, 13.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.6ms\n",
            "Speed: 9.0ms preprocess, 20.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 34.8ms\n",
            "Speed: 2.5ms preprocess, 34.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.2ms\n",
            "Speed: 3.2ms preprocess, 19.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.2ms\n",
            "Speed: 3.4ms preprocess, 19.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.0ms\n",
            "Speed: 7.8ms preprocess, 18.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.1ms\n",
            "Speed: 3.0ms preprocess, 16.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.0ms\n",
            "Speed: 2.7ms preprocess, 19.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.0ms\n",
            "Speed: 3.8ms preprocess, 20.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 25.1ms\n",
            "Speed: 4.8ms preprocess, 25.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.0ms\n",
            "Speed: 5.1ms preprocess, 20.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.4ms\n",
            "Speed: 4.6ms preprocess, 15.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 30.9ms\n",
            "Speed: 9.2ms preprocess, 30.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.0ms\n",
            "Speed: 2.7ms preprocess, 19.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.4ms\n",
            "Speed: 2.8ms preprocess, 18.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23.0ms\n",
            "Speed: 2.7ms preprocess, 23.0ms inference, 11.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.5ms\n",
            "Speed: 2.8ms preprocess, 17.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.8ms\n",
            "Speed: 5.1ms preprocess, 20.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.7ms\n",
            "Speed: 3.5ms preprocess, 14.7ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.6ms\n",
            "Speed: 2.7ms preprocess, 16.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.9ms\n",
            "Speed: 2.7ms preprocess, 20.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23.6ms\n",
            "Speed: 2.7ms preprocess, 23.6ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.8ms\n",
            "Speed: 4.1ms preprocess, 14.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.2ms\n",
            "Speed: 5.2ms preprocess, 19.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.6ms\n",
            "Speed: 2.8ms preprocess, 17.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 4.7ms preprocess, 15.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.7ms\n",
            "Speed: 3.8ms preprocess, 14.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.1ms\n",
            "Speed: 5.7ms preprocess, 16.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.3ms\n",
            "Speed: 3.8ms preprocess, 17.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.4ms\n",
            "Speed: 5.7ms preprocess, 15.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.5ms\n",
            "Speed: 2.8ms preprocess, 16.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.8ms\n",
            "Speed: 6.4ms preprocess, 14.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.1ms\n",
            "Speed: 3.3ms preprocess, 16.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.4ms\n",
            "Speed: 5.3ms preprocess, 18.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.2ms\n",
            "Speed: 2.9ms preprocess, 16.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.8ms\n",
            "Speed: 4.3ms preprocess, 15.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.1ms\n",
            "Speed: 3.1ms preprocess, 16.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 7.4ms preprocess, 15.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.2ms\n",
            "Speed: 2.9ms preprocess, 18.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.9ms\n",
            "Speed: 6.5ms preprocess, 14.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 25.7ms\n",
            "Speed: 3.0ms preprocess, 25.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.4ms\n",
            "Speed: 2.9ms preprocess, 15.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23.9ms\n",
            "Speed: 3.1ms preprocess, 23.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.4ms\n",
            "Speed: 3.3ms preprocess, 17.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Makes/mahesh_make19.mp4\n",
            "\n",
            "0: 384x640 1 person, 18.4ms\n",
            "Speed: 8.3ms preprocess, 18.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 27.0ms\n",
            "Speed: 6.8ms preprocess, 27.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.5ms\n",
            "Speed: 2.8ms preprocess, 19.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.3ms\n",
            "Speed: 4.2ms preprocess, 18.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23.8ms\n",
            "Speed: 4.4ms preprocess, 23.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23.2ms\n",
            "Speed: 8.3ms preprocess, 23.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.3ms\n",
            "Speed: 4.7ms preprocess, 18.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23.3ms\n",
            "Speed: 2.9ms preprocess, 23.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.5ms\n",
            "Speed: 6.4ms preprocess, 18.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.5ms\n",
            "Speed: 5.5ms preprocess, 18.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.4ms\n",
            "Speed: 9.4ms preprocess, 20.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.0ms\n",
            "Speed: 3.0ms preprocess, 19.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 19.0ms\n",
            "Speed: 3.5ms preprocess, 19.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.2ms\n",
            "Speed: 7.8ms preprocess, 20.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.2ms\n",
            "Speed: 3.9ms preprocess, 21.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.5ms\n",
            "Speed: 5.8ms preprocess, 18.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.4ms\n",
            "Speed: 3.0ms preprocess, 19.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.0ms\n",
            "Speed: 5.9ms preprocess, 21.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.5ms\n",
            "Speed: 4.5ms preprocess, 18.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.9ms\n",
            "Speed: 7.5ms preprocess, 19.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.4ms\n",
            "Speed: 2.7ms preprocess, 18.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.9ms\n",
            "Speed: 2.7ms preprocess, 20.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.3ms\n",
            "Speed: 3.5ms preprocess, 17.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.4ms\n",
            "Speed: 6.4ms preprocess, 17.4ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.7ms\n",
            "Speed: 8.8ms preprocess, 21.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.4ms\n",
            "Speed: 6.7ms preprocess, 18.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.3ms\n",
            "Speed: 3.0ms preprocess, 17.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.6ms\n",
            "Speed: 6.3ms preprocess, 18.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.4ms\n",
            "Speed: 3.4ms preprocess, 18.4ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 25.8ms\n",
            "Speed: 2.9ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.7ms\n",
            "Speed: 2.9ms preprocess, 19.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.9ms\n",
            "Speed: 7.5ms preprocess, 17.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.8ms\n",
            "Speed: 2.8ms preprocess, 18.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 17.4ms\n",
            "Speed: 9.2ms preprocess, 17.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.3ms\n",
            "Speed: 2.8ms preprocess, 17.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.1ms\n",
            "Speed: 7.5ms preprocess, 21.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.4ms\n",
            "Speed: 5.4ms preprocess, 17.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.0ms\n",
            "Speed: 4.3ms preprocess, 21.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.9ms\n",
            "Speed: 2.8ms preprocess, 16.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.9ms\n",
            "Speed: 2.9ms preprocess, 20.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.0ms\n",
            "Speed: 3.2ms preprocess, 22.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.8ms\n",
            "Speed: 3.0ms preprocess, 20.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.9ms\n",
            "Speed: 7.3ms preprocess, 16.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.8ms\n",
            "Speed: 2.9ms preprocess, 16.8ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.0ms\n",
            "Speed: 3.5ms preprocess, 26.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.9ms\n",
            "Speed: 6.9ms preprocess, 16.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.9ms\n",
            "Speed: 5.1ms preprocess, 16.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.1ms\n",
            "Speed: 2.7ms preprocess, 20.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.9ms\n",
            "Speed: 2.8ms preprocess, 16.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.1ms\n",
            "Speed: 4.5ms preprocess, 17.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.5ms\n",
            "Speed: 4.1ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.3ms\n",
            "Speed: 4.9ms preprocess, 18.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.4ms\n",
            "Speed: 2.7ms preprocess, 18.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.9ms\n",
            "Speed: 2.6ms preprocess, 16.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.9ms\n",
            "Speed: 2.8ms preprocess, 16.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.7ms\n",
            "Speed: 2.7ms preprocess, 19.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.9ms\n",
            "Speed: 8.7ms preprocess, 16.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.9ms\n",
            "Speed: 2.7ms preprocess, 16.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.3ms\n",
            "Speed: 2.8ms preprocess, 20.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.9ms\n",
            "Speed: 3.5ms preprocess, 16.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.8ms\n",
            "Speed: 2.5ms preprocess, 16.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.6ms\n",
            "Speed: 3.1ms preprocess, 19.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.9ms\n",
            "Speed: 2.6ms preprocess, 16.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.3ms\n",
            "Speed: 8.1ms preprocess, 16.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.5ms\n",
            "Speed: 2.8ms preprocess, 21.5ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.8ms\n",
            "Speed: 4.8ms preprocess, 19.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.2ms\n",
            "Speed: 3.0ms preprocess, 19.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 2.9ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Makes/mahesh_make20.mp4\n",
            "\n",
            "0: 384x640 1 person, 17.6ms\n",
            "Speed: 4.3ms preprocess, 17.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 29.6ms\n",
            "Speed: 2.7ms preprocess, 29.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 40.2ms\n",
            "Speed: 2.7ms preprocess, 40.2ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.2ms\n",
            "Speed: 6.8ms preprocess, 20.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.4ms\n",
            "Speed: 2.7ms preprocess, 17.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 24.7ms\n",
            "Speed: 3.1ms preprocess, 24.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.6ms\n",
            "Speed: 2.9ms preprocess, 18.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.5ms\n",
            "Speed: 3.9ms preprocess, 21.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.5ms\n",
            "Speed: 2.8ms preprocess, 20.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.4ms\n",
            "Speed: 2.7ms preprocess, 22.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.4ms\n",
            "Speed: 2.6ms preprocess, 21.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 2.9ms preprocess, 16.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.5ms\n",
            "Speed: 4.1ms preprocess, 20.5ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.7ms\n",
            "Speed: 2.7ms preprocess, 20.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.3ms\n",
            "Speed: 4.9ms preprocess, 18.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.5ms\n",
            "Speed: 5.4ms preprocess, 18.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.3ms\n",
            "Speed: 5.8ms preprocess, 17.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 24.0ms\n",
            "Speed: 3.4ms preprocess, 24.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.9ms\n",
            "Speed: 3.0ms preprocess, 15.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.0ms\n",
            "Speed: 3.8ms preprocess, 18.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.5ms\n",
            "Speed: 3.1ms preprocess, 16.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 3.3ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23.4ms\n",
            "Speed: 2.7ms preprocess, 23.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.8ms\n",
            "Speed: 3.3ms preprocess, 16.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.2ms\n",
            "Speed: 2.7ms preprocess, 17.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.6ms\n",
            "Speed: 2.7ms preprocess, 15.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.0ms\n",
            "Speed: 2.8ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 3.1ms preprocess, 16.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.9ms\n",
            "Speed: 2.9ms preprocess, 14.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 3.0ms preprocess, 15.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.8ms\n",
            "Speed: 2.9ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 2.9ms preprocess, 14.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.7ms\n",
            "Speed: 2.9ms preprocess, 20.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14.6ms\n",
            "Speed: 2.9ms preprocess, 14.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.4ms\n",
            "Speed: 3.1ms preprocess, 16.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.3ms\n",
            "Speed: 2.8ms preprocess, 14.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.1ms\n",
            "Speed: 2.9ms preprocess, 17.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 2.8ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Makes/mahesh_make21.mp4\n",
            "\n",
            "0: 384x640 1 person, 15.9ms\n",
            "Speed: 3.4ms preprocess, 15.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 3.6ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.7ms\n",
            "Speed: 4.0ms preprocess, 18.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.7ms\n",
            "Speed: 2.8ms preprocess, 20.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 5.0ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.1ms\n",
            "Speed: 2.7ms preprocess, 16.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.7ms\n",
            "Speed: 2.9ms preprocess, 18.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.3ms\n",
            "Speed: 2.7ms preprocess, 16.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.2ms\n",
            "Speed: 3.1ms preprocess, 16.2ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 25.8ms\n",
            "Speed: 3.5ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 5.2ms preprocess, 14.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.1ms\n",
            "Speed: 3.5ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.1ms\n",
            "Speed: 2.7ms preprocess, 21.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 2.8ms preprocess, 14.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 2.8ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 2.6ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.7ms\n",
            "Speed: 4.7ms preprocess, 14.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.3ms\n",
            "Speed: 4.3ms preprocess, 14.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.5ms\n",
            "Speed: 2.7ms preprocess, 16.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.7ms\n",
            "Speed: 4.5ms preprocess, 19.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 2.7ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.1ms\n",
            "Speed: 2.7ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.9ms\n",
            "Speed: 3.3ms preprocess, 14.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.9ms\n",
            "Speed: 5.0ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.0ms\n",
            "Speed: 2.7ms preprocess, 14.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.3ms\n",
            "Speed: 2.8ms preprocess, 19.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.5ms\n",
            "Speed: 2.7ms preprocess, 21.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.7ms\n",
            "Speed: 2.8ms preprocess, 16.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.6ms\n",
            "Speed: 2.8ms preprocess, 15.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.5ms\n",
            "Speed: 2.7ms preprocess, 17.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 2.8ms preprocess, 14.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.9ms\n",
            "Speed: 3.5ms preprocess, 14.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.0ms\n",
            "Speed: 2.9ms preprocess, 14.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.3ms\n",
            "Speed: 2.7ms preprocess, 14.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.9ms\n",
            "Speed: 2.7ms preprocess, 17.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.0ms\n",
            "Speed: 2.9ms preprocess, 19.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.3ms\n",
            "Speed: 3.0ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.5ms\n",
            "Speed: 2.9ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 2.9ms preprocess, 15.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.2ms\n",
            "Speed: 2.8ms preprocess, 15.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.9ms\n",
            "Speed: 2.8ms preprocess, 16.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 5.4ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.0ms\n",
            "Speed: 2.8ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.1ms\n",
            "Speed: 2.9ms preprocess, 18.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.1ms\n",
            "Speed: 2.7ms preprocess, 18.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.2ms\n",
            "Speed: 2.8ms preprocess, 15.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.1ms\n",
            "Speed: 6.4ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.9ms\n",
            "Speed: 2.7ms preprocess, 13.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.0ms\n",
            "Speed: 6.2ms preprocess, 17.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 3.0ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.9ms\n",
            "Speed: 2.9ms preprocess, 18.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 25.7ms\n",
            "Speed: 2.9ms preprocess, 25.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.3ms\n",
            "Speed: 2.8ms preprocess, 16.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.7ms\n",
            "Speed: 2.8ms preprocess, 13.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.9ms\n",
            "Speed: 2.6ms preprocess, 19.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.7ms\n",
            "Speed: 2.7ms preprocess, 14.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.7ms\n",
            "Speed: 2.7ms preprocess, 14.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 3.8ms preprocess, 13.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 2.6ms preprocess, 13.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.9ms\n",
            "Speed: 3.5ms preprocess, 13.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 2.7ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.9ms\n",
            "Speed: 2.8ms preprocess, 13.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 4.5ms preprocess, 13.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 4.5ms preprocess, 13.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.0ms\n",
            "Speed: 2.8ms preprocess, 14.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Makes/mahesh_make22.mp4\n",
            "\n",
            "0: 384x640 1 person, 14.1ms\n",
            "Speed: 2.8ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 25.9ms\n",
            "Speed: 2.7ms preprocess, 25.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 2.7ms preprocess, 13.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.6ms\n",
            "Speed: 2.5ms preprocess, 19.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.4ms\n",
            "Speed: 2.6ms preprocess, 19.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.0ms\n",
            "Speed: 2.5ms preprocess, 18.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 6.5ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 4.7ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.7ms\n",
            "Speed: 2.9ms preprocess, 13.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 2.8ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.9ms\n",
            "Speed: 2.7ms preprocess, 16.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.4ms\n",
            "Speed: 2.9ms preprocess, 15.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 5.0ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.5ms\n",
            "Speed: 2.7ms preprocess, 15.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.7ms\n",
            "Speed: 3.7ms preprocess, 13.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.3ms\n",
            "Speed: 2.7ms preprocess, 15.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.6ms\n",
            "Speed: 2.8ms preprocess, 13.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.4ms\n",
            "Speed: 2.8ms preprocess, 16.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.6ms\n",
            "Speed: 3.2ms preprocess, 17.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.6ms\n",
            "Speed: 2.3ms preprocess, 13.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.0ms\n",
            "Speed: 2.7ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 6.3ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.6ms\n",
            "Speed: 2.9ms preprocess, 13.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 2.8ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.3ms\n",
            "Speed: 2.7ms preprocess, 17.3ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.7ms\n",
            "Speed: 3.2ms preprocess, 13.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 2.9ms preprocess, 15.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.7ms\n",
            "Speed: 4.3ms preprocess, 14.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.0ms\n",
            "Speed: 2.8ms preprocess, 17.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.8ms\n",
            "Speed: 3.1ms preprocess, 15.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.7ms\n",
            "Speed: 3.4ms preprocess, 15.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 2.8ms preprocess, 16.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.5ms\n",
            "Speed: 2.9ms preprocess, 15.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.9ms\n",
            "Speed: 6.4ms preprocess, 18.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.7ms\n",
            "Speed: 2.7ms preprocess, 17.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 2.8ms preprocess, 15.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.1ms\n",
            "Speed: 2.7ms preprocess, 17.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.3ms\n",
            "Speed: 2.7ms preprocess, 14.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.7ms\n",
            "Speed: 2.8ms preprocess, 13.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.6ms\n",
            "Speed: 2.7ms preprocess, 13.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.4ms\n",
            "Speed: 3.0ms preprocess, 16.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.4ms\n",
            "Speed: 2.7ms preprocess, 19.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.6ms\n",
            "Speed: 2.8ms preprocess, 13.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.9ms\n",
            "Speed: 2.8ms preprocess, 16.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.8ms\n",
            "Speed: 2.8ms preprocess, 14.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.7ms\n",
            "Speed: 3.0ms preprocess, 13.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Makes/mahesh_make23.mp4\n",
            "\n",
            "0: 384x640 1 person, 13.7ms\n",
            "Speed: 3.5ms preprocess, 13.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.6ms\n",
            "Speed: 4.5ms preprocess, 13.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.8ms\n",
            "Speed: 3.4ms preprocess, 19.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.4ms\n",
            "Speed: 3.1ms preprocess, 16.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.3ms\n",
            "Speed: 2.9ms preprocess, 16.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.3ms\n",
            "Speed: 2.8ms preprocess, 16.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.6ms\n",
            "Speed: 2.7ms preprocess, 18.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.7ms\n",
            "Speed: 2.9ms preprocess, 16.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.3ms\n",
            "Speed: 3.1ms preprocess, 16.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.1ms\n",
            "Speed: 2.8ms preprocess, 20.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.3ms\n",
            "Speed: 2.7ms preprocess, 16.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.8ms\n",
            "Speed: 4.0ms preprocess, 16.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.7ms\n",
            "Speed: 2.8ms preprocess, 15.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.7ms\n",
            "Speed: 3.1ms preprocess, 15.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.4ms\n",
            "Speed: 3.2ms preprocess, 14.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.4ms\n",
            "Speed: 3.0ms preprocess, 14.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 2.7ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.6ms\n",
            "Speed: 3.1ms preprocess, 19.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.1ms\n",
            "Speed: 5.0ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.7ms\n",
            "Speed: 2.9ms preprocess, 18.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.0ms\n",
            "Speed: 5.8ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.5ms\n",
            "Speed: 3.1ms preprocess, 16.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 2.9ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.6ms\n",
            "Speed: 2.7ms preprocess, 19.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 2.7ms preprocess, 14.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.3ms\n",
            "Speed: 2.9ms preprocess, 15.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.0ms\n",
            "Speed: 2.7ms preprocess, 18.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.6ms\n",
            "Speed: 3.0ms preprocess, 15.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 2.9ms preprocess, 16.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 3.5ms preprocess, 14.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 2.6ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.6ms\n",
            "Speed: 3.6ms preprocess, 15.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.1ms\n",
            "Speed: 2.8ms preprocess, 14.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.3ms\n",
            "Speed: 5.3ms preprocess, 19.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 3.6ms preprocess, 14.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 3.0ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.5ms\n",
            "Speed: 2.8ms preprocess, 19.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.6ms\n",
            "Speed: 2.6ms preprocess, 17.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.9ms\n",
            "Speed: 2.7ms preprocess, 14.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.3ms\n",
            "Speed: 3.0ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.4ms\n",
            "Speed: 4.6ms preprocess, 15.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 2.9ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.1ms\n",
            "Speed: 6.6ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 5.1ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.0ms\n",
            "Speed: 2.6ms preprocess, 15.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.9ms\n",
            "Speed: 2.8ms preprocess, 15.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.6ms\n",
            "Speed: 5.8ms preprocess, 16.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 2.7ms preprocess, 14.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.0ms\n",
            "Speed: 3.2ms preprocess, 17.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.5ms\n",
            "Speed: 2.8ms preprocess, 16.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Makes/mahesh_make24.mp4\n",
            "\n",
            "0: 384x640 1 person, 13.9ms\n",
            "Speed: 5.6ms preprocess, 13.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.6ms\n",
            "Speed: 7.9ms preprocess, 17.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 24.4ms\n",
            "Speed: 2.9ms preprocess, 24.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.4ms\n",
            "Speed: 2.9ms preprocess, 15.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 3.0ms preprocess, 13.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 2.9ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 2.8ms preprocess, 14.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.3ms\n",
            "Speed: 2.9ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 2.9ms preprocess, 14.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.1ms\n",
            "Speed: 3.0ms preprocess, 18.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.9ms\n",
            "Speed: 3.3ms preprocess, 13.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.6ms\n",
            "Speed: 4.9ms preprocess, 14.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.4ms\n",
            "Speed: 3.3ms preprocess, 15.4ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 2.8ms preprocess, 14.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 3.1ms preprocess, 13.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.3ms\n",
            "Speed: 3.0ms preprocess, 17.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.8ms\n",
            "Speed: 2.8ms preprocess, 17.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23.2ms\n",
            "Speed: 3.4ms preprocess, 23.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.6ms\n",
            "Speed: 3.0ms preprocess, 16.6ms inference, 8.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.5ms\n",
            "Speed: 2.8ms preprocess, 18.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 2.7ms preprocess, 13.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.8ms\n",
            "Speed: 2.9ms preprocess, 16.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.9ms\n",
            "Speed: 3.1ms preprocess, 14.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 3.7ms preprocess, 13.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.6ms\n",
            "Speed: 2.8ms preprocess, 15.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.1ms\n",
            "Speed: 2.8ms preprocess, 18.1ms inference, 7.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.5ms\n",
            "Speed: 3.0ms preprocess, 17.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 3.2ms preprocess, 13.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.0ms\n",
            "Speed: 5.4ms preprocess, 14.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.6ms\n",
            "Speed: 2.7ms preprocess, 14.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.2ms\n",
            "Speed: 4.5ms preprocess, 15.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.9ms\n",
            "Speed: 3.0ms preprocess, 14.9ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.0ms\n",
            "Speed: 4.1ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.0ms\n",
            "Speed: 4.8ms preprocess, 15.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.7ms\n",
            "Speed: 2.8ms preprocess, 17.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.9ms\n",
            "Speed: 4.0ms preprocess, 15.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 2.8ms preprocess, 15.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.1ms\n",
            "Speed: 2.8ms preprocess, 17.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Makes/mahesh_make25.mp4\n",
            "\n",
            "0: 384x640 1 person, 16.9ms\n",
            "Speed: 3.2ms preprocess, 16.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 25.0ms\n",
            "Speed: 3.0ms preprocess, 25.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.1ms\n",
            "Speed: 2.8ms preprocess, 18.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 55.5ms\n",
            "Speed: 3.1ms preprocess, 55.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.3ms\n",
            "Speed: 3.0ms preprocess, 20.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.3ms\n",
            "Speed: 2.9ms preprocess, 18.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.7ms\n",
            "Speed: 2.8ms preprocess, 18.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23.4ms\n",
            "Speed: 2.7ms preprocess, 23.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.3ms\n",
            "Speed: 6.9ms preprocess, 18.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.1ms\n",
            "Speed: 4.9ms preprocess, 17.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.7ms\n",
            "Speed: 3.9ms preprocess, 17.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.2ms\n",
            "Speed: 5.4ms preprocess, 17.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.1ms\n",
            "Speed: 2.8ms preprocess, 17.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.1ms\n",
            "Speed: 8.1ms preprocess, 17.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.5ms\n",
            "Speed: 4.5ms preprocess, 18.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.0ms\n",
            "Speed: 2.9ms preprocess, 19.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.1ms\n",
            "Speed: 6.5ms preprocess, 19.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 24.0ms\n",
            "Speed: 6.0ms preprocess, 24.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.6ms\n",
            "Speed: 3.1ms preprocess, 21.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.0ms\n",
            "Speed: 3.0ms preprocess, 17.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.5ms\n",
            "Speed: 3.0ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.1ms\n",
            "Speed: 5.5ms preprocess, 17.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.4ms\n",
            "Speed: 8.8ms preprocess, 18.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.0ms\n",
            "Speed: 2.7ms preprocess, 17.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 24.1ms\n",
            "Speed: 8.0ms preprocess, 24.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.1ms\n",
            "Speed: 2.8ms preprocess, 17.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.3ms\n",
            "Speed: 6.5ms preprocess, 17.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.8ms\n",
            "Speed: 4.6ms preprocess, 21.8ms inference, 8.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23.8ms\n",
            "Speed: 7.4ms preprocess, 23.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.5ms\n",
            "Speed: 3.0ms preprocess, 18.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.1ms\n",
            "Speed: 6.7ms preprocess, 17.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.9ms\n",
            "Speed: 2.6ms preprocess, 17.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.1ms\n",
            "Speed: 4.8ms preprocess, 17.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.0ms\n",
            "Speed: 2.7ms preprocess, 17.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.8ms\n",
            "Speed: 9.5ms preprocess, 21.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.0ms\n",
            "Speed: 2.8ms preprocess, 17.0ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.3ms\n",
            "Speed: 2.7ms preprocess, 18.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.0ms\n",
            "Speed: 2.8ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.2ms\n",
            "Speed: 2.7ms preprocess, 26.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.1ms\n",
            "Speed: 2.9ms preprocess, 17.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 27.7ms\n",
            "Speed: 3.9ms preprocess, 27.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 30.6ms\n",
            "Speed: 7.5ms preprocess, 30.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.1ms\n",
            "Speed: 2.8ms preprocess, 17.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23.2ms\n",
            "Speed: 2.8ms preprocess, 23.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.1ms\n",
            "Speed: 2.7ms preprocess, 17.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.2ms\n",
            "Speed: 6.5ms preprocess, 17.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.4ms\n",
            "Speed: 2.5ms preprocess, 20.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.3ms\n",
            "Speed: 3.0ms preprocess, 21.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.3ms\n",
            "Speed: 5.9ms preprocess, 16.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.8ms\n",
            "Speed: 5.6ms preprocess, 16.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.1ms\n",
            "Speed: 2.7ms preprocess, 16.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.0ms\n",
            "Speed: 2.9ms preprocess, 21.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 2.8ms preprocess, 16.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.3ms\n",
            "Speed: 10.2ms preprocess, 18.3ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.1ms\n",
            "Speed: 2.7ms preprocess, 17.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.6ms\n",
            "Speed: 2.9ms preprocess, 21.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 25.3ms\n",
            "Speed: 2.8ms preprocess, 25.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 2.7ms preprocess, 16.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 30.1ms\n",
            "Speed: 2.7ms preprocess, 30.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 2.7ms preprocess, 16.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.5ms\n",
            "Speed: 2.7ms preprocess, 21.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 2.7ms preprocess, 16.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 2.8ms preprocess, 16.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.8ms\n",
            "Speed: 3.1ms preprocess, 17.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 24.7ms\n",
            "Speed: 4.4ms preprocess, 24.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.8ms\n",
            "Speed: 2.8ms preprocess, 18.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.9ms\n",
            "Speed: 2.7ms preprocess, 15.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Check for nulls"
      ],
      "metadata": {
        "id": "S1jorLQ2MtJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_xy_coord_fin.isna().sum()\n"
      ],
      "metadata": {
        "id": "wBpSW9XSqArJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a421e14d-b31f-4af8-c55c-87888cf975a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0               0\n",
              "1               0\n",
              "2               0\n",
              "3               0\n",
              "4               0\n",
              "5               0\n",
              "6               0\n",
              "7               0\n",
              "8               0\n",
              "9               0\n",
              "10              0\n",
              "11              0\n",
              "12              0\n",
              "13              0\n",
              "14              0\n",
              "15              0\n",
              "16              0\n",
              "17              0\n",
              "18              0\n",
              "19              0\n",
              "20              0\n",
              "21              0\n",
              "22              0\n",
              "23              0\n",
              "24              0\n",
              "25              0\n",
              "26              0\n",
              "27              0\n",
              "28              0\n",
              "29              0\n",
              "30              0\n",
              "31              0\n",
              "32              0\n",
              "33              0\n",
              "video           0\n",
              "label           0\n",
              "frame_number    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Use YOLOv8 model to extract joint coordinates for Misses"
      ],
      "metadata": {
        "id": "hVnSQ4o8O42t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shot_array=[]\n",
        "detection_keypoint = DetectKeypoint()\n",
        "df_xy_coord_fin_misses=pd.DataFrame()\n",
        "\n",
        "for i in video_list_miss:\n",
        "\n",
        "  # Load the YOLO model\n",
        "  model = YOLO('yolov8n-pose.pt')\n",
        "\n",
        "  # Open the video file\n",
        "  video_path = \"/content/drive/MyDrive/Shots/Shot Misses/\"+i\n",
        "  print(video_path)\n",
        "  cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "  # Create a video writer to save the output\n",
        "  writer = imageio.get_writer(\"output.mp4\", mode=\"I\")\n",
        "  joints_extracted_from_pose=34\n",
        "  xy_coord_array=np.zeros(joints_extracted_from_pose)\n",
        "  # Loop through the video frames\n",
        "  while cap.isOpened():\n",
        "      # Read a frame from the video\n",
        "      success, frame = cap.read()\n",
        "\n",
        "      if success:\n",
        "        start_time = time.time()\n",
        "        # Run pose detection on the frame\n",
        "\n",
        "        results = detection_keypoint(frame)\n",
        "        results_keypoint = detection_keypoint.get_xy_keypoint(results)\n",
        "\n",
        "        body_part_xy=np.array(results_keypoint)\n",
        "\n",
        "\n",
        "        xy_coord_array=np.vstack((xy_coord_array,body_part_xy))\n",
        "\n",
        "\n",
        "\n",
        "        # Break the loop if 'q' is pressed\n",
        "        if cv2.waitKey(1) & 0xFF ==ord('q'):\n",
        "            break\n",
        "      else:\n",
        "          # Break the loop if the end of the video is reached\n",
        "          break\n",
        "\n",
        "  # Release the video capture object and close the display window\n",
        "  df_xs_coord=pd.DataFrame(xy_coord_array)\n",
        "  df_xs_coord['video']=i\n",
        "  df_xs_coord['label']=0\n",
        "  df_xs_coord['frame_number']=range(1,len(xy_coord_array)+1)\n",
        "\n",
        "  df_xy_coord_fin_misses = pd.concat([df_xy_coord_fin_misses, df_xs_coord], ignore_index=True)\n",
        "  cap.release()\n",
        "  cv2.destroyAllWindows()\n",
        "\n",
        "  # Close the video writer\n",
        "  writer.close()\n"
      ],
      "metadata": {
        "id": "MRaB43m0qTZh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed983827-cc7d-4775-ed95-5feca911a6ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Shots/Shot Misses/1.mp4\n",
            "\n",
            "0: 480x640 1 person, 30.7ms\n",
            "Speed: 4.0ms preprocess, 30.7ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 29.5ms\n",
            "Speed: 3.8ms preprocess, 29.5ms inference, 9.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 29.4ms\n",
            "Speed: 6.8ms preprocess, 29.4ms inference, 6.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 34.6ms\n",
            "Speed: 5.7ms preprocess, 34.6ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 40.0ms\n",
            "Speed: 7.4ms preprocess, 40.0ms inference, 9.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 27.0ms\n",
            "Speed: 3.3ms preprocess, 27.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 27.1ms\n",
            "Speed: 4.1ms preprocess, 27.1ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 27.1ms\n",
            "Speed: 7.8ms preprocess, 27.1ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 27.1ms\n",
            "Speed: 6.1ms preprocess, 27.1ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 27.0ms\n",
            "Speed: 3.5ms preprocess, 27.0ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 27.1ms\n",
            "Speed: 3.7ms preprocess, 27.1ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 26.2ms\n",
            "Speed: 4.7ms preprocess, 26.2ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 26.0ms\n",
            "Speed: 3.6ms preprocess, 26.0ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 26.0ms\n",
            "Speed: 3.4ms preprocess, 26.0ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 25.5ms\n",
            "Speed: 3.5ms preprocess, 25.5ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 28.7ms\n",
            "Speed: 3.7ms preprocess, 28.7ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 21.7ms\n",
            "Speed: 3.7ms preprocess, 21.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 21.7ms\n",
            "Speed: 3.7ms preprocess, 21.7ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 21.7ms\n",
            "Speed: 3.7ms preprocess, 21.7ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 27.4ms\n",
            "Speed: 3.9ms preprocess, 27.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 21.7ms\n",
            "Speed: 3.6ms preprocess, 21.7ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 21.7ms\n",
            "Speed: 3.4ms preprocess, 21.7ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 21.7ms\n",
            "Speed: 3.7ms preprocess, 21.7ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 21.7ms\n",
            "Speed: 3.5ms preprocess, 21.7ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 21.7ms\n",
            "Speed: 4.2ms preprocess, 21.7ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 20.5ms\n",
            "Speed: 3.8ms preprocess, 20.5ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 20.6ms\n",
            "Speed: 3.8ms preprocess, 20.6ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 20.5ms\n",
            "Speed: 3.6ms preprocess, 20.5ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 20.5ms\n",
            "Speed: 3.9ms preprocess, 20.5ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 20.4ms\n",
            "Speed: 4.3ms preprocess, 20.4ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 20.5ms\n",
            "Speed: 3.4ms preprocess, 20.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 20.5ms\n",
            "Speed: 3.9ms preprocess, 20.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Misses/2.mp4\n",
            "\n",
            "0: 544x640 1 person, 26.3ms\n",
            "Speed: 4.5ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 25.7ms\n",
            "Speed: 3.9ms preprocess, 25.7ms inference, 2.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 25.2ms\n",
            "Speed: 4.0ms preprocess, 25.2ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 25.2ms\n",
            "Speed: 3.8ms preprocess, 25.2ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 27.3ms\n",
            "Speed: 6.0ms preprocess, 27.3ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 25.2ms\n",
            "Speed: 4.7ms preprocess, 25.2ms inference, 2.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 25.2ms\n",
            "Speed: 3.8ms preprocess, 25.2ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.8ms\n",
            "Speed: 3.8ms preprocess, 20.8ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.7ms\n",
            "Speed: 4.2ms preprocess, 20.7ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.5ms\n",
            "Speed: 3.8ms preprocess, 20.5ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.5ms\n",
            "Speed: 4.1ms preprocess, 20.5ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.5ms\n",
            "Speed: 3.8ms preprocess, 20.5ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.5ms\n",
            "Speed: 3.6ms preprocess, 20.5ms inference, 2.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.6ms\n",
            "Speed: 4.1ms preprocess, 20.6ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.5ms\n",
            "Speed: 3.7ms preprocess, 20.5ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.5ms\n",
            "Speed: 3.7ms preprocess, 20.5ms inference, 2.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.6ms\n",
            "Speed: 4.2ms preprocess, 20.6ms inference, 2.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.6ms\n",
            "Speed: 3.9ms preprocess, 20.6ms inference, 2.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.5ms\n",
            "Speed: 4.7ms preprocess, 20.5ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.9ms\n",
            "Speed: 4.5ms preprocess, 20.9ms inference, 5.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.5ms\n",
            "Speed: 4.0ms preprocess, 20.5ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.5ms\n",
            "Speed: 4.0ms preprocess, 20.5ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 22.6ms\n",
            "Speed: 4.6ms preprocess, 22.6ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.5ms\n",
            "Speed: 3.9ms preprocess, 20.5ms inference, 2.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.5ms\n",
            "Speed: 4.0ms preprocess, 20.5ms inference, 2.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.5ms\n",
            "Speed: 3.9ms preprocess, 20.5ms inference, 2.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.6ms\n",
            "Speed: 4.0ms preprocess, 20.6ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.5ms\n",
            "Speed: 3.9ms preprocess, 20.5ms inference, 2.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.7ms\n",
            "Speed: 3.9ms preprocess, 20.7ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.5ms\n",
            "Speed: 4.0ms preprocess, 20.5ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.5ms\n",
            "Speed: 4.0ms preprocess, 20.5ms inference, 2.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.5ms\n",
            "Speed: 4.0ms preprocess, 20.5ms inference, 2.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.7ms\n",
            "Speed: 4.4ms preprocess, 20.7ms inference, 2.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.0ms\n",
            "Speed: 4.0ms preprocess, 20.0ms inference, 4.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.0ms\n",
            "Speed: 4.0ms preprocess, 20.0ms inference, 2.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.9ms\n",
            "Speed: 4.0ms preprocess, 19.9ms inference, 2.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 27.3ms\n",
            "Speed: 4.1ms preprocess, 27.3ms inference, 2.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.7ms\n",
            "Speed: 4.0ms preprocess, 19.7ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.7ms\n",
            "Speed: 8.6ms preprocess, 19.7ms inference, 2.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.7ms\n",
            "Speed: 3.8ms preprocess, 19.7ms inference, 2.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.7ms\n",
            "Speed: 4.0ms preprocess, 19.7ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.6ms\n",
            "Speed: 3.8ms preprocess, 19.6ms inference, 2.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.7ms\n",
            "Speed: 3.9ms preprocess, 19.7ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.7ms\n",
            "Speed: 3.9ms preprocess, 19.7ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.7ms\n",
            "Speed: 3.9ms preprocess, 19.7ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.6ms\n",
            "Speed: 3.9ms preprocess, 19.6ms inference, 2.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.7ms\n",
            "Speed: 3.8ms preprocess, 19.7ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.7ms\n",
            "Speed: 3.8ms preprocess, 19.7ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.1ms\n",
            "Speed: 4.5ms preprocess, 20.1ms inference, 2.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.7ms\n",
            "Speed: 4.1ms preprocess, 19.7ms inference, 2.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 21.9ms\n",
            "Speed: 3.9ms preprocess, 21.9ms inference, 4.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.8ms\n",
            "Speed: 4.1ms preprocess, 19.8ms inference, 2.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.8ms\n",
            "Speed: 4.3ms preprocess, 19.8ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.7ms\n",
            "Speed: 4.1ms preprocess, 19.7ms inference, 2.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.7ms\n",
            "Speed: 4.5ms preprocess, 19.7ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.7ms\n",
            "Speed: 4.1ms preprocess, 19.7ms inference, 2.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.8ms\n",
            "Speed: 4.5ms preprocess, 19.8ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.6ms\n",
            "Speed: 4.1ms preprocess, 19.6ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 19.6ms\n",
            "Speed: 4.3ms preprocess, 19.6ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Misses/3.mp4\n",
            "\n",
            "0: 640x640 1 person, 26.2ms\n",
            "Speed: 5.7ms preprocess, 26.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 26.6ms\n",
            "Speed: 4.7ms preprocess, 26.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 26.6ms\n",
            "Speed: 4.4ms preprocess, 26.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 26.6ms\n",
            "Speed: 4.4ms preprocess, 26.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 26.7ms\n",
            "Speed: 5.2ms preprocess, 26.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 21.2ms\n",
            "Speed: 5.2ms preprocess, 21.2ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 21.0ms\n",
            "Speed: 7.5ms preprocess, 21.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 20.9ms\n",
            "Speed: 5.1ms preprocess, 20.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 35.2ms\n",
            "Speed: 4.6ms preprocess, 35.2ms inference, 6.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 56.9ms\n",
            "Speed: 11.7ms preprocess, 56.9ms inference, 14.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 53.6ms\n",
            "Speed: 5.0ms preprocess, 53.6ms inference, 19.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 30.1ms\n",
            "Speed: 5.1ms preprocess, 30.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 21.4ms\n",
            "Speed: 5.5ms preprocess, 21.4ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 20.9ms\n",
            "Speed: 5.6ms preprocess, 20.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 20.9ms\n",
            "Speed: 5.1ms preprocess, 20.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 21.5ms\n",
            "Speed: 4.8ms preprocess, 21.5ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 21.0ms\n",
            "Speed: 4.4ms preprocess, 21.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 20.9ms\n",
            "Speed: 5.3ms preprocess, 20.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 20.9ms\n",
            "Speed: 5.7ms preprocess, 20.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 20.2ms\n",
            "Speed: 4.3ms preprocess, 20.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 20.2ms\n",
            "Speed: 4.9ms preprocess, 20.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 20.3ms\n",
            "Speed: 6.0ms preprocess, 20.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 24.5ms\n",
            "Speed: 4.8ms preprocess, 24.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 62.8ms\n",
            "Speed: 7.5ms preprocess, 62.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 20.0ms\n",
            "Speed: 11.0ms preprocess, 20.0ms inference, 18.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 19.9ms\n",
            "Speed: 4.4ms preprocess, 19.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 19.9ms\n",
            "Speed: 4.5ms preprocess, 19.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 19.9ms\n",
            "Speed: 5.5ms preprocess, 19.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 19.9ms\n",
            "Speed: 4.7ms preprocess, 19.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 19.9ms\n",
            "Speed: 5.1ms preprocess, 19.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 21.7ms\n",
            "Speed: 9.6ms preprocess, 21.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 19.9ms\n",
            "Speed: 4.9ms preprocess, 19.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 19.6ms\n",
            "Speed: 4.8ms preprocess, 19.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 19.6ms\n",
            "Speed: 4.6ms preprocess, 19.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 19.6ms\n",
            "Speed: 4.2ms preprocess, 19.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Misses/4.mp4\n",
            "\n",
            "0: 640x640 1 person, 19.6ms\n",
            "Speed: 6.1ms preprocess, 19.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 19.5ms\n",
            "Speed: 4.5ms preprocess, 19.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 19.5ms\n",
            "Speed: 4.7ms preprocess, 19.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 20.3ms\n",
            "Speed: 7.1ms preprocess, 20.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 19.5ms\n",
            "Speed: 4.4ms preprocess, 19.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 19.2ms\n",
            "Speed: 5.9ms preprocess, 19.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 19.1ms\n",
            "Speed: 4.8ms preprocess, 19.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 19.0ms\n",
            "Speed: 4.1ms preprocess, 19.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 19.1ms\n",
            "Speed: 5.0ms preprocess, 19.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 19.0ms\n",
            "Speed: 4.6ms preprocess, 19.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.0ms\n",
            "Speed: 4.5ms preprocess, 18.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.2ms\n",
            "Speed: 4.3ms preprocess, 18.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.1ms\n",
            "Speed: 4.6ms preprocess, 18.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.1ms\n",
            "Speed: 4.5ms preprocess, 18.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.0ms\n",
            "Speed: 4.6ms preprocess, 18.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.0ms\n",
            "Speed: 4.6ms preprocess, 18.0ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.2ms\n",
            "Speed: 4.8ms preprocess, 18.2ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.0ms\n",
            "Speed: 4.3ms preprocess, 18.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.2ms\n",
            "Speed: 4.8ms preprocess, 18.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.1ms\n",
            "Speed: 4.6ms preprocess, 18.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.4ms\n",
            "Speed: 7.2ms preprocess, 18.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.0ms\n",
            "Speed: 4.5ms preprocess, 18.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.1ms\n",
            "Speed: 4.9ms preprocess, 18.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.0ms\n",
            "Speed: 5.0ms preprocess, 18.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.0ms\n",
            "Speed: 4.8ms preprocess, 18.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.3ms\n",
            "Speed: 4.8ms preprocess, 18.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.0ms\n",
            "Speed: 5.6ms preprocess, 18.0ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.0ms\n",
            "Speed: 5.9ms preprocess, 18.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.0ms\n",
            "Speed: 6.1ms preprocess, 18.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.0ms\n",
            "Speed: 4.1ms preprocess, 18.0ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.6ms\n",
            "Speed: 4.5ms preprocess, 18.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.0ms\n",
            "Speed: 6.4ms preprocess, 18.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.1ms\n",
            "Speed: 4.4ms preprocess, 18.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.1ms\n",
            "Speed: 4.6ms preprocess, 18.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.0ms\n",
            "Speed: 4.3ms preprocess, 18.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.5ms\n",
            "Speed: 4.4ms preprocess, 18.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.0ms\n",
            "Speed: 4.6ms preprocess, 18.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.0ms\n",
            "Speed: 5.0ms preprocess, 18.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.7ms\n",
            "Speed: 4.8ms preprocess, 18.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 48.0ms\n",
            "Speed: 7.7ms preprocess, 48.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 23.3ms\n",
            "Speed: 4.8ms preprocess, 23.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.0ms\n",
            "Speed: 4.3ms preprocess, 18.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.1ms\n",
            "Speed: 4.3ms preprocess, 18.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Misses/5.mp4\n",
            "\n",
            "0: 544x640 1 person, 17.9ms\n",
            "Speed: 3.9ms preprocess, 17.9ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 31.1ms\n",
            "Speed: 3.8ms preprocess, 31.1ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 23.1ms\n",
            "Speed: 7.5ms preprocess, 23.1ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 28.3ms\n",
            "Speed: 4.0ms preprocess, 28.3ms inference, 6.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 17.4ms\n",
            "Speed: 4.5ms preprocess, 17.4ms inference, 7.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.0ms\n",
            "Speed: 8.4ms preprocess, 20.0ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 29.0ms\n",
            "Speed: 4.8ms preprocess, 29.0ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 30.7ms\n",
            "Speed: 3.8ms preprocess, 30.7ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 16.8ms\n",
            "Speed: 3.8ms preprocess, 16.8ms inference, 5.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 22.1ms\n",
            "Speed: 4.2ms preprocess, 22.1ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 27.0ms\n",
            "Speed: 8.0ms preprocess, 27.0ms inference, 5.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 27.4ms\n",
            "Speed: 7.0ms preprocess, 27.4ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 22.8ms\n",
            "Speed: 4.0ms preprocess, 22.8ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 29.8ms\n",
            "Speed: 3.9ms preprocess, 29.8ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 24.3ms\n",
            "Speed: 7.2ms preprocess, 24.3ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 23.3ms\n",
            "Speed: 4.1ms preprocess, 23.3ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 30.6ms\n",
            "Speed: 8.4ms preprocess, 30.6ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 29.6ms\n",
            "Speed: 6.1ms preprocess, 29.6ms inference, 7.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 2 persons, 30.2ms\n",
            "Speed: 5.0ms preprocess, 30.2ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 28.6ms\n",
            "Speed: 3.7ms preprocess, 28.6ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 24.4ms\n",
            "Speed: 6.3ms preprocess, 24.4ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 30.3ms\n",
            "Speed: 4.0ms preprocess, 30.3ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 27.4ms\n",
            "Speed: 10.1ms preprocess, 27.4ms inference, 5.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 34.8ms\n",
            "Speed: 10.9ms preprocess, 34.8ms inference, 10.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 25.2ms\n",
            "Speed: 4.7ms preprocess, 25.2ms inference, 2.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 27.6ms\n",
            "Speed: 6.8ms preprocess, 27.6ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 26.1ms\n",
            "Speed: 3.6ms preprocess, 26.1ms inference, 3.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 35.4ms\n",
            "Speed: 4.4ms preprocess, 35.4ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 31.5ms\n",
            "Speed: 5.1ms preprocess, 31.5ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 26.4ms\n",
            "Speed: 4.3ms preprocess, 26.4ms inference, 2.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 26.7ms\n",
            "Speed: 6.7ms preprocess, 26.7ms inference, 2.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 26.3ms\n",
            "Speed: 4.0ms preprocess, 26.3ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 27.8ms\n",
            "Speed: 4.5ms preprocess, 27.8ms inference, 2.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 26.7ms\n",
            "Speed: 9.7ms preprocess, 26.7ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 30.7ms\n",
            "Speed: 7.1ms preprocess, 30.7ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 27.3ms\n",
            "Speed: 9.7ms preprocess, 27.3ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 31.3ms\n",
            "Speed: 4.0ms preprocess, 31.3ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 27.2ms\n",
            "Speed: 4.0ms preprocess, 27.2ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 26.3ms\n",
            "Speed: 3.8ms preprocess, 26.3ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 26.4ms\n",
            "Speed: 6.1ms preprocess, 26.4ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Misses/6.mp4\n",
            "\n",
            "0: 512x640 1 person, 22.9ms\n",
            "Speed: 7.1ms preprocess, 22.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 21.6ms\n",
            "Speed: 3.8ms preprocess, 21.6ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 22.2ms\n",
            "Speed: 3.7ms preprocess, 22.2ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 21.8ms\n",
            "Speed: 4.4ms preprocess, 21.8ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 24.4ms\n",
            "Speed: 5.0ms preprocess, 24.4ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 27.8ms\n",
            "Speed: 10.9ms preprocess, 27.8ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 26.1ms\n",
            "Speed: 4.5ms preprocess, 26.1ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 21.7ms\n",
            "Speed: 9.2ms preprocess, 21.7ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 31.1ms\n",
            "Speed: 10.3ms preprocess, 31.1ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 28.8ms\n",
            "Speed: 8.9ms preprocess, 28.8ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 21.6ms\n",
            "Speed: 4.1ms preprocess, 21.6ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 21.6ms\n",
            "Speed: 4.9ms preprocess, 21.6ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 22.3ms\n",
            "Speed: 3.7ms preprocess, 22.3ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 21.7ms\n",
            "Speed: 5.1ms preprocess, 21.7ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 21.6ms\n",
            "Speed: 4.3ms preprocess, 21.6ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 22.0ms\n",
            "Speed: 4.1ms preprocess, 22.0ms inference, 3.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 21.9ms\n",
            "Speed: 3.7ms preprocess, 21.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 20.4ms\n",
            "Speed: 4.6ms preprocess, 20.4ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 20.6ms\n",
            "Speed: 4.1ms preprocess, 20.6ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 20.5ms\n",
            "Speed: 4.1ms preprocess, 20.5ms inference, 2.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 20.1ms\n",
            "Speed: 4.0ms preprocess, 20.1ms inference, 3.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.9ms\n",
            "Speed: 4.4ms preprocess, 19.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.9ms\n",
            "Speed: 3.8ms preprocess, 19.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.9ms\n",
            "Speed: 4.6ms preprocess, 19.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 20.8ms\n",
            "Speed: 6.0ms preprocess, 20.8ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.9ms\n",
            "Speed: 3.8ms preprocess, 19.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 21.6ms\n",
            "Speed: 9.1ms preprocess, 21.6ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 20.0ms\n",
            "Speed: 4.4ms preprocess, 20.0ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.9ms\n",
            "Speed: 4.2ms preprocess, 19.9ms inference, 2.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.9ms\n",
            "Speed: 4.1ms preprocess, 19.9ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.9ms\n",
            "Speed: 4.2ms preprocess, 19.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 20.0ms\n",
            "Speed: 4.2ms preprocess, 20.0ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.9ms\n",
            "Speed: 5.4ms preprocess, 19.9ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 persons, 23.3ms\n",
            "Speed: 3.9ms preprocess, 23.3ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 persons, 20.0ms\n",
            "Speed: 6.4ms preprocess, 20.0ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.9ms\n",
            "Speed: 4.0ms preprocess, 19.9ms inference, 2.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.9ms\n",
            "Speed: 4.5ms preprocess, 19.9ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.9ms\n",
            "Speed: 3.8ms preprocess, 19.9ms inference, 2.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.9ms\n",
            "Speed: 4.0ms preprocess, 19.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.9ms\n",
            "Speed: 3.7ms preprocess, 19.9ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.9ms\n",
            "Speed: 3.7ms preprocess, 19.9ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.9ms\n",
            "Speed: 4.1ms preprocess, 19.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.9ms\n",
            "Speed: 5.8ms preprocess, 19.9ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 21.1ms\n",
            "Speed: 4.3ms preprocess, 21.1ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.9ms\n",
            "Speed: 4.1ms preprocess, 19.9ms inference, 2.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.9ms\n",
            "Speed: 3.7ms preprocess, 19.9ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 persons, 19.8ms\n",
            "Speed: 4.2ms preprocess, 19.8ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 persons, 19.8ms\n",
            "Speed: 4.0ms preprocess, 19.8ms inference, 2.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.9ms\n",
            "Speed: 4.2ms preprocess, 19.9ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Misses/7.mp4\n",
            "\n",
            "0: 448x640 1 person, 19.8ms\n",
            "Speed: 4.4ms preprocess, 19.8ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 18.7ms\n",
            "Speed: 3.8ms preprocess, 18.7ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 18.7ms\n",
            "Speed: 3.2ms preprocess, 18.7ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 18.8ms\n",
            "Speed: 3.1ms preprocess, 18.8ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 18.7ms\n",
            "Speed: 2.7ms preprocess, 18.7ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 18.7ms\n",
            "Speed: 2.9ms preprocess, 18.7ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 18.7ms\n",
            "Speed: 2.9ms preprocess, 18.7ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 18.7ms\n",
            "Speed: 3.1ms preprocess, 18.7ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 18.7ms\n",
            "Speed: 3.2ms preprocess, 18.7ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 17.8ms\n",
            "Speed: 3.1ms preprocess, 17.8ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 14.3ms\n",
            "Speed: 3.5ms preprocess, 14.3ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 14.2ms\n",
            "Speed: 3.4ms preprocess, 14.2ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 14.2ms\n",
            "Speed: 3.3ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 14.4ms\n",
            "Speed: 3.5ms preprocess, 14.4ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 14.2ms\n",
            "Speed: 3.6ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 16.0ms\n",
            "Speed: 3.7ms preprocess, 16.0ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 13.0ms\n",
            "Speed: 3.6ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 13.9ms\n",
            "Speed: 3.4ms preprocess, 13.9ms inference, 2.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 13.1ms\n",
            "Speed: 3.3ms preprocess, 13.1ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 13.4ms\n",
            "Speed: 3.4ms preprocess, 13.4ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 19.7ms\n",
            "Speed: 3.4ms preprocess, 19.7ms inference, 2.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 12.9ms\n",
            "Speed: 3.3ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 12.7ms\n",
            "Speed: 3.0ms preprocess, 12.7ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 13.4ms\n",
            "Speed: 2.9ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 12.8ms\n",
            "Speed: 3.0ms preprocess, 12.8ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 13.5ms\n",
            "Speed: 3.0ms preprocess, 13.5ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 13.4ms\n",
            "Speed: 4.0ms preprocess, 13.4ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 12.9ms\n",
            "Speed: 5.0ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 13.0ms\n",
            "Speed: 3.0ms preprocess, 13.0ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 15.9ms\n",
            "Speed: 3.5ms preprocess, 15.9ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 13.5ms\n",
            "Speed: 3.5ms preprocess, 13.5ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 14.8ms\n",
            "Speed: 3.0ms preprocess, 14.8ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 13.2ms\n",
            "Speed: 2.9ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 13.5ms\n",
            "Speed: 4.0ms preprocess, 13.5ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 12.9ms\n",
            "Speed: 5.5ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 13.4ms\n",
            "Speed: 3.1ms preprocess, 13.4ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 12.7ms\n",
            "Speed: 2.8ms preprocess, 12.7ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 13.3ms\n",
            "Speed: 3.3ms preprocess, 13.3ms inference, 2.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 12.9ms\n",
            "Speed: 2.9ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 12.9ms\n",
            "Speed: 2.8ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Misses/8.mp4\n",
            "\n",
            "0: 640x640 1 person, 18.5ms\n",
            "Speed: 4.9ms preprocess, 18.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.2ms\n",
            "Speed: 2.5ms preprocess, 18.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.7ms\n",
            "Speed: 5.7ms preprocess, 18.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 17.9ms\n",
            "Speed: 3.2ms preprocess, 17.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.5ms\n",
            "Speed: 4.1ms preprocess, 18.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 25.0ms\n",
            "Speed: 3.5ms preprocess, 25.0ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 19.5ms\n",
            "Speed: 4.1ms preprocess, 19.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 20.3ms\n",
            "Speed: 4.2ms preprocess, 20.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.7ms\n",
            "Speed: 3.9ms preprocess, 18.7ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.2ms\n",
            "Speed: 3.7ms preprocess, 18.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.5ms\n",
            "Speed: 3.7ms preprocess, 18.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.8ms\n",
            "Speed: 3.4ms preprocess, 18.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.6ms\n",
            "Speed: 4.4ms preprocess, 18.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 persons, 18.7ms\n",
            "Speed: 3.5ms preprocess, 18.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 17.7ms\n",
            "Speed: 3.6ms preprocess, 17.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 17.6ms\n",
            "Speed: 3.6ms preprocess, 17.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 19.5ms\n",
            "Speed: 3.7ms preprocess, 19.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 19.0ms\n",
            "Speed: 3.8ms preprocess, 19.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.6ms\n",
            "Speed: 3.9ms preprocess, 18.6ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.9ms\n",
            "Speed: 3.6ms preprocess, 18.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.2ms\n",
            "Speed: 3.9ms preprocess, 18.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 20.1ms\n",
            "Speed: 3.5ms preprocess, 20.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.6ms\n",
            "Speed: 4.0ms preprocess, 18.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.2ms\n",
            "Speed: 4.1ms preprocess, 18.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 19.0ms\n",
            "Speed: 3.5ms preprocess, 19.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.5ms\n",
            "Speed: 3.4ms preprocess, 18.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.1ms\n",
            "Speed: 3.9ms preprocess, 18.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 19.3ms\n",
            "Speed: 3.7ms preprocess, 19.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.8ms\n",
            "Speed: 4.0ms preprocess, 18.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.5ms\n",
            "Speed: 3.9ms preprocess, 18.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 19.5ms\n",
            "Speed: 4.3ms preprocess, 19.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 18.2ms\n",
            "Speed: 4.2ms preprocess, 18.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 19.4ms\n",
            "Speed: 3.7ms preprocess, 19.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Misses/9.mp4\n",
            "\n",
            "0: 480x640 1 person, 14.2ms\n",
            "Speed: 3.8ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 13.0ms\n",
            "Speed: 4.1ms preprocess, 13.0ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 25.1ms\n",
            "Speed: 3.5ms preprocess, 25.1ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 14.2ms\n",
            "Speed: 3.7ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 13.9ms\n",
            "Speed: 3.7ms preprocess, 13.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 13.6ms\n",
            "Speed: 4.4ms preprocess, 13.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 16.5ms\n",
            "Speed: 3.4ms preprocess, 16.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 13.2ms\n",
            "Speed: 2.1ms preprocess, 13.2ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 13.3ms\n",
            "Speed: 3.6ms preprocess, 13.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 13.6ms\n",
            "Speed: 3.1ms preprocess, 13.6ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 13.5ms\n",
            "Speed: 3.0ms preprocess, 13.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 14.0ms\n",
            "Speed: 3.4ms preprocess, 14.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 13.3ms\n",
            "Speed: 6.7ms preprocess, 13.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 13.7ms\n",
            "Speed: 4.1ms preprocess, 13.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 13.5ms\n",
            "Speed: 5.0ms preprocess, 13.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 13.5ms\n",
            "Speed: 3.3ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 13.4ms\n",
            "Speed: 3.6ms preprocess, 13.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 13.3ms\n",
            "Speed: 3.4ms preprocess, 13.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 13.9ms\n",
            "Speed: 3.8ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 13.7ms\n",
            "Speed: 3.4ms preprocess, 13.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 13.9ms\n",
            "Speed: 3.3ms preprocess, 13.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 13.9ms\n",
            "Speed: 3.3ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 13.4ms\n",
            "Speed: 3.3ms preprocess, 13.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 14.7ms\n",
            "Speed: 3.4ms preprocess, 14.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 13.5ms\n",
            "Speed: 3.6ms preprocess, 13.5ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 14.9ms\n",
            "Speed: 3.1ms preprocess, 14.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 13.8ms\n",
            "Speed: 3.2ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 15.5ms\n",
            "Speed: 3.0ms preprocess, 15.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 13.6ms\n",
            "Speed: 3.4ms preprocess, 13.6ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 14.0ms\n",
            "Speed: 4.0ms preprocess, 14.0ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 13.4ms\n",
            "Speed: 3.0ms preprocess, 13.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 14.2ms\n",
            "Speed: 3.1ms preprocess, 14.2ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 16.9ms\n",
            "Speed: 3.1ms preprocess, 16.9ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 14.0ms\n",
            "Speed: 3.5ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 13.5ms\n",
            "Speed: 3.6ms preprocess, 13.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 13.5ms\n",
            "Speed: 3.6ms preprocess, 13.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 person, 14.3ms\n",
            "Speed: 3.5ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Misses/10.mp4\n",
            "\n",
            "0: 384x640 1 person, 12.6ms\n",
            "Speed: 6.7ms preprocess, 12.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 24.8ms\n",
            "Speed: 2.9ms preprocess, 24.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.0ms\n",
            "Speed: 2.8ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.3ms\n",
            "Speed: 2.7ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.3ms\n",
            "Speed: 2.7ms preprocess, 14.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.6ms\n",
            "Speed: 2.8ms preprocess, 15.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.5ms\n",
            "Speed: 3.3ms preprocess, 15.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.8ms\n",
            "Speed: 3.1ms preprocess, 11.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 2.6ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 2.8ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.8ms\n",
            "Speed: 3.8ms preprocess, 12.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.6ms\n",
            "Speed: 3.4ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.6ms\n",
            "Speed: 3.0ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.0ms\n",
            "Speed: 2.8ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.9ms\n",
            "Speed: 3.4ms preprocess, 13.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.2ms\n",
            "Speed: 2.7ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.7ms\n",
            "Speed: 2.8ms preprocess, 17.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.6ms\n",
            "Speed: 2.9ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.3ms\n",
            "Speed: 2.8ms preprocess, 16.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.8ms\n",
            "Speed: 2.8ms preprocess, 11.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.7ms\n",
            "Speed: 2.8ms preprocess, 16.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.5ms\n",
            "Speed: 2.9ms preprocess, 13.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.8ms\n",
            "Speed: 2.6ms preprocess, 14.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.3ms\n",
            "Speed: 2.9ms preprocess, 15.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.5ms\n",
            "Speed: 3.0ms preprocess, 15.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.6ms\n",
            "Speed: 7.4ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.3ms\n",
            "Speed: 2.9ms preprocess, 15.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.8ms\n",
            "Speed: 3.1ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.4ms\n",
            "Speed: 2.7ms preprocess, 15.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 3.2ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.8ms\n",
            "Speed: 4.8ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.0ms\n",
            "Speed: 2.6ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.0ms\n",
            "Speed: 2.7ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.3ms\n",
            "Speed: 3.8ms preprocess, 17.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.0ms\n",
            "Speed: 2.8ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.9ms\n",
            "Speed: 2.6ms preprocess, 16.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.9ms\n",
            "Speed: 2.7ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.3ms\n",
            "Speed: 3.6ms preprocess, 17.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.1ms\n",
            "Speed: 2.6ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Misses/11.mp4\n",
            "\n",
            "0: 384x640 1 person, 22.2ms\n",
            "Speed: 3.4ms preprocess, 22.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.9ms\n",
            "Speed: 3.1ms preprocess, 15.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.1ms\n",
            "Speed: 6.9ms preprocess, 17.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 39.9ms\n",
            "Speed: 3.6ms preprocess, 39.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.6ms\n",
            "Speed: 3.2ms preprocess, 15.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.7ms\n",
            "Speed: 3.0ms preprocess, 15.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.9ms\n",
            "Speed: 3.2ms preprocess, 17.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.5ms\n",
            "Speed: 3.0ms preprocess, 16.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.6ms\n",
            "Speed: 2.9ms preprocess, 15.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.6ms\n",
            "Speed: 2.6ms preprocess, 15.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.6ms\n",
            "Speed: 2.8ms preprocess, 15.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.9ms\n",
            "Speed: 6.6ms preprocess, 14.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.6ms\n",
            "Speed: 2.7ms preprocess, 15.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.5ms\n",
            "Speed: 2.8ms preprocess, 13.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.3ms\n",
            "Speed: 3.2ms preprocess, 15.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 2.8ms preprocess, 15.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.6ms\n",
            "Speed: 3.1ms preprocess, 14.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 2.6ms preprocess, 16.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.6ms\n",
            "Speed: 2.7ms preprocess, 14.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.5ms\n",
            "Speed: 2.6ms preprocess, 15.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.2ms\n",
            "Speed: 2.8ms preprocess, 15.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 2.7ms preprocess, 16.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.3ms\n",
            "Speed: 2.8ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 2.9ms preprocess, 16.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.4ms\n",
            "Speed: 2.9ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.3ms\n",
            "Speed: 6.5ms preprocess, 22.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.5ms\n",
            "Speed: 6.0ms preprocess, 16.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.0ms\n",
            "Speed: 2.8ms preprocess, 17.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.8ms\n",
            "Speed: 5.4ms preprocess, 12.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.8ms\n",
            "Speed: 4.6ms preprocess, 15.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.4ms\n",
            "Speed: 3.0ms preprocess, 15.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 6.2ms preprocess, 13.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.3ms\n",
            "Speed: 2.6ms preprocess, 21.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.3ms\n",
            "Speed: 2.9ms preprocess, 19.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 2.9ms preprocess, 16.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.0ms\n",
            "Speed: 3.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.8ms\n",
            "Speed: 2.6ms preprocess, 22.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.3ms\n",
            "Speed: 2.9ms preprocess, 18.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.2ms\n",
            "Speed: 2.9ms preprocess, 13.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.1ms\n",
            "Speed: 2.6ms preprocess, 14.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.8ms\n",
            "Speed: 2.8ms preprocess, 19.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.7ms\n",
            "Speed: 2.8ms preprocess, 17.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.6ms\n",
            "Speed: 2.7ms preprocess, 12.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.9ms\n",
            "Speed: 2.7ms preprocess, 15.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.5ms\n",
            "Speed: 4.5ms preprocess, 15.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.3ms\n",
            "Speed: 4.1ms preprocess, 15.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.8ms\n",
            "Speed: 3.0ms preprocess, 14.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.4ms\n",
            "Speed: 4.9ms preprocess, 12.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.1ms\n",
            "Speed: 2.6ms preprocess, 16.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.8ms\n",
            "Speed: 2.9ms preprocess, 15.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.6ms\n",
            "Speed: 5.3ms preprocess, 19.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.8ms\n",
            "Speed: 4.7ms preprocess, 15.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Misses/12.mp4\n",
            "\n",
            "0: 384x640 1 person, 31.3ms\n",
            "Speed: 3.2ms preprocess, 31.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.4ms\n",
            "Speed: 6.3ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.4ms\n",
            "Speed: 2.8ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.4ms\n",
            "Speed: 4.4ms preprocess, 26.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.4ms\n",
            "Speed: 3.2ms preprocess, 26.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23.1ms\n",
            "Speed: 6.3ms preprocess, 23.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.8ms\n",
            "Speed: 2.9ms preprocess, 22.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23.0ms\n",
            "Speed: 5.1ms preprocess, 23.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23.1ms\n",
            "Speed: 5.9ms preprocess, 23.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.3ms\n",
            "Speed: 2.8ms preprocess, 20.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.7ms\n",
            "Speed: 4.3ms preprocess, 20.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.2ms\n",
            "Speed: 2.8ms preprocess, 20.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.5ms\n",
            "Speed: 2.7ms preprocess, 20.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.6ms\n",
            "Speed: 2.9ms preprocess, 19.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.7ms\n",
            "Speed: 2.7ms preprocess, 19.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.6ms\n",
            "Speed: 3.2ms preprocess, 19.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.7ms\n",
            "Speed: 2.8ms preprocess, 19.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.6ms\n",
            "Speed: 2.9ms preprocess, 19.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.3ms\n",
            "Speed: 3.1ms preprocess, 16.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.4ms\n",
            "Speed: 6.6ms preprocess, 17.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.7ms\n",
            "Speed: 2.8ms preprocess, 16.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.8ms\n",
            "Speed: 3.9ms preprocess, 17.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.2ms\n",
            "Speed: 2.8ms preprocess, 16.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 5.8ms preprocess, 16.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.9ms\n",
            "Speed: 4.6ms preprocess, 15.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.9ms\n",
            "Speed: 4.8ms preprocess, 15.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.2ms\n",
            "Speed: 3.2ms preprocess, 18.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.9ms\n",
            "Speed: 3.1ms preprocess, 15.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.9ms\n",
            "Speed: 3.1ms preprocess, 15.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.9ms\n",
            "Speed: 4.2ms preprocess, 15.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.7ms\n",
            "Speed: 2.6ms preprocess, 17.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.9ms\n",
            "Speed: 4.7ms preprocess, 15.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.8ms\n",
            "Speed: 2.8ms preprocess, 15.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.8ms\n",
            "Speed: 2.9ms preprocess, 15.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.8ms\n",
            "Speed: 2.8ms preprocess, 15.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.5ms\n",
            "Speed: 2.6ms preprocess, 21.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.4ms\n",
            "Speed: 4.4ms preprocess, 19.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.7ms\n",
            "Speed: 2.7ms preprocess, 22.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.7ms\n",
            "Speed: 2.9ms preprocess, 21.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.9ms\n",
            "Speed: 2.8ms preprocess, 17.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.4ms\n",
            "Speed: 3.2ms preprocess, 21.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.8ms\n",
            "Speed: 2.8ms preprocess, 21.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.3ms\n",
            "Speed: 3.1ms preprocess, 19.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.1ms\n",
            "Speed: 2.8ms preprocess, 19.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.9ms\n",
            "Speed: 6.9ms preprocess, 15.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.6ms\n",
            "Speed: 3.1ms preprocess, 22.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.8ms\n",
            "Speed: 2.8ms preprocess, 15.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.8ms\n",
            "Speed: 5.9ms preprocess, 15.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.9ms\n",
            "Speed: 2.7ms preprocess, 21.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Misses/13.mp4\n",
            "\n",
            "0: 384x640 1 person, 16.1ms\n",
            "Speed: 5.2ms preprocess, 16.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.9ms\n",
            "Speed: 5.3ms preprocess, 15.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.8ms\n",
            "Speed: 2.7ms preprocess, 15.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.8ms\n",
            "Speed: 3.0ms preprocess, 15.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.3ms\n",
            "Speed: 4.1ms preprocess, 18.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.3ms\n",
            "Speed: 5.9ms preprocess, 18.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.3ms\n",
            "Speed: 4.4ms preprocess, 18.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.3ms\n",
            "Speed: 2.9ms preprocess, 18.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.3ms\n",
            "Speed: 5.0ms preprocess, 18.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.2ms\n",
            "Speed: 2.7ms preprocess, 16.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.2ms\n",
            "Speed: 2.7ms preprocess, 16.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.2ms\n",
            "Speed: 2.8ms preprocess, 16.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 2.9ms preprocess, 16.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 4.4ms preprocess, 16.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.9ms\n",
            "Speed: 3.8ms preprocess, 15.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.6ms\n",
            "Speed: 2.9ms preprocess, 15.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 4.2ms preprocess, 14.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.8ms\n",
            "Speed: 2.7ms preprocess, 15.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.6ms\n",
            "Speed: 2.9ms preprocess, 15.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.4ms\n",
            "Speed: 2.7ms preprocess, 15.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.0ms\n",
            "Speed: 3.0ms preprocess, 14.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.0ms\n",
            "Speed: 3.1ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 2.7ms preprocess, 14.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.8ms\n",
            "Speed: 2.8ms preprocess, 14.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.0ms\n",
            "Speed: 2.8ms preprocess, 14.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.0ms\n",
            "Speed: 2.8ms preprocess, 14.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.0ms\n",
            "Speed: 2.9ms preprocess, 14.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.5ms\n",
            "Speed: 2.8ms preprocess, 22.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 2.8ms preprocess, 16.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 3.0ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 4.3ms preprocess, 13.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 2.6ms preprocess, 13.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 2.7ms preprocess, 14.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.8ms\n",
            "Speed: 2.7ms preprocess, 15.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.5ms\n",
            "Speed: 2.8ms preprocess, 17.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.7ms\n",
            "Speed: 2.7ms preprocess, 14.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 2.7ms preprocess, 13.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 2.6ms preprocess, 13.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.5ms\n",
            "Speed: 2.6ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.6ms\n",
            "Speed: 2.7ms preprocess, 12.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Misses/14.mp4\n",
            "\n",
            "0: 384x640 1 person, 12.6ms\n",
            "Speed: 7.0ms preprocess, 12.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.1ms\n",
            "Speed: 3.8ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.4ms\n",
            "Speed: 3.0ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.5ms\n",
            "Speed: 4.9ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.5ms\n",
            "Speed: 3.3ms preprocess, 15.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.7ms\n",
            "Speed: 2.9ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 2.8ms preprocess, 15.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.5ms\n",
            "Speed: 2.3ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.3ms\n",
            "Speed: 2.7ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.6ms\n",
            "Speed: 2.7ms preprocess, 14.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.0ms\n",
            "Speed: 4.8ms preprocess, 21.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 2.8ms preprocess, 14.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.0ms\n",
            "Speed: 2.7ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.2ms\n",
            "Speed: 2.8ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 2.6ms preprocess, 14.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.3ms\n",
            "Speed: 6.3ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.3ms\n",
            "Speed: 3.2ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.4ms\n",
            "Speed: 4.6ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.9ms\n",
            "Speed: 2.8ms preprocess, 14.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.3ms\n",
            "Speed: 2.9ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.7ms\n",
            "Speed: 2.7ms preprocess, 14.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.2ms\n",
            "Speed: 2.7ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.5ms\n",
            "Speed: 3.1ms preprocess, 15.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.6ms\n",
            "Speed: 2.9ms preprocess, 19.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.7ms\n",
            "Speed: 2.6ms preprocess, 14.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.2ms\n",
            "Speed: 2.6ms preprocess, 12.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.9ms\n",
            "Speed: 2.8ms preprocess, 14.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.3ms\n",
            "Speed: 2.6ms preprocess, 12.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.1ms\n",
            "Speed: 3.9ms preprocess, 17.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.6ms\n",
            "Speed: 3.3ms preprocess, 14.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 3.1ms preprocess, 14.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.0ms\n",
            "Speed: 2.6ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.3ms\n",
            "Speed: 3.2ms preprocess, 15.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.6ms\n",
            "Speed: 3.2ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.1ms\n",
            "Speed: 2.9ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.1ms\n",
            "Speed: 2.8ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 4.9ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.0ms\n",
            "Speed: 5.4ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.2ms\n",
            "Speed: 2.7ms preprocess, 16.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.8ms\n",
            "Speed: 3.0ms preprocess, 12.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.0ms\n",
            "Speed: 3.6ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.2ms\n",
            "Speed: 2.8ms preprocess, 21.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.7ms\n",
            "Speed: 2.7ms preprocess, 12.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.9ms\n",
            "Speed: 2.7ms preprocess, 13.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.1ms\n",
            "Speed: 2.8ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.2ms\n",
            "Speed: 2.9ms preprocess, 15.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.0ms\n",
            "Speed: 2.9ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.5ms\n",
            "Speed: 2.7ms preprocess, 13.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.1ms\n",
            "Speed: 2.3ms preprocess, 12.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.9ms\n",
            "Speed: 2.6ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.1ms\n",
            "Speed: 2.9ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Misses/15.mp4\n",
            "\n",
            "0: 384x640 1 person, 13.2ms\n",
            "Speed: 3.3ms preprocess, 13.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 1.9ms preprocess, 14.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.9ms\n",
            "Speed: 7.6ms preprocess, 13.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.2ms\n",
            "Speed: 3.8ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.0ms\n",
            "Speed: 3.7ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.5ms\n",
            "Speed: 3.0ms preprocess, 13.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.0ms\n",
            "Speed: 2.7ms preprocess, 22.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.0ms\n",
            "Speed: 3.3ms preprocess, 13.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.0ms\n",
            "Speed: 2.7ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.0ms\n",
            "Speed: 2.6ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.9ms\n",
            "Speed: 2.6ms preprocess, 15.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 2.7ms preprocess, 16.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.0ms\n",
            "Speed: 2.9ms preprocess, 12.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.9ms\n",
            "Speed: 2.6ms preprocess, 17.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.5ms\n",
            "Speed: 2.6ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.5ms\n",
            "Speed: 6.8ms preprocess, 20.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.0ms\n",
            "Speed: 3.2ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.0ms\n",
            "Speed: 2.7ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.0ms\n",
            "Speed: 2.7ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.0ms\n",
            "Speed: 3.0ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.3ms\n",
            "Speed: 5.3ms preprocess, 17.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 4.5ms preprocess, 16.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.7ms\n",
            "Speed: 2.6ms preprocess, 14.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 2.6ms preprocess, 14.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.7ms\n",
            "Speed: 3.0ms preprocess, 12.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.1ms\n",
            "Speed: 2.8ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.0ms\n",
            "Speed: 2.8ms preprocess, 18.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.2ms\n",
            "Speed: 2.9ms preprocess, 15.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.8ms\n",
            "Speed: 3.1ms preprocess, 15.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.2ms\n",
            "Speed: 3.2ms preprocess, 15.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.3ms\n",
            "Speed: 2.8ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.7ms\n",
            "Speed: 2.6ms preprocess, 12.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Misses/16.mp4\n",
            "\n",
            "0: 384x640 1 person, 13.5ms\n",
            "Speed: 3.9ms preprocess, 13.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.6ms\n",
            "Speed: 5.0ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.2ms\n",
            "Speed: 4.4ms preprocess, 16.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.5ms\n",
            "Speed: 3.1ms preprocess, 18.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.3ms\n",
            "Speed: 3.0ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.7ms\n",
            "Speed: 2.8ms preprocess, 12.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.6ms\n",
            "Speed: 2.7ms preprocess, 15.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.4ms\n",
            "Speed: 2.7ms preprocess, 15.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.6ms\n",
            "Speed: 2.8ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.6ms\n",
            "Speed: 2.7ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 2.9ms preprocess, 16.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.7ms\n",
            "Speed: 2.3ms preprocess, 12.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.5ms\n",
            "Speed: 2.9ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.7ms\n",
            "Speed: 2.8ms preprocess, 17.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.9ms\n",
            "Speed: 3.1ms preprocess, 15.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.7ms\n",
            "Speed: 3.0ms preprocess, 15.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.5ms\n",
            "Speed: 2.9ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.6ms\n",
            "Speed: 3.5ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 3.0ms preprocess, 14.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.1ms\n",
            "Speed: 2.8ms preprocess, 16.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.5ms\n",
            "Speed: 3.3ms preprocess, 17.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.9ms\n",
            "Speed: 3.0ms preprocess, 16.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.9ms\n",
            "Speed: 3.0ms preprocess, 18.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.3ms\n",
            "Speed: 3.2ms preprocess, 16.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.7ms\n",
            "Speed: 3.4ms preprocess, 15.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.1ms\n",
            "Speed: 3.5ms preprocess, 13.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.4ms\n",
            "Speed: 3.2ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.1ms\n",
            "Speed: 2.7ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.3ms\n",
            "Speed: 3.0ms preprocess, 13.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.5ms\n",
            "Speed: 3.0ms preprocess, 18.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.2ms\n",
            "Speed: 2.7ms preprocess, 16.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.1ms\n",
            "Speed: 3.4ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.7ms\n",
            "Speed: 4.0ms preprocess, 16.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Misses/17.mp4\n",
            "\n",
            "0: 384x640 1 person, 22.3ms\n",
            "Speed: 5.4ms preprocess, 22.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.1ms\n",
            "Speed: 10.5ms preprocess, 22.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 25.1ms\n",
            "Speed: 3.4ms preprocess, 25.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.1ms\n",
            "Speed: 3.5ms preprocess, 22.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.0ms\n",
            "Speed: 3.0ms preprocess, 22.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.1ms\n",
            "Speed: 3.0ms preprocess, 22.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.0ms\n",
            "Speed: 2.9ms preprocess, 22.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.0ms\n",
            "Speed: 2.8ms preprocess, 22.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.3ms\n",
            "Speed: 3.0ms preprocess, 16.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.4ms\n",
            "Speed: 2.7ms preprocess, 16.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.4ms\n",
            "Speed: 2.8ms preprocess, 16.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.1ms\n",
            "Speed: 2.6ms preprocess, 16.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.1ms\n",
            "Speed: 2.5ms preprocess, 16.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 4.0ms preprocess, 16.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.1ms\n",
            "Speed: 5.3ms preprocess, 16.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 3.2ms preprocess, 16.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.3ms\n",
            "Speed: 2.9ms preprocess, 18.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.7ms\n",
            "Speed: 2.8ms preprocess, 15.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.6ms\n",
            "Speed: 3.7ms preprocess, 15.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.7ms\n",
            "Speed: 2.8ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.8ms\n",
            "Speed: 2.9ms preprocess, 14.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.0ms\n",
            "Speed: 3.0ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 2.9ms preprocess, 15.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.3ms\n",
            "Speed: 3.3ms preprocess, 15.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.0ms\n",
            "Speed: 3.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.2ms\n",
            "Speed: 2.9ms preprocess, 16.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.4ms\n",
            "Speed: 2.8ms preprocess, 17.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.3ms\n",
            "Speed: 3.1ms preprocess, 17.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.8ms\n",
            "Speed: 2.7ms preprocess, 15.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 25.6ms\n",
            "Speed: 2.9ms preprocess, 25.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.0ms\n",
            "Speed: 2.9ms preprocess, 22.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.4ms\n",
            "Speed: 3.2ms preprocess, 18.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 2.7ms preprocess, 16.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Misses/18.mp4\n",
            "\n",
            "0: 384x640 1 person, 26.8ms\n",
            "Speed: 3.4ms preprocess, 26.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.4ms\n",
            "Speed: 3.1ms preprocess, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 31.4ms\n",
            "Speed: 6.0ms preprocess, 31.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.4ms\n",
            "Speed: 3.1ms preprocess, 26.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.6ms\n",
            "Speed: 6.6ms preprocess, 26.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 28.9ms\n",
            "Speed: 3.4ms preprocess, 28.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 27.9ms\n",
            "Speed: 4.3ms preprocess, 27.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.7ms\n",
            "Speed: 6.8ms preprocess, 26.7ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.5ms\n",
            "Speed: 9.3ms preprocess, 26.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 27.5ms\n",
            "Speed: 7.3ms preprocess, 27.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.6ms\n",
            "Speed: 3.1ms preprocess, 26.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 28.4ms\n",
            "Speed: 2.9ms preprocess, 28.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 32.6ms\n",
            "Speed: 3.1ms preprocess, 32.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.4ms\n",
            "Speed: 3.2ms preprocess, 26.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 57.8ms\n",
            "Speed: 3.4ms preprocess, 57.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.4ms\n",
            "Speed: 3.3ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.8ms\n",
            "Speed: 7.0ms preprocess, 26.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 39.8ms\n",
            "Speed: 11.3ms preprocess, 39.8ms inference, 10.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.5ms\n",
            "Speed: 7.3ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.4ms\n",
            "Speed: 3.1ms preprocess, 26.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 30.9ms\n",
            "Speed: 3.4ms preprocess, 30.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.4ms\n",
            "Speed: 6.9ms preprocess, 26.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 28.2ms\n",
            "Speed: 3.6ms preprocess, 28.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.4ms\n",
            "Speed: 5.2ms preprocess, 26.4ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.6ms\n",
            "Speed: 3.5ms preprocess, 26.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.6ms\n",
            "Speed: 3.2ms preprocess, 26.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 27.5ms\n",
            "Speed: 3.1ms preprocess, 27.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.4ms\n",
            "Speed: 3.9ms preprocess, 26.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.5ms\n",
            "Speed: 3.9ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.5ms\n",
            "Speed: 3.8ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 27.5ms\n",
            "Speed: 3.1ms preprocess, 27.5ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.4ms\n",
            "Speed: 2.8ms preprocess, 26.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.5ms\n",
            "Speed: 4.4ms preprocess, 26.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.6ms\n",
            "Speed: 3.5ms preprocess, 26.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.5ms\n",
            "Speed: 3.1ms preprocess, 26.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.4ms\n",
            "Speed: 3.1ms preprocess, 26.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.4ms\n",
            "Speed: 3.5ms preprocess, 26.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.5ms\n",
            "Speed: 3.2ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.4ms\n",
            "Speed: 3.2ms preprocess, 26.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.6ms\n",
            "Speed: 7.1ms preprocess, 26.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.5ms\n",
            "Speed: 3.1ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.6ms\n",
            "Speed: 3.1ms preprocess, 26.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.7ms\n",
            "Speed: 4.5ms preprocess, 26.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 27.2ms\n",
            "Speed: 3.1ms preprocess, 27.2ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.5ms\n",
            "Speed: 3.5ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.5ms\n",
            "Speed: 3.2ms preprocess, 26.5ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.5ms\n",
            "Speed: 5.5ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 27.6ms\n",
            "Speed: 3.8ms preprocess, 27.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.5ms\n",
            "Speed: 4.6ms preprocess, 26.5ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.5ms\n",
            "Speed: 3.6ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 26.6ms\n",
            "Speed: 3.1ms preprocess, 26.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.5ms\n",
            "Speed: 3.1ms preprocess, 26.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.6ms\n",
            "Speed: 4.2ms preprocess, 26.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.4ms\n",
            "Speed: 3.7ms preprocess, 26.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 28.1ms\n",
            "Speed: 3.0ms preprocess, 28.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.4ms\n",
            "Speed: 3.4ms preprocess, 26.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Misses/19.mp4\n",
            "\n",
            "0: 448x640 1 person, 30.8ms\n",
            "Speed: 7.3ms preprocess, 30.8ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 28.6ms\n",
            "Speed: 3.2ms preprocess, 28.6ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 28.6ms\n",
            "Speed: 3.8ms preprocess, 28.6ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 31.2ms\n",
            "Speed: 3.4ms preprocess, 31.2ms inference, 5.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 28.6ms\n",
            "Speed: 5.4ms preprocess, 28.6ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 27.5ms\n",
            "Speed: 4.7ms preprocess, 27.5ms inference, 2.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 30.6ms\n",
            "Speed: 4.3ms preprocess, 30.6ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 27.4ms\n",
            "Speed: 3.6ms preprocess, 27.4ms inference, 2.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 26.3ms\n",
            "Speed: 4.4ms preprocess, 26.3ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 26.2ms\n",
            "Speed: 3.3ms preprocess, 26.2ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 32.9ms\n",
            "Speed: 3.8ms preprocess, 32.9ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 25.4ms\n",
            "Speed: 3.2ms preprocess, 25.4ms inference, 2.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 25.2ms\n",
            "Speed: 3.2ms preprocess, 25.2ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 25.2ms\n",
            "Speed: 3.8ms preprocess, 25.2ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 25.8ms\n",
            "Speed: 3.4ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 24.8ms\n",
            "Speed: 3.2ms preprocess, 24.8ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 24.3ms\n",
            "Speed: 3.4ms preprocess, 24.3ms inference, 2.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 24.3ms\n",
            "Speed: 3.4ms preprocess, 24.3ms inference, 2.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 24.4ms\n",
            "Speed: 4.3ms preprocess, 24.4ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 24.3ms\n",
            "Speed: 4.4ms preprocess, 24.3ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 24.4ms\n",
            "Speed: 3.4ms preprocess, 24.4ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 23.1ms\n",
            "Speed: 3.7ms preprocess, 23.1ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 23.3ms\n",
            "Speed: 4.0ms preprocess, 23.3ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 23.1ms\n",
            "Speed: 3.5ms preprocess, 23.1ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 23.1ms\n",
            "Speed: 3.2ms preprocess, 23.1ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 23.2ms\n",
            "Speed: 5.3ms preprocess, 23.2ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 23.1ms\n",
            "Speed: 3.8ms preprocess, 23.1ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 23.1ms\n",
            "Speed: 3.3ms preprocess, 23.1ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 23.2ms\n",
            "Speed: 4.8ms preprocess, 23.2ms inference, 2.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 23.1ms\n",
            "Speed: 4.9ms preprocess, 23.1ms inference, 2.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 23.1ms\n",
            "Speed: 3.4ms preprocess, 23.1ms inference, 2.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 24.1ms\n",
            "Speed: 9.6ms preprocess, 24.1ms inference, 2.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 23.1ms\n",
            "Speed: 6.2ms preprocess, 23.1ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 23.1ms\n",
            "Speed: 3.1ms preprocess, 23.1ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 23.2ms\n",
            "Speed: 3.2ms preprocess, 23.2ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 23.1ms\n",
            "Speed: 3.2ms preprocess, 23.1ms inference, 2.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 23.1ms\n",
            "Speed: 3.8ms preprocess, 23.1ms inference, 2.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 23.2ms\n",
            "Speed: 3.8ms preprocess, 23.2ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 23.1ms\n",
            "Speed: 3.5ms preprocess, 23.1ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 23.1ms\n",
            "Speed: 3.5ms preprocess, 23.1ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 22.3ms\n",
            "Speed: 3.2ms preprocess, 22.3ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 22.9ms\n",
            "Speed: 3.5ms preprocess, 22.9ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 22.6ms\n",
            "Speed: 3.9ms preprocess, 22.6ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 24.2ms\n",
            "Speed: 4.2ms preprocess, 24.2ms inference, 2.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 22.5ms\n",
            "Speed: 4.2ms preprocess, 22.5ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 22.3ms\n",
            "Speed: 3.5ms preprocess, 22.3ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 22.4ms\n",
            "Speed: 4.0ms preprocess, 22.4ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 22.4ms\n",
            "Speed: 9.2ms preprocess, 22.4ms inference, 2.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 22.4ms\n",
            "Speed: 4.4ms preprocess, 22.4ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 22.4ms\n",
            "Speed: 3.6ms preprocess, 22.4ms inference, 2.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 22.3ms\n",
            "Speed: 3.5ms preprocess, 22.3ms inference, 2.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 22.3ms\n",
            "Speed: 5.9ms preprocess, 22.3ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 22.3ms\n",
            "Speed: 3.6ms preprocess, 22.3ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 22.5ms\n",
            "Speed: 3.3ms preprocess, 22.5ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 22.4ms\n",
            "Speed: 3.2ms preprocess, 22.4ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 22.3ms\n",
            "Speed: 3.4ms preprocess, 22.3ms inference, 2.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 21.2ms\n",
            "Speed: 3.7ms preprocess, 21.2ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 21.0ms\n",
            "Speed: 3.4ms preprocess, 21.0ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 20.9ms\n",
            "Speed: 3.1ms preprocess, 20.9ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 20.7ms\n",
            "Speed: 3.9ms preprocess, 20.7ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Misses/20.mp4\n",
            "\n",
            "0: 544x640 1 person, 28.6ms\n",
            "Speed: 4.9ms preprocess, 28.6ms inference, 2.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 25.6ms\n",
            "Speed: 3.8ms preprocess, 25.6ms inference, 2.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 25.6ms\n",
            "Speed: 4.8ms preprocess, 25.6ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 25.8ms\n",
            "Speed: 4.8ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 25.6ms\n",
            "Speed: 4.6ms preprocess, 25.6ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 25.7ms\n",
            "Speed: 5.6ms preprocess, 25.7ms inference, 2.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 26.7ms\n",
            "Speed: 11.7ms preprocess, 26.7ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 25.2ms\n",
            "Speed: 4.1ms preprocess, 25.2ms inference, 2.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 22.6ms\n",
            "Speed: 6.1ms preprocess, 22.6ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 22.5ms\n",
            "Speed: 5.3ms preprocess, 22.5ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 22.4ms\n",
            "Speed: 5.2ms preprocess, 22.4ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 22.5ms\n",
            "Speed: 4.9ms preprocess, 22.5ms inference, 2.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 22.4ms\n",
            "Speed: 5.8ms preprocess, 22.4ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 23.0ms\n",
            "Speed: 5.8ms preprocess, 23.0ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 22.4ms\n",
            "Speed: 5.9ms preprocess, 22.4ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 22.5ms\n",
            "Speed: 4.1ms preprocess, 22.5ms inference, 2.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 22.4ms\n",
            "Speed: 4.1ms preprocess, 22.4ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 22.3ms\n",
            "Speed: 3.7ms preprocess, 22.3ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 21.2ms\n",
            "Speed: 3.8ms preprocess, 21.2ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 21.2ms\n",
            "Speed: 3.9ms preprocess, 21.2ms inference, 2.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.9ms\n",
            "Speed: 3.9ms preprocess, 20.9ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 21.0ms\n",
            "Speed: 4.0ms preprocess, 21.0ms inference, 2.7ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 21.9ms\n",
            "Speed: 4.5ms preprocess, 21.9ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 21.0ms\n",
            "Speed: 4.1ms preprocess, 21.0ms inference, 2.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.1ms\n",
            "Speed: 7.0ms preprocess, 20.1ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 27.7ms\n",
            "Speed: 8.0ms preprocess, 27.7ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.0ms\n",
            "Speed: 4.1ms preprocess, 20.0ms inference, 5.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.2ms\n",
            "Speed: 4.7ms preprocess, 20.2ms inference, 2.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 27.2ms\n",
            "Speed: 10.2ms preprocess, 27.2ms inference, 3.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 26.0ms\n",
            "Speed: 5.7ms preprocess, 26.0ms inference, 3.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.1ms\n",
            "Speed: 5.7ms preprocess, 20.1ms inference, 8.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.1ms\n",
            "Speed: 3.9ms preprocess, 20.1ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.0ms\n",
            "Speed: 8.5ms preprocess, 20.0ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 28.4ms\n",
            "Speed: 7.0ms preprocess, 28.4ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.0ms\n",
            "Speed: 4.0ms preprocess, 20.0ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.1ms\n",
            "Speed: 4.4ms preprocess, 20.1ms inference, 10.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 24.5ms\n",
            "Speed: 3.9ms preprocess, 24.5ms inference, 9.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 24.1ms\n",
            "Speed: 9.9ms preprocess, 24.1ms inference, 9.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 28.7ms\n",
            "Speed: 10.3ms preprocess, 28.7ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 30.1ms\n",
            "Speed: 6.4ms preprocess, 30.1ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 24.2ms\n",
            "Speed: 4.0ms preprocess, 24.2ms inference, 8.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 27.7ms\n",
            "Speed: 6.6ms preprocess, 27.7ms inference, 9.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 31.0ms\n",
            "Speed: 7.2ms preprocess, 31.0ms inference, 2.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 28.1ms\n",
            "Speed: 4.4ms preprocess, 28.1ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 20.0ms\n",
            "Speed: 11.1ms preprocess, 20.0ms inference, 5.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 28.3ms\n",
            "Speed: 5.4ms preprocess, 28.3ms inference, 9.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 23.9ms\n",
            "Speed: 4.0ms preprocess, 23.9ms inference, 2.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 24.6ms\n",
            "Speed: 3.9ms preprocess, 24.6ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 27.9ms\n",
            "Speed: 6.0ms preprocess, 27.9ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 25.2ms\n",
            "Speed: 13.7ms preprocess, 25.2ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 26.2ms\n",
            "Speed: 4.0ms preprocess, 26.2ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 24.5ms\n",
            "Speed: 7.8ms preprocess, 24.5ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 37.5ms\n",
            "Speed: 4.2ms preprocess, 37.5ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 25.3ms\n",
            "Speed: 4.0ms preprocess, 25.3ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 25.9ms\n",
            "Speed: 4.0ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 32.3ms\n",
            "Speed: 6.4ms preprocess, 32.3ms inference, 5.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 29.1ms\n",
            "Speed: 3.8ms preprocess, 29.1ms inference, 6.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 26.1ms\n",
            "Speed: 3.8ms preprocess, 26.1ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 28.0ms\n",
            "Speed: 4.1ms preprocess, 28.0ms inference, 2.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 26.3ms\n",
            "Speed: 3.8ms preprocess, 26.3ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 544x640 1 person, 25.1ms\n",
            "Speed: 3.7ms preprocess, 25.1ms inference, 2.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Misses/21.mp4\n",
            "\n",
            "0: 576x640 1 person, 27.1ms\n",
            "Speed: 6.2ms preprocess, 27.1ms inference, 14.3ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 41.8ms\n",
            "Speed: 4.3ms preprocess, 41.8ms inference, 2.3ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 32.1ms\n",
            "Speed: 6.2ms preprocess, 32.1ms inference, 9.1ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 36.8ms\n",
            "Speed: 6.6ms preprocess, 36.8ms inference, 2.3ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 24.6ms\n",
            "Speed: 6.2ms preprocess, 24.6ms inference, 2.8ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 24.5ms\n",
            "Speed: 6.6ms preprocess, 24.5ms inference, 2.7ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 27.1ms\n",
            "Speed: 6.3ms preprocess, 27.1ms inference, 5.3ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 30.0ms\n",
            "Speed: 9.2ms preprocess, 30.0ms inference, 2.1ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 27.1ms\n",
            "Speed: 9.1ms preprocess, 27.1ms inference, 2.1ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 24.4ms\n",
            "Speed: 5.8ms preprocess, 24.4ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 24.5ms\n",
            "Speed: 14.2ms preprocess, 24.5ms inference, 5.5ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 24.4ms\n",
            "Speed: 3.9ms preprocess, 24.4ms inference, 2.3ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 29.6ms\n",
            "Speed: 4.7ms preprocess, 29.6ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 25.1ms\n",
            "Speed: 9.9ms preprocess, 25.1ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 33.4ms\n",
            "Speed: 9.0ms preprocess, 33.4ms inference, 2.2ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 25.7ms\n",
            "Speed: 4.5ms preprocess, 25.7ms inference, 2.2ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 26.8ms\n",
            "Speed: 4.1ms preprocess, 26.8ms inference, 2.2ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 31.1ms\n",
            "Speed: 6.4ms preprocess, 31.1ms inference, 4.2ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 32.3ms\n",
            "Speed: 18.4ms preprocess, 32.3ms inference, 2.2ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 36.8ms\n",
            "Speed: 4.7ms preprocess, 36.8ms inference, 2.3ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 27.5ms\n",
            "Speed: 5.9ms preprocess, 27.5ms inference, 3.1ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 30.9ms\n",
            "Speed: 12.2ms preprocess, 30.9ms inference, 3.3ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 28.7ms\n",
            "Speed: 3.9ms preprocess, 28.7ms inference, 6.7ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 30.1ms\n",
            "Speed: 4.8ms preprocess, 30.1ms inference, 2.1ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 28.4ms\n",
            "Speed: 5.7ms preprocess, 28.4ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 32.2ms\n",
            "Speed: 4.0ms preprocess, 32.2ms inference, 2.3ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 26.9ms\n",
            "Speed: 5.9ms preprocess, 26.9ms inference, 2.3ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 29.5ms\n",
            "Speed: 3.9ms preprocess, 29.5ms inference, 6.1ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 26.6ms\n",
            "Speed: 4.0ms preprocess, 26.6ms inference, 3.1ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 27.5ms\n",
            "Speed: 9.7ms preprocess, 27.5ms inference, 2.3ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 27.7ms\n",
            "Speed: 5.9ms preprocess, 27.7ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 26.6ms\n",
            "Speed: 9.0ms preprocess, 26.6ms inference, 3.4ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 29.6ms\n",
            "Speed: 4.2ms preprocess, 29.6ms inference, 2.2ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 31.0ms\n",
            "Speed: 4.0ms preprocess, 31.0ms inference, 3.7ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 26.6ms\n",
            "Speed: 4.0ms preprocess, 26.6ms inference, 3.5ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 26.6ms\n",
            "Speed: 8.3ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 27.0ms\n",
            "Speed: 4.8ms preprocess, 27.0ms inference, 2.3ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 26.6ms\n",
            "Speed: 4.4ms preprocess, 26.6ms inference, 2.6ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 26.6ms\n",
            "Speed: 4.1ms preprocess, 26.6ms inference, 1.8ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 24.0ms\n",
            "Speed: 4.0ms preprocess, 24.0ms inference, 2.2ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 24.3ms\n",
            "Speed: 4.8ms preprocess, 24.3ms inference, 1.7ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 23.9ms\n",
            "Speed: 4.9ms preprocess, 23.9ms inference, 2.2ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 23.9ms\n",
            "Speed: 4.7ms preprocess, 23.9ms inference, 1.6ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 23.9ms\n",
            "Speed: 5.3ms preprocess, 23.9ms inference, 1.9ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 23.9ms\n",
            "Speed: 7.1ms preprocess, 23.9ms inference, 3.8ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 23.9ms\n",
            "Speed: 9.2ms preprocess, 23.9ms inference, 2.3ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 23.0ms\n",
            "Speed: 4.0ms preprocess, 23.0ms inference, 2.4ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 22.8ms\n",
            "Speed: 4.6ms preprocess, 22.8ms inference, 1.6ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 22.6ms\n",
            "Speed: 4.2ms preprocess, 22.6ms inference, 2.3ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 25.9ms\n",
            "Speed: 6.3ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 22.7ms\n",
            "Speed: 4.0ms preprocess, 22.7ms inference, 1.9ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 22.6ms\n",
            "Speed: 4.1ms preprocess, 22.6ms inference, 2.6ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 22.6ms\n",
            "Speed: 4.2ms preprocess, 22.6ms inference, 2.3ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 21.3ms\n",
            "Speed: 4.0ms preprocess, 21.3ms inference, 2.5ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 21.3ms\n",
            "Speed: 4.1ms preprocess, 21.3ms inference, 2.4ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 21.0ms\n",
            "Speed: 4.1ms preprocess, 21.0ms inference, 2.1ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 21.0ms\n",
            "Speed: 4.4ms preprocess, 21.0ms inference, 2.2ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 21.1ms\n",
            "Speed: 4.2ms preprocess, 21.1ms inference, 1.7ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 20.9ms\n",
            "Speed: 4.3ms preprocess, 20.9ms inference, 2.2ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 20.7ms\n",
            "Speed: 4.0ms preprocess, 20.7ms inference, 2.3ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 20.6ms\n",
            "Speed: 4.2ms preprocess, 20.6ms inference, 2.1ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 20.6ms\n",
            "Speed: 4.0ms preprocess, 20.6ms inference, 2.2ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 20.6ms\n",
            "Speed: 4.2ms preprocess, 20.6ms inference, 2.1ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 24.1ms\n",
            "Speed: 7.3ms preprocess, 24.1ms inference, 2.4ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 20.2ms\n",
            "Speed: 6.4ms preprocess, 20.2ms inference, 1.7ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 20.1ms\n",
            "Speed: 5.8ms preprocess, 20.1ms inference, 2.3ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 19.9ms\n",
            "Speed: 5.5ms preprocess, 19.9ms inference, 1.7ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 19.9ms\n",
            "Speed: 4.1ms preprocess, 19.9ms inference, 2.2ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 19.9ms\n",
            "Speed: 6.5ms preprocess, 19.9ms inference, 1.7ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 19.8ms\n",
            "Speed: 5.3ms preprocess, 19.8ms inference, 2.1ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 19.8ms\n",
            "Speed: 4.3ms preprocess, 19.8ms inference, 1.7ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 19.9ms\n",
            "Speed: 4.9ms preprocess, 19.9ms inference, 2.5ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 20.1ms\n",
            "Speed: 4.1ms preprocess, 20.1ms inference, 2.2ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 19.9ms\n",
            "Speed: 4.6ms preprocess, 19.9ms inference, 1.7ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 19.9ms\n",
            "Speed: 4.5ms preprocess, 19.9ms inference, 2.4ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 19.9ms\n",
            "Speed: 4.3ms preprocess, 19.9ms inference, 2.1ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 19.9ms\n",
            "Speed: 4.3ms preprocess, 19.9ms inference, 2.1ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 19.9ms\n",
            "Speed: 4.4ms preprocess, 19.9ms inference, 2.2ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 19.9ms\n",
            "Speed: 4.4ms preprocess, 19.9ms inference, 1.7ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 20.0ms\n",
            "Speed: 3.8ms preprocess, 20.0ms inference, 1.6ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 19.8ms\n",
            "Speed: 4.1ms preprocess, 19.8ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 576x640 1 person, 19.8ms\n",
            "Speed: 5.4ms preprocess, 19.8ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
            "/content/drive/MyDrive/Shots/Shot Misses/22.mp4\n",
            "\n",
            "0: 640x576 1 person, 96.6ms\n",
            "Speed: 5.7ms preprocess, 96.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 19.7ms\n",
            "Speed: 4.6ms preprocess, 19.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 19.8ms\n",
            "Speed: 4.3ms preprocess, 19.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 20.2ms\n",
            "Speed: 4.5ms preprocess, 20.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 19.7ms\n",
            "Speed: 4.9ms preprocess, 19.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 19.8ms\n",
            "Speed: 4.2ms preprocess, 19.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 23.5ms\n",
            "Speed: 4.1ms preprocess, 23.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 19.8ms\n",
            "Speed: 5.1ms preprocess, 19.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 19.8ms\n",
            "Speed: 4.1ms preprocess, 19.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 19.8ms\n",
            "Speed: 4.3ms preprocess, 19.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 19.8ms\n",
            "Speed: 5.2ms preprocess, 19.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 22.3ms\n",
            "Speed: 6.8ms preprocess, 22.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 20.6ms\n",
            "Speed: 7.4ms preprocess, 20.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 19.8ms\n",
            "Speed: 8.8ms preprocess, 19.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 19.8ms\n",
            "Speed: 8.0ms preprocess, 19.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 19.8ms\n",
            "Speed: 4.3ms preprocess, 19.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 19.8ms\n",
            "Speed: 4.6ms preprocess, 19.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 19.8ms\n",
            "Speed: 4.3ms preprocess, 19.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 19.8ms\n",
            "Speed: 4.6ms preprocess, 19.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 20.7ms\n",
            "Speed: 4.3ms preprocess, 20.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 19.8ms\n",
            "Speed: 5.2ms preprocess, 19.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 19.8ms\n",
            "Speed: 5.2ms preprocess, 19.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 19.8ms\n",
            "Speed: 4.0ms preprocess, 19.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 19.8ms\n",
            "Speed: 4.6ms preprocess, 19.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 20.0ms\n",
            "Speed: 5.3ms preprocess, 20.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 19.3ms\n",
            "Speed: 6.0ms preprocess, 19.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 18.6ms\n",
            "Speed: 5.2ms preprocess, 18.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 18.5ms\n",
            "Speed: 4.2ms preprocess, 18.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 18.4ms\n",
            "Speed: 4.2ms preprocess, 18.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 18.4ms\n",
            "Speed: 5.1ms preprocess, 18.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 18.1ms\n",
            "Speed: 5.0ms preprocess, 18.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 27.1ms\n",
            "Speed: 5.2ms preprocess, 27.1ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 17.7ms\n",
            "Speed: 4.5ms preprocess, 17.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 17.6ms\n",
            "Speed: 4.2ms preprocess, 17.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 17.5ms\n",
            "Speed: 6.1ms preprocess, 17.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 22.5ms\n",
            "Speed: 4.3ms preprocess, 22.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 17.7ms\n",
            "Speed: 4.2ms preprocess, 17.7ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 17.7ms\n",
            "Speed: 4.8ms preprocess, 17.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 17.7ms\n",
            "Speed: 6.6ms preprocess, 17.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 18.2ms\n",
            "Speed: 4.2ms preprocess, 18.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 17.7ms\n",
            "Speed: 4.1ms preprocess, 17.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 17.7ms\n",
            "Speed: 7.0ms preprocess, 17.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 17.7ms\n",
            "Speed: 4.6ms preprocess, 17.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 17.6ms\n",
            "Speed: 4.6ms preprocess, 17.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 17.6ms\n",
            "Speed: 7.0ms preprocess, 17.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 17.6ms\n",
            "Speed: 10.6ms preprocess, 17.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 17.7ms\n",
            "Speed: 5.0ms preprocess, 17.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 17.6ms\n",
            "Speed: 8.0ms preprocess, 17.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 17.7ms\n",
            "Speed: 6.2ms preprocess, 17.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 20.2ms\n",
            "Speed: 4.4ms preprocess, 20.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 17.7ms\n",
            "Speed: 4.5ms preprocess, 17.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 17.4ms\n",
            "Speed: 8.6ms preprocess, 17.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 17.5ms\n",
            "Speed: 4.8ms preprocess, 17.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 18.4ms\n",
            "Speed: 4.8ms preprocess, 18.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 person, 17.5ms\n",
            "Speed: 4.3ms preprocess, 17.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 576)\n",
            "/content/drive/MyDrive/Shots/Shot Misses/23.mp4\n",
            "\n",
            "0: 512x640 1 person, 26.5ms\n",
            "Speed: 9.1ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 13.9ms\n",
            "Speed: 8.0ms preprocess, 13.9ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 14.0ms\n",
            "Speed: 9.3ms preprocess, 14.0ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 14.2ms\n",
            "Speed: 5.5ms preprocess, 14.2ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 15.5ms\n",
            "Speed: 4.2ms preprocess, 15.5ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 15.1ms\n",
            "Speed: 4.1ms preprocess, 15.1ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 14.3ms\n",
            "Speed: 4.8ms preprocess, 14.3ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 17.5ms\n",
            "Speed: 4.0ms preprocess, 17.5ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 21.0ms\n",
            "Speed: 5.4ms preprocess, 21.0ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 17.9ms\n",
            "Speed: 4.3ms preprocess, 17.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 15.8ms\n",
            "Speed: 4.3ms preprocess, 15.8ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.0ms\n",
            "Speed: 5.1ms preprocess, 19.0ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 15.8ms\n",
            "Speed: 4.0ms preprocess, 15.8ms inference, 4.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 16.3ms\n",
            "Speed: 23.7ms preprocess, 16.3ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.7ms\n",
            "Speed: 5.7ms preprocess, 19.7ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 14.7ms\n",
            "Speed: 3.9ms preprocess, 14.7ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 15.2ms\n",
            "Speed: 4.0ms preprocess, 15.2ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 15.8ms\n",
            "Speed: 3.7ms preprocess, 15.8ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 16.5ms\n",
            "Speed: 4.0ms preprocess, 16.5ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 17.5ms\n",
            "Speed: 4.0ms preprocess, 17.5ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 17.5ms\n",
            "Speed: 4.9ms preprocess, 17.5ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 17.5ms\n",
            "Speed: 3.8ms preprocess, 17.5ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 17.6ms\n",
            "Speed: 3.7ms preprocess, 17.6ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 17.5ms\n",
            "Speed: 3.8ms preprocess, 17.5ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 17.5ms\n",
            "Speed: 4.2ms preprocess, 17.5ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 18.4ms\n",
            "Speed: 3.8ms preprocess, 18.4ms inference, 2.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 18.2ms\n",
            "Speed: 7.4ms preprocess, 18.2ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 20.0ms\n",
            "Speed: 10.0ms preprocess, 20.0ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 17.9ms\n",
            "Speed: 3.9ms preprocess, 17.9ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 18.6ms\n",
            "Speed: 4.7ms preprocess, 18.6ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 18.5ms\n",
            "Speed: 4.2ms preprocess, 18.5ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 18.3ms\n",
            "Speed: 4.1ms preprocess, 18.3ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 18.2ms\n",
            "Speed: 4.7ms preprocess, 18.2ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 21.5ms\n",
            "Speed: 4.3ms preprocess, 21.5ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.9ms\n",
            "Speed: 4.1ms preprocess, 19.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 18.3ms\n",
            "Speed: 4.0ms preprocess, 18.3ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.1ms\n",
            "Speed: 6.4ms preprocess, 19.1ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.5ms\n",
            "Speed: 3.7ms preprocess, 19.5ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 18.8ms\n",
            "Speed: 4.3ms preprocess, 18.8ms inference, 4.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.0ms\n",
            "Speed: 4.9ms preprocess, 19.0ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.0ms\n",
            "Speed: 4.7ms preprocess, 19.0ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.1ms\n",
            "Speed: 7.4ms preprocess, 19.1ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.4ms\n",
            "Speed: 4.3ms preprocess, 19.4ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 29.6ms\n",
            "Speed: 3.8ms preprocess, 29.6ms inference, 2.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.2ms\n",
            "Speed: 3.6ms preprocess, 19.2ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.2ms\n",
            "Speed: 3.7ms preprocess, 19.2ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.4ms\n",
            "Speed: 6.1ms preprocess, 19.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.4ms\n",
            "Speed: 3.5ms preprocess, 19.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.4ms\n",
            "Speed: 4.5ms preprocess, 19.4ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.5ms\n",
            "Speed: 3.8ms preprocess, 19.5ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.7ms\n",
            "Speed: 6.6ms preprocess, 19.7ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.7ms\n",
            "Speed: 6.6ms preprocess, 19.7ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.6ms\n",
            "Speed: 6.0ms preprocess, 19.6ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.8ms\n",
            "Speed: 6.8ms preprocess, 19.8ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.9ms\n",
            "Speed: 4.0ms preprocess, 19.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 20.5ms\n",
            "Speed: 3.7ms preprocess, 20.5ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 23.0ms\n",
            "Speed: 5.9ms preprocess, 23.0ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 20.0ms\n",
            "Speed: 4.5ms preprocess, 20.0ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 19.9ms\n",
            "Speed: 3.8ms preprocess, 19.9ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 person, 20.4ms\n",
            "Speed: 3.8ms preprocess, 20.4ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_xy_coord_fin_misses"
      ],
      "metadata": {
        "id": "zbFbbIedtzSY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "c8d3e5dd-cd48-49ea-89b1-f632c1bd066a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             0         1         2         3         4         5    6    7  \\\n",
              "0     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.0   \n",
              "1     0.244748  0.469072  0.242726  0.463604  0.237798  0.466227  0.0  0.0   \n",
              "2     0.241856  0.469719  0.240809  0.463748  0.234975  0.466184  0.0  0.0   \n",
              "3     0.240319  0.473987  0.239087  0.467859  0.233368  0.470006  0.0  0.0   \n",
              "4     0.238371  0.475059  0.000000  0.000000  0.231190  0.471483  0.0  0.0   \n",
              "...        ...       ...       ...       ...       ...       ...  ...  ...   \n",
              "1095  0.375570  0.399020  0.372361  0.393344  0.369477  0.393789  0.0  0.0   \n",
              "1096  0.375842  0.398520  0.372638  0.392600  0.369709  0.393252  0.0  0.0   \n",
              "1097  0.376478  0.398737  0.372547  0.392018  0.370101  0.392954  0.0  0.0   \n",
              "1098  0.376569  0.398836  0.000000  0.000000  0.369938  0.392954  0.0  0.0   \n",
              "1099  0.376443  0.399309  0.000000  0.000000  0.370517  0.392972  0.0  0.0   \n",
              "\n",
              "             8         9  ...        27        28        29        30  \\\n",
              "0     0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "1     0.224721  0.481162  ...  0.698153  0.228349  0.704048  0.229006   \n",
              "2     0.222226  0.479791  ...  0.698162  0.228678  0.705289  0.228929   \n",
              "3     0.219059  0.482814  ...  0.699723  0.227879  0.709614  0.226327   \n",
              "4     0.216147  0.485944  ...  0.701566  0.229911  0.712696  0.224901   \n",
              "...        ...       ...  ...       ...       ...       ...       ...   \n",
              "1095  0.351877  0.405190  ...  0.641477  0.358902  0.647209  0.351591   \n",
              "1096  0.351811  0.404797  ...  0.639471  0.360213  0.645472  0.350392   \n",
              "1097  0.351889  0.404138  ...  0.638220  0.357322  0.644855  0.353428   \n",
              "1098  0.351718  0.403736  ...  0.638895  0.352830  0.644631  0.350808   \n",
              "1099  0.352782  0.402610  ...  0.635436  0.358017  0.645474  0.351226   \n",
              "\n",
              "            31        32        33   video  label  frame_number  \n",
              "0     0.000000  0.000000  0.000000   1.mp4      0             1  \n",
              "1     0.773553  0.214974  0.781680   1.mp4      0             2  \n",
              "2     0.773118  0.213182  0.782527   1.mp4      0             3  \n",
              "3     0.772932  0.211209  0.787645   1.mp4      0             4  \n",
              "4     0.772323  0.208862  0.788640   1.mp4      0             5  \n",
              "...        ...       ...       ...     ...    ...           ...  \n",
              "1095  0.734951  0.334408  0.744310  23.mp4      0            57  \n",
              "1096  0.734034  0.335498  0.741388  23.mp4      0            58  \n",
              "1097  0.732414  0.332303  0.740661  23.mp4      0            59  \n",
              "1098  0.733159  0.334628  0.740569  23.mp4      0            60  \n",
              "1099  0.730695  0.334544  0.740200  23.mp4      0            61  \n",
              "\n",
              "[1100 rows x 37 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-41a326ed-274a-42cf-a44e-58e5167dbd6d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>video</th>\n",
              "      <th>label</th>\n",
              "      <th>frame_number</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.244748</td>\n",
              "      <td>0.469072</td>\n",
              "      <td>0.242726</td>\n",
              "      <td>0.463604</td>\n",
              "      <td>0.237798</td>\n",
              "      <td>0.466227</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.224721</td>\n",
              "      <td>0.481162</td>\n",
              "      <td>...</td>\n",
              "      <td>0.698153</td>\n",
              "      <td>0.228349</td>\n",
              "      <td>0.704048</td>\n",
              "      <td>0.229006</td>\n",
              "      <td>0.773553</td>\n",
              "      <td>0.214974</td>\n",
              "      <td>0.781680</td>\n",
              "      <td>1.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.241856</td>\n",
              "      <td>0.469719</td>\n",
              "      <td>0.240809</td>\n",
              "      <td>0.463748</td>\n",
              "      <td>0.234975</td>\n",
              "      <td>0.466184</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.222226</td>\n",
              "      <td>0.479791</td>\n",
              "      <td>...</td>\n",
              "      <td>0.698162</td>\n",
              "      <td>0.228678</td>\n",
              "      <td>0.705289</td>\n",
              "      <td>0.228929</td>\n",
              "      <td>0.773118</td>\n",
              "      <td>0.213182</td>\n",
              "      <td>0.782527</td>\n",
              "      <td>1.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.240319</td>\n",
              "      <td>0.473987</td>\n",
              "      <td>0.239087</td>\n",
              "      <td>0.467859</td>\n",
              "      <td>0.233368</td>\n",
              "      <td>0.470006</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.219059</td>\n",
              "      <td>0.482814</td>\n",
              "      <td>...</td>\n",
              "      <td>0.699723</td>\n",
              "      <td>0.227879</td>\n",
              "      <td>0.709614</td>\n",
              "      <td>0.226327</td>\n",
              "      <td>0.772932</td>\n",
              "      <td>0.211209</td>\n",
              "      <td>0.787645</td>\n",
              "      <td>1.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.238371</td>\n",
              "      <td>0.475059</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.231190</td>\n",
              "      <td>0.471483</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.216147</td>\n",
              "      <td>0.485944</td>\n",
              "      <td>...</td>\n",
              "      <td>0.701566</td>\n",
              "      <td>0.229911</td>\n",
              "      <td>0.712696</td>\n",
              "      <td>0.224901</td>\n",
              "      <td>0.772323</td>\n",
              "      <td>0.208862</td>\n",
              "      <td>0.788640</td>\n",
              "      <td>1.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1095</th>\n",
              "      <td>0.375570</td>\n",
              "      <td>0.399020</td>\n",
              "      <td>0.372361</td>\n",
              "      <td>0.393344</td>\n",
              "      <td>0.369477</td>\n",
              "      <td>0.393789</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.351877</td>\n",
              "      <td>0.405190</td>\n",
              "      <td>...</td>\n",
              "      <td>0.641477</td>\n",
              "      <td>0.358902</td>\n",
              "      <td>0.647209</td>\n",
              "      <td>0.351591</td>\n",
              "      <td>0.734951</td>\n",
              "      <td>0.334408</td>\n",
              "      <td>0.744310</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1096</th>\n",
              "      <td>0.375842</td>\n",
              "      <td>0.398520</td>\n",
              "      <td>0.372638</td>\n",
              "      <td>0.392600</td>\n",
              "      <td>0.369709</td>\n",
              "      <td>0.393252</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.351811</td>\n",
              "      <td>0.404797</td>\n",
              "      <td>...</td>\n",
              "      <td>0.639471</td>\n",
              "      <td>0.360213</td>\n",
              "      <td>0.645472</td>\n",
              "      <td>0.350392</td>\n",
              "      <td>0.734034</td>\n",
              "      <td>0.335498</td>\n",
              "      <td>0.741388</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1097</th>\n",
              "      <td>0.376478</td>\n",
              "      <td>0.398737</td>\n",
              "      <td>0.372547</td>\n",
              "      <td>0.392018</td>\n",
              "      <td>0.370101</td>\n",
              "      <td>0.392954</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.351889</td>\n",
              "      <td>0.404138</td>\n",
              "      <td>...</td>\n",
              "      <td>0.638220</td>\n",
              "      <td>0.357322</td>\n",
              "      <td>0.644855</td>\n",
              "      <td>0.353428</td>\n",
              "      <td>0.732414</td>\n",
              "      <td>0.332303</td>\n",
              "      <td>0.740661</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1098</th>\n",
              "      <td>0.376569</td>\n",
              "      <td>0.398836</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.369938</td>\n",
              "      <td>0.392954</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.351718</td>\n",
              "      <td>0.403736</td>\n",
              "      <td>...</td>\n",
              "      <td>0.638895</td>\n",
              "      <td>0.352830</td>\n",
              "      <td>0.644631</td>\n",
              "      <td>0.350808</td>\n",
              "      <td>0.733159</td>\n",
              "      <td>0.334628</td>\n",
              "      <td>0.740569</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099</th>\n",
              "      <td>0.376443</td>\n",
              "      <td>0.399309</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.370517</td>\n",
              "      <td>0.392972</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.352782</td>\n",
              "      <td>0.402610</td>\n",
              "      <td>...</td>\n",
              "      <td>0.635436</td>\n",
              "      <td>0.358017</td>\n",
              "      <td>0.645474</td>\n",
              "      <td>0.351226</td>\n",
              "      <td>0.730695</td>\n",
              "      <td>0.334544</td>\n",
              "      <td>0.740200</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1100 rows × 37 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41a326ed-274a-42cf-a44e-58e5167dbd6d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-41a326ed-274a-42cf-a44e-58e5167dbd6d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-41a326ed-274a-42cf-a44e-58e5167dbd6d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a079d3d1-db71-4ad0-b8dc-aa477d5035eb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a079d3d1-db71-4ad0-b8dc-aa477d5035eb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a079d3d1-db71-4ad0-b8dc-aa477d5035eb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_680eb1ce-1d06-41f6-8cc2-148855babb8d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_xy_coord_fin_misses')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_680eb1ce-1d06-41f6-8cc2-148855babb8d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_xy_coord_fin_misses');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_all_coord = pd.concat([df_xy_coord_fin, df_xy_coord_fin_misses], ignore_index=True)\n",
        "df_all_coord"
      ],
      "metadata": {
        "id": "xYBwSwYi5JU4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "outputId": "e55f6632-3318-4d5c-cb20-b5c44cbb86b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             0         1         2         3         4         5    6    7  \\\n",
              "0     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.0   \n",
              "1     0.141942  0.519379  0.140354  0.512539  0.133615  0.515330  0.0  0.0   \n",
              "2     0.143001  0.522868  0.140956  0.515682  0.134432  0.518720  0.0  0.0   \n",
              "3     0.142824  0.530111  0.000000  0.000000  0.134676  0.526676  0.0  0.0   \n",
              "4     0.145013  0.539606  0.000000  0.000000  0.137419  0.535154  0.0  0.0   \n",
              "...        ...       ...       ...       ...       ...       ...  ...  ...   \n",
              "2543  0.375570  0.399020  0.372361  0.393344  0.369477  0.393789  0.0  0.0   \n",
              "2544  0.375842  0.398520  0.372638  0.392600  0.369709  0.393252  0.0  0.0   \n",
              "2545  0.376478  0.398737  0.372547  0.392018  0.370101  0.392954  0.0  0.0   \n",
              "2546  0.376569  0.398836  0.000000  0.000000  0.369938  0.392954  0.0  0.0   \n",
              "2547  0.376443  0.399309  0.000000  0.000000  0.370517  0.392972  0.0  0.0   \n",
              "\n",
              "             8         9  ...        27        28        29        30  \\\n",
              "0     0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "1     0.117914  0.528823  ...  0.749542  0.120475  0.763546  0.123502   \n",
              "2     0.117831  0.532366  ...  0.750962  0.130295  0.763179  0.125134   \n",
              "3     0.118476  0.540698  ...  0.754452  0.135328  0.768395  0.123493   \n",
              "4     0.120887  0.547287  ...  0.762864  0.137136  0.777557  0.118015   \n",
              "...        ...       ...  ...       ...       ...       ...       ...   \n",
              "2543  0.351877  0.405190  ...  0.641477  0.358902  0.647209  0.351591   \n",
              "2544  0.351811  0.404797  ...  0.639471  0.360213  0.645472  0.350392   \n",
              "2545  0.351889  0.404138  ...  0.638220  0.357322  0.644855  0.353428   \n",
              "2546  0.351718  0.403736  ...  0.638895  0.352830  0.644631  0.350808   \n",
              "2547  0.352782  0.402610  ...  0.635436  0.358017  0.645474  0.351226   \n",
              "\n",
              "            31        32        33             video  label  frame_number  \n",
              "0     0.000000  0.000000  0.000000  ankur-make-1.mp4      1             1  \n",
              "1     0.825739  0.101721  0.848228  ankur-make-1.mp4      1             2  \n",
              "2     0.828403  0.102264  0.846033  ankur-make-1.mp4      1             3  \n",
              "3     0.830647  0.105687  0.852329  ankur-make-1.mp4      1             4  \n",
              "4     0.833874  0.108978  0.855727  ankur-make-1.mp4      1             5  \n",
              "...        ...       ...       ...               ...    ...           ...  \n",
              "2543  0.734951  0.334408  0.744310            23.mp4      0            57  \n",
              "2544  0.734034  0.335498  0.741388            23.mp4      0            58  \n",
              "2545  0.732414  0.332303  0.740661            23.mp4      0            59  \n",
              "2546  0.733159  0.334628  0.740569            23.mp4      0            60  \n",
              "2547  0.730695  0.334544  0.740200            23.mp4      0            61  \n",
              "\n",
              "[2548 rows x 37 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4f987dce-f207-4dc0-a516-e3e3692965f9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>video</th>\n",
              "      <th>label</th>\n",
              "      <th>frame_number</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.141942</td>\n",
              "      <td>0.519379</td>\n",
              "      <td>0.140354</td>\n",
              "      <td>0.512539</td>\n",
              "      <td>0.133615</td>\n",
              "      <td>0.515330</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.117914</td>\n",
              "      <td>0.528823</td>\n",
              "      <td>...</td>\n",
              "      <td>0.749542</td>\n",
              "      <td>0.120475</td>\n",
              "      <td>0.763546</td>\n",
              "      <td>0.123502</td>\n",
              "      <td>0.825739</td>\n",
              "      <td>0.101721</td>\n",
              "      <td>0.848228</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.143001</td>\n",
              "      <td>0.522868</td>\n",
              "      <td>0.140956</td>\n",
              "      <td>0.515682</td>\n",
              "      <td>0.134432</td>\n",
              "      <td>0.518720</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.117831</td>\n",
              "      <td>0.532366</td>\n",
              "      <td>...</td>\n",
              "      <td>0.750962</td>\n",
              "      <td>0.130295</td>\n",
              "      <td>0.763179</td>\n",
              "      <td>0.125134</td>\n",
              "      <td>0.828403</td>\n",
              "      <td>0.102264</td>\n",
              "      <td>0.846033</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.142824</td>\n",
              "      <td>0.530111</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.134676</td>\n",
              "      <td>0.526676</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.118476</td>\n",
              "      <td>0.540698</td>\n",
              "      <td>...</td>\n",
              "      <td>0.754452</td>\n",
              "      <td>0.135328</td>\n",
              "      <td>0.768395</td>\n",
              "      <td>0.123493</td>\n",
              "      <td>0.830647</td>\n",
              "      <td>0.105687</td>\n",
              "      <td>0.852329</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.145013</td>\n",
              "      <td>0.539606</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.137419</td>\n",
              "      <td>0.535154</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.120887</td>\n",
              "      <td>0.547287</td>\n",
              "      <td>...</td>\n",
              "      <td>0.762864</td>\n",
              "      <td>0.137136</td>\n",
              "      <td>0.777557</td>\n",
              "      <td>0.118015</td>\n",
              "      <td>0.833874</td>\n",
              "      <td>0.108978</td>\n",
              "      <td>0.855727</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2543</th>\n",
              "      <td>0.375570</td>\n",
              "      <td>0.399020</td>\n",
              "      <td>0.372361</td>\n",
              "      <td>0.393344</td>\n",
              "      <td>0.369477</td>\n",
              "      <td>0.393789</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.351877</td>\n",
              "      <td>0.405190</td>\n",
              "      <td>...</td>\n",
              "      <td>0.641477</td>\n",
              "      <td>0.358902</td>\n",
              "      <td>0.647209</td>\n",
              "      <td>0.351591</td>\n",
              "      <td>0.734951</td>\n",
              "      <td>0.334408</td>\n",
              "      <td>0.744310</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2544</th>\n",
              "      <td>0.375842</td>\n",
              "      <td>0.398520</td>\n",
              "      <td>0.372638</td>\n",
              "      <td>0.392600</td>\n",
              "      <td>0.369709</td>\n",
              "      <td>0.393252</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.351811</td>\n",
              "      <td>0.404797</td>\n",
              "      <td>...</td>\n",
              "      <td>0.639471</td>\n",
              "      <td>0.360213</td>\n",
              "      <td>0.645472</td>\n",
              "      <td>0.350392</td>\n",
              "      <td>0.734034</td>\n",
              "      <td>0.335498</td>\n",
              "      <td>0.741388</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2545</th>\n",
              "      <td>0.376478</td>\n",
              "      <td>0.398737</td>\n",
              "      <td>0.372547</td>\n",
              "      <td>0.392018</td>\n",
              "      <td>0.370101</td>\n",
              "      <td>0.392954</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.351889</td>\n",
              "      <td>0.404138</td>\n",
              "      <td>...</td>\n",
              "      <td>0.638220</td>\n",
              "      <td>0.357322</td>\n",
              "      <td>0.644855</td>\n",
              "      <td>0.353428</td>\n",
              "      <td>0.732414</td>\n",
              "      <td>0.332303</td>\n",
              "      <td>0.740661</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2546</th>\n",
              "      <td>0.376569</td>\n",
              "      <td>0.398836</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.369938</td>\n",
              "      <td>0.392954</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.351718</td>\n",
              "      <td>0.403736</td>\n",
              "      <td>...</td>\n",
              "      <td>0.638895</td>\n",
              "      <td>0.352830</td>\n",
              "      <td>0.644631</td>\n",
              "      <td>0.350808</td>\n",
              "      <td>0.733159</td>\n",
              "      <td>0.334628</td>\n",
              "      <td>0.740569</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2547</th>\n",
              "      <td>0.376443</td>\n",
              "      <td>0.399309</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.370517</td>\n",
              "      <td>0.392972</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.352782</td>\n",
              "      <td>0.402610</td>\n",
              "      <td>...</td>\n",
              "      <td>0.635436</td>\n",
              "      <td>0.358017</td>\n",
              "      <td>0.645474</td>\n",
              "      <td>0.351226</td>\n",
              "      <td>0.730695</td>\n",
              "      <td>0.334544</td>\n",
              "      <td>0.740200</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2548 rows × 37 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4f987dce-f207-4dc0-a516-e3e3692965f9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4f987dce-f207-4dc0-a516-e3e3692965f9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4f987dce-f207-4dc0-a516-e3e3692965f9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1e435df1-eab4-4d5e-87fb-4d2b2b41f6e7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1e435df1-eab4-4d5e-87fb-4d2b2b41f6e7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1e435df1-eab4-4d5e-87fb-4d2b2b41f6e7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_120de151-6bd4-4ffd-8f88-2e0b9a62303c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_all_coord')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_120de151-6bd4-4ffd-8f88-2e0b9a62303c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_all_coord');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_all_coord.isna().sum()"
      ],
      "metadata": {
        "id": "PPAaNM_u3_Pa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48a97672-b61d-4988-9993-7cb4eddfe49e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0               0\n",
              "1               0\n",
              "2               0\n",
              "3               0\n",
              "4               0\n",
              "5               0\n",
              "6               0\n",
              "7               0\n",
              "8               0\n",
              "9               0\n",
              "10              0\n",
              "11              0\n",
              "12              0\n",
              "13              0\n",
              "14              0\n",
              "15              0\n",
              "16              0\n",
              "17              0\n",
              "18              0\n",
              "19              0\n",
              "20              0\n",
              "21              0\n",
              "22              0\n",
              "23              0\n",
              "24              0\n",
              "25              0\n",
              "26              0\n",
              "27              0\n",
              "28              0\n",
              "29              0\n",
              "30              0\n",
              "31              0\n",
              "32              0\n",
              "33              0\n",
              "video           0\n",
              "label           0\n",
              "frame_number    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Label the dataset with columns with different parts and their X and Y coordinates"
      ],
      "metadata": {
        "id": "omBw9-gmPSWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "body_parts = [\n",
        "'Nose',\n",
        "'Left_eye',\n",
        "'Right_eye',\n",
        "'Left_ear',\n",
        "'Right_ear',\n",
        "'Left_shoulder',\n",
        "'Right_shoulder',\n",
        "'Left_elbow',\n",
        " 'Right_elbow',\n",
        "'Left_wrist',\n",
        "'Right_wrist',\n",
        "'Left_hip',\n",
        "'Right_hip',\n",
        "'Left_knee',\n",
        "'Right_knee',\n",
        "'Left_ankle',\n",
        "'Right_ankle']\n",
        "\n",
        "new_body_parts = []\n",
        "\n",
        "for i in range(0,len(body_parts)):\n",
        "\n",
        "  new_body_parts.append(body_parts[i] + '_x')\n",
        "  new_body_parts.append(body_parts[i] + '_y')\n",
        "\n",
        "num_list=[i for i in range(0,len(new_body_parts))]\n",
        "\n",
        "print(new_body_parts)\n",
        "print(num_list)"
      ],
      "metadata": {
        "id": "pqpnCImG6PY6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ffa3400-ed72-44f3-d464-683f095c37cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Nose_x', 'Nose_y', 'Left_eye_x', 'Left_eye_y', 'Right_eye_x', 'Right_eye_y', 'Left_ear_x', 'Left_ear_y', 'Right_ear_x', 'Right_ear_y', 'Left_shoulder_x', 'Left_shoulder_y', 'Right_shoulder_x', 'Right_shoulder_y', 'Left_elbow_x', 'Left_elbow_y', 'Right_elbow_x', 'Right_elbow_y', 'Left_wrist_x', 'Left_wrist_y', 'Right_wrist_x', 'Right_wrist_y', 'Left_hip_x', 'Left_hip_y', 'Right_hip_x', 'Right_hip_y', 'Left_knee_x', 'Left_knee_y', 'Right_knee_x', 'Right_knee_y', 'Left_ankle_x', 'Left_ankle_y', 'Right_ankle_x', 'Right_ankle_y']\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Make a dictionary to rename columns"
      ],
      "metadata": {
        "id": "3jXW_fPAQZAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dict_body = {}\n",
        "for i in range(len(new_body_parts)):\n",
        "    dict_body[num_list[i]] = new_body_parts[i]\n",
        "print(dict_body)"
      ],
      "metadata": {
        "id": "ED5AeQwl6Ual",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "556c3eb8-d726-4e01-c4ee-6b4f2812cb5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'Nose_x', 1: 'Nose_y', 2: 'Left_eye_x', 3: 'Left_eye_y', 4: 'Right_eye_x', 5: 'Right_eye_y', 6: 'Left_ear_x', 7: 'Left_ear_y', 8: 'Right_ear_x', 9: 'Right_ear_y', 10: 'Left_shoulder_x', 11: 'Left_shoulder_y', 12: 'Right_shoulder_x', 13: 'Right_shoulder_y', 14: 'Left_elbow_x', 15: 'Left_elbow_y', 16: 'Right_elbow_x', 17: 'Right_elbow_y', 18: 'Left_wrist_x', 19: 'Left_wrist_y', 20: 'Right_wrist_x', 21: 'Right_wrist_y', 22: 'Left_hip_x', 23: 'Left_hip_y', 24: 'Right_hip_x', 25: 'Right_hip_y', 26: 'Left_knee_x', 27: 'Left_knee_y', 28: 'Right_knee_x', 29: 'Right_knee_y', 30: 'Left_ankle_x', 31: 'Left_ankle_y', 32: 'Right_ankle_x', 33: 'Right_ankle_y'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_all_coord.rename(columns=dict_body, inplace=True)\n",
        "\n",
        "df_all_coord"
      ],
      "metadata": {
        "id": "bfHYU_C66YlY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "outputId": "b5e5939d-040a-4808-b71c-97fc8707db8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Nose_x    Nose_y  Left_eye_x  Left_eye_y  Right_eye_x  Right_eye_y  \\\n",
              "0     0.000000  0.000000    0.000000    0.000000     0.000000     0.000000   \n",
              "1     0.141942  0.519379    0.140354    0.512539     0.133615     0.515330   \n",
              "2     0.143001  0.522868    0.140956    0.515682     0.134432     0.518720   \n",
              "3     0.142824  0.530111    0.000000    0.000000     0.134676     0.526676   \n",
              "4     0.145013  0.539606    0.000000    0.000000     0.137419     0.535154   \n",
              "...        ...       ...         ...         ...          ...          ...   \n",
              "2543  0.375570  0.399020    0.372361    0.393344     0.369477     0.393789   \n",
              "2544  0.375842  0.398520    0.372638    0.392600     0.369709     0.393252   \n",
              "2545  0.376478  0.398737    0.372547    0.392018     0.370101     0.392954   \n",
              "2546  0.376569  0.398836    0.000000    0.000000     0.369938     0.392954   \n",
              "2547  0.376443  0.399309    0.000000    0.000000     0.370517     0.392972   \n",
              "\n",
              "      Left_ear_x  Left_ear_y  Right_ear_x  Right_ear_y  ...  Left_knee_y  \\\n",
              "0            0.0         0.0     0.000000     0.000000  ...     0.000000   \n",
              "1            0.0         0.0     0.117914     0.528823  ...     0.749542   \n",
              "2            0.0         0.0     0.117831     0.532366  ...     0.750962   \n",
              "3            0.0         0.0     0.118476     0.540698  ...     0.754452   \n",
              "4            0.0         0.0     0.120887     0.547287  ...     0.762864   \n",
              "...          ...         ...          ...          ...  ...          ...   \n",
              "2543         0.0         0.0     0.351877     0.405190  ...     0.641477   \n",
              "2544         0.0         0.0     0.351811     0.404797  ...     0.639471   \n",
              "2545         0.0         0.0     0.351889     0.404138  ...     0.638220   \n",
              "2546         0.0         0.0     0.351718     0.403736  ...     0.638895   \n",
              "2547         0.0         0.0     0.352782     0.402610  ...     0.635436   \n",
              "\n",
              "      Right_knee_x  Right_knee_y  Left_ankle_x  Left_ankle_y  Right_ankle_x  \\\n",
              "0         0.000000      0.000000      0.000000      0.000000       0.000000   \n",
              "1         0.120475      0.763546      0.123502      0.825739       0.101721   \n",
              "2         0.130295      0.763179      0.125134      0.828403       0.102264   \n",
              "3         0.135328      0.768395      0.123493      0.830647       0.105687   \n",
              "4         0.137136      0.777557      0.118015      0.833874       0.108978   \n",
              "...            ...           ...           ...           ...            ...   \n",
              "2543      0.358902      0.647209      0.351591      0.734951       0.334408   \n",
              "2544      0.360213      0.645472      0.350392      0.734034       0.335498   \n",
              "2545      0.357322      0.644855      0.353428      0.732414       0.332303   \n",
              "2546      0.352830      0.644631      0.350808      0.733159       0.334628   \n",
              "2547      0.358017      0.645474      0.351226      0.730695       0.334544   \n",
              "\n",
              "      Right_ankle_y             video  label  frame_number  \n",
              "0          0.000000  ankur-make-1.mp4      1             1  \n",
              "1          0.848228  ankur-make-1.mp4      1             2  \n",
              "2          0.846033  ankur-make-1.mp4      1             3  \n",
              "3          0.852329  ankur-make-1.mp4      1             4  \n",
              "4          0.855727  ankur-make-1.mp4      1             5  \n",
              "...             ...               ...    ...           ...  \n",
              "2543       0.744310            23.mp4      0            57  \n",
              "2544       0.741388            23.mp4      0            58  \n",
              "2545       0.740661            23.mp4      0            59  \n",
              "2546       0.740569            23.mp4      0            60  \n",
              "2547       0.740200            23.mp4      0            61  \n",
              "\n",
              "[2548 rows x 37 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d6258a09-4eec-4fd3-bcfc-f737804020ae\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Nose_x</th>\n",
              "      <th>Nose_y</th>\n",
              "      <th>Left_eye_x</th>\n",
              "      <th>Left_eye_y</th>\n",
              "      <th>Right_eye_x</th>\n",
              "      <th>Right_eye_y</th>\n",
              "      <th>Left_ear_x</th>\n",
              "      <th>Left_ear_y</th>\n",
              "      <th>Right_ear_x</th>\n",
              "      <th>Right_ear_y</th>\n",
              "      <th>...</th>\n",
              "      <th>Left_knee_y</th>\n",
              "      <th>Right_knee_x</th>\n",
              "      <th>Right_knee_y</th>\n",
              "      <th>Left_ankle_x</th>\n",
              "      <th>Left_ankle_y</th>\n",
              "      <th>Right_ankle_x</th>\n",
              "      <th>Right_ankle_y</th>\n",
              "      <th>video</th>\n",
              "      <th>label</th>\n",
              "      <th>frame_number</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.141942</td>\n",
              "      <td>0.519379</td>\n",
              "      <td>0.140354</td>\n",
              "      <td>0.512539</td>\n",
              "      <td>0.133615</td>\n",
              "      <td>0.515330</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.117914</td>\n",
              "      <td>0.528823</td>\n",
              "      <td>...</td>\n",
              "      <td>0.749542</td>\n",
              "      <td>0.120475</td>\n",
              "      <td>0.763546</td>\n",
              "      <td>0.123502</td>\n",
              "      <td>0.825739</td>\n",
              "      <td>0.101721</td>\n",
              "      <td>0.848228</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.143001</td>\n",
              "      <td>0.522868</td>\n",
              "      <td>0.140956</td>\n",
              "      <td>0.515682</td>\n",
              "      <td>0.134432</td>\n",
              "      <td>0.518720</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.117831</td>\n",
              "      <td>0.532366</td>\n",
              "      <td>...</td>\n",
              "      <td>0.750962</td>\n",
              "      <td>0.130295</td>\n",
              "      <td>0.763179</td>\n",
              "      <td>0.125134</td>\n",
              "      <td>0.828403</td>\n",
              "      <td>0.102264</td>\n",
              "      <td>0.846033</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.142824</td>\n",
              "      <td>0.530111</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.134676</td>\n",
              "      <td>0.526676</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.118476</td>\n",
              "      <td>0.540698</td>\n",
              "      <td>...</td>\n",
              "      <td>0.754452</td>\n",
              "      <td>0.135328</td>\n",
              "      <td>0.768395</td>\n",
              "      <td>0.123493</td>\n",
              "      <td>0.830647</td>\n",
              "      <td>0.105687</td>\n",
              "      <td>0.852329</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.145013</td>\n",
              "      <td>0.539606</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.137419</td>\n",
              "      <td>0.535154</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.120887</td>\n",
              "      <td>0.547287</td>\n",
              "      <td>...</td>\n",
              "      <td>0.762864</td>\n",
              "      <td>0.137136</td>\n",
              "      <td>0.777557</td>\n",
              "      <td>0.118015</td>\n",
              "      <td>0.833874</td>\n",
              "      <td>0.108978</td>\n",
              "      <td>0.855727</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2543</th>\n",
              "      <td>0.375570</td>\n",
              "      <td>0.399020</td>\n",
              "      <td>0.372361</td>\n",
              "      <td>0.393344</td>\n",
              "      <td>0.369477</td>\n",
              "      <td>0.393789</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.351877</td>\n",
              "      <td>0.405190</td>\n",
              "      <td>...</td>\n",
              "      <td>0.641477</td>\n",
              "      <td>0.358902</td>\n",
              "      <td>0.647209</td>\n",
              "      <td>0.351591</td>\n",
              "      <td>0.734951</td>\n",
              "      <td>0.334408</td>\n",
              "      <td>0.744310</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2544</th>\n",
              "      <td>0.375842</td>\n",
              "      <td>0.398520</td>\n",
              "      <td>0.372638</td>\n",
              "      <td>0.392600</td>\n",
              "      <td>0.369709</td>\n",
              "      <td>0.393252</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.351811</td>\n",
              "      <td>0.404797</td>\n",
              "      <td>...</td>\n",
              "      <td>0.639471</td>\n",
              "      <td>0.360213</td>\n",
              "      <td>0.645472</td>\n",
              "      <td>0.350392</td>\n",
              "      <td>0.734034</td>\n",
              "      <td>0.335498</td>\n",
              "      <td>0.741388</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2545</th>\n",
              "      <td>0.376478</td>\n",
              "      <td>0.398737</td>\n",
              "      <td>0.372547</td>\n",
              "      <td>0.392018</td>\n",
              "      <td>0.370101</td>\n",
              "      <td>0.392954</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.351889</td>\n",
              "      <td>0.404138</td>\n",
              "      <td>...</td>\n",
              "      <td>0.638220</td>\n",
              "      <td>0.357322</td>\n",
              "      <td>0.644855</td>\n",
              "      <td>0.353428</td>\n",
              "      <td>0.732414</td>\n",
              "      <td>0.332303</td>\n",
              "      <td>0.740661</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2546</th>\n",
              "      <td>0.376569</td>\n",
              "      <td>0.398836</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.369938</td>\n",
              "      <td>0.392954</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.351718</td>\n",
              "      <td>0.403736</td>\n",
              "      <td>...</td>\n",
              "      <td>0.638895</td>\n",
              "      <td>0.352830</td>\n",
              "      <td>0.644631</td>\n",
              "      <td>0.350808</td>\n",
              "      <td>0.733159</td>\n",
              "      <td>0.334628</td>\n",
              "      <td>0.740569</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2547</th>\n",
              "      <td>0.376443</td>\n",
              "      <td>0.399309</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.370517</td>\n",
              "      <td>0.392972</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.352782</td>\n",
              "      <td>0.402610</td>\n",
              "      <td>...</td>\n",
              "      <td>0.635436</td>\n",
              "      <td>0.358017</td>\n",
              "      <td>0.645474</td>\n",
              "      <td>0.351226</td>\n",
              "      <td>0.730695</td>\n",
              "      <td>0.334544</td>\n",
              "      <td>0.740200</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2548 rows × 37 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6258a09-4eec-4fd3-bcfc-f737804020ae')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d6258a09-4eec-4fd3-bcfc-f737804020ae button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d6258a09-4eec-4fd3-bcfc-f737804020ae');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-52948e71-bf47-4eda-826c-c1035cf502f0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-52948e71-bf47-4eda-826c-c1035cf502f0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-52948e71-bf47-4eda-826c-c1035cf502f0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_6add2529-bdb1-454c-82ee-79002d0ab8dc\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_all_coord')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6add2529-bdb1-454c-82ee-79002d0ab8dc button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_all_coord');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_all_coord_updated=df_all_coord.loc[:,['Left_shoulder_x','Left_shoulder_y','Right_shoulder_x'   , 'Right_shoulder_y','Left_wrist_y','Left_elbow_x','Left_elbow_y','Right_elbow_x','Right_elbow_y','Left_wrist_x','Left_wrist_y','Right_wrist_x','Right_wrist_y','Left_hip_x','Left_hip_y','Right_hip_x','Right_hip_y','Left_knee_x','Left_knee_y', 'Right_knee_x', 'Right_knee_y','Left_ankle_x', 'Left_ankle_y',  'Right_ankle_x', 'Right_ankle_y','frame_number','video','label']]\n",
        "\n",
        "df_all_coord_updated"
      ],
      "metadata": {
        "id": "s_QG3TY26qMR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "outputId": "3cae4178-e95b-47ba-a408-e2198df9a76d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Left_shoulder_x  Left_shoulder_y  Right_shoulder_x  Right_shoulder_y  \\\n",
              "0            0.000000         0.000000          0.000000          0.000000   \n",
              "1            0.137992         0.567018          0.114047          0.574758   \n",
              "2            0.137748         0.569186          0.115349          0.579705   \n",
              "3            0.135332         0.574709          0.118000          0.584913   \n",
              "4            0.137106         0.581849          0.117793          0.593527   \n",
              "...               ...              ...               ...               ...   \n",
              "2543         0.336772         0.450447          0.361769          0.440221   \n",
              "2544         0.336169         0.446795          0.361282          0.442094   \n",
              "2545         0.336118         0.446699          0.360174          0.445972   \n",
              "2546         0.337864         0.445126          0.358200          0.446341   \n",
              "2547         0.334369         0.441393          0.358173          0.447999   \n",
              "\n",
              "      Left_wrist_y  Left_elbow_x  Left_elbow_y  Right_elbow_x  Right_elbow_y  \\\n",
              "0         0.000000      0.000000      0.000000       0.000000       0.000000   \n",
              "1         0.632627      0.138122      0.620622       0.112386       0.633044   \n",
              "2         0.630857      0.142738      0.619906       0.118926       0.639296   \n",
              "3         0.630535      0.143820      0.624669       0.126229       0.641880   \n",
              "4         0.632422      0.148398      0.628282       0.137886       0.648005   \n",
              "...            ...           ...           ...            ...            ...   \n",
              "2543      0.571684      0.315813      0.510262       0.387930       0.452417   \n",
              "2544      0.569260      0.315534      0.508232       0.381513       0.467133   \n",
              "2545      0.566294      0.317613      0.512701       0.379284       0.479733   \n",
              "2546      0.569123      0.318504      0.510571       0.374125       0.480640   \n",
              "2547      0.570865      0.316519      0.510886       0.367897       0.494650   \n",
              "\n",
              "      Left_wrist_x  ...  Left_knee_y  Right_knee_x  Right_knee_y  \\\n",
              "0         0.000000  ...     0.000000      0.000000      0.000000   \n",
              "1         0.163240  ...     0.749542      0.120475      0.763546   \n",
              "2         0.169016  ...     0.750962      0.130295      0.763179   \n",
              "3         0.169926  ...     0.754452      0.135328      0.768395   \n",
              "4         0.175129  ...     0.762864      0.137136      0.777557   \n",
              "...            ...  ...          ...           ...           ...   \n",
              "2543      0.306920  ...     0.641477      0.358902      0.647209   \n",
              "2544      0.306491  ...     0.639471      0.360213      0.645472   \n",
              "2545      0.307859  ...     0.638220      0.357322      0.644855   \n",
              "2546      0.309391  ...     0.638895      0.352830      0.644631   \n",
              "2547      0.310895  ...     0.635436      0.358017      0.645474   \n",
              "\n",
              "      Left_ankle_x  Left_ankle_y  Right_ankle_x  Right_ankle_y  frame_number  \\\n",
              "0         0.000000      0.000000       0.000000       0.000000             1   \n",
              "1         0.123502      0.825739       0.101721       0.848228             2   \n",
              "2         0.125134      0.828403       0.102264       0.846033             3   \n",
              "3         0.123493      0.830647       0.105687       0.852329             4   \n",
              "4         0.118015      0.833874       0.108978       0.855727             5   \n",
              "...            ...           ...            ...            ...           ...   \n",
              "2543      0.351591      0.734951       0.334408       0.744310            57   \n",
              "2544      0.350392      0.734034       0.335498       0.741388            58   \n",
              "2545      0.353428      0.732414       0.332303       0.740661            59   \n",
              "2546      0.350808      0.733159       0.334628       0.740569            60   \n",
              "2547      0.351226      0.730695       0.334544       0.740200            61   \n",
              "\n",
              "                 video  label  \n",
              "0     ankur-make-1.mp4      1  \n",
              "1     ankur-make-1.mp4      1  \n",
              "2     ankur-make-1.mp4      1  \n",
              "3     ankur-make-1.mp4      1  \n",
              "4     ankur-make-1.mp4      1  \n",
              "...                ...    ...  \n",
              "2543            23.mp4      0  \n",
              "2544            23.mp4      0  \n",
              "2545            23.mp4      0  \n",
              "2546            23.mp4      0  \n",
              "2547            23.mp4      0  \n",
              "\n",
              "[2548 rows x 28 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8281c985-1fc7-431c-a8c7-80878e36702b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Left_shoulder_x</th>\n",
              "      <th>Left_shoulder_y</th>\n",
              "      <th>Right_shoulder_x</th>\n",
              "      <th>Right_shoulder_y</th>\n",
              "      <th>Left_wrist_y</th>\n",
              "      <th>Left_elbow_x</th>\n",
              "      <th>Left_elbow_y</th>\n",
              "      <th>Right_elbow_x</th>\n",
              "      <th>Right_elbow_y</th>\n",
              "      <th>Left_wrist_x</th>\n",
              "      <th>...</th>\n",
              "      <th>Left_knee_y</th>\n",
              "      <th>Right_knee_x</th>\n",
              "      <th>Right_knee_y</th>\n",
              "      <th>Left_ankle_x</th>\n",
              "      <th>Left_ankle_y</th>\n",
              "      <th>Right_ankle_x</th>\n",
              "      <th>Right_ankle_y</th>\n",
              "      <th>frame_number</th>\n",
              "      <th>video</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.137992</td>\n",
              "      <td>0.567018</td>\n",
              "      <td>0.114047</td>\n",
              "      <td>0.574758</td>\n",
              "      <td>0.632627</td>\n",
              "      <td>0.138122</td>\n",
              "      <td>0.620622</td>\n",
              "      <td>0.112386</td>\n",
              "      <td>0.633044</td>\n",
              "      <td>0.163240</td>\n",
              "      <td>...</td>\n",
              "      <td>0.749542</td>\n",
              "      <td>0.120475</td>\n",
              "      <td>0.763546</td>\n",
              "      <td>0.123502</td>\n",
              "      <td>0.825739</td>\n",
              "      <td>0.101721</td>\n",
              "      <td>0.848228</td>\n",
              "      <td>2</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.137748</td>\n",
              "      <td>0.569186</td>\n",
              "      <td>0.115349</td>\n",
              "      <td>0.579705</td>\n",
              "      <td>0.630857</td>\n",
              "      <td>0.142738</td>\n",
              "      <td>0.619906</td>\n",
              "      <td>0.118926</td>\n",
              "      <td>0.639296</td>\n",
              "      <td>0.169016</td>\n",
              "      <td>...</td>\n",
              "      <td>0.750962</td>\n",
              "      <td>0.130295</td>\n",
              "      <td>0.763179</td>\n",
              "      <td>0.125134</td>\n",
              "      <td>0.828403</td>\n",
              "      <td>0.102264</td>\n",
              "      <td>0.846033</td>\n",
              "      <td>3</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.135332</td>\n",
              "      <td>0.574709</td>\n",
              "      <td>0.118000</td>\n",
              "      <td>0.584913</td>\n",
              "      <td>0.630535</td>\n",
              "      <td>0.143820</td>\n",
              "      <td>0.624669</td>\n",
              "      <td>0.126229</td>\n",
              "      <td>0.641880</td>\n",
              "      <td>0.169926</td>\n",
              "      <td>...</td>\n",
              "      <td>0.754452</td>\n",
              "      <td>0.135328</td>\n",
              "      <td>0.768395</td>\n",
              "      <td>0.123493</td>\n",
              "      <td>0.830647</td>\n",
              "      <td>0.105687</td>\n",
              "      <td>0.852329</td>\n",
              "      <td>4</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.137106</td>\n",
              "      <td>0.581849</td>\n",
              "      <td>0.117793</td>\n",
              "      <td>0.593527</td>\n",
              "      <td>0.632422</td>\n",
              "      <td>0.148398</td>\n",
              "      <td>0.628282</td>\n",
              "      <td>0.137886</td>\n",
              "      <td>0.648005</td>\n",
              "      <td>0.175129</td>\n",
              "      <td>...</td>\n",
              "      <td>0.762864</td>\n",
              "      <td>0.137136</td>\n",
              "      <td>0.777557</td>\n",
              "      <td>0.118015</td>\n",
              "      <td>0.833874</td>\n",
              "      <td>0.108978</td>\n",
              "      <td>0.855727</td>\n",
              "      <td>5</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2543</th>\n",
              "      <td>0.336772</td>\n",
              "      <td>0.450447</td>\n",
              "      <td>0.361769</td>\n",
              "      <td>0.440221</td>\n",
              "      <td>0.571684</td>\n",
              "      <td>0.315813</td>\n",
              "      <td>0.510262</td>\n",
              "      <td>0.387930</td>\n",
              "      <td>0.452417</td>\n",
              "      <td>0.306920</td>\n",
              "      <td>...</td>\n",
              "      <td>0.641477</td>\n",
              "      <td>0.358902</td>\n",
              "      <td>0.647209</td>\n",
              "      <td>0.351591</td>\n",
              "      <td>0.734951</td>\n",
              "      <td>0.334408</td>\n",
              "      <td>0.744310</td>\n",
              "      <td>57</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2544</th>\n",
              "      <td>0.336169</td>\n",
              "      <td>0.446795</td>\n",
              "      <td>0.361282</td>\n",
              "      <td>0.442094</td>\n",
              "      <td>0.569260</td>\n",
              "      <td>0.315534</td>\n",
              "      <td>0.508232</td>\n",
              "      <td>0.381513</td>\n",
              "      <td>0.467133</td>\n",
              "      <td>0.306491</td>\n",
              "      <td>...</td>\n",
              "      <td>0.639471</td>\n",
              "      <td>0.360213</td>\n",
              "      <td>0.645472</td>\n",
              "      <td>0.350392</td>\n",
              "      <td>0.734034</td>\n",
              "      <td>0.335498</td>\n",
              "      <td>0.741388</td>\n",
              "      <td>58</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2545</th>\n",
              "      <td>0.336118</td>\n",
              "      <td>0.446699</td>\n",
              "      <td>0.360174</td>\n",
              "      <td>0.445972</td>\n",
              "      <td>0.566294</td>\n",
              "      <td>0.317613</td>\n",
              "      <td>0.512701</td>\n",
              "      <td>0.379284</td>\n",
              "      <td>0.479733</td>\n",
              "      <td>0.307859</td>\n",
              "      <td>...</td>\n",
              "      <td>0.638220</td>\n",
              "      <td>0.357322</td>\n",
              "      <td>0.644855</td>\n",
              "      <td>0.353428</td>\n",
              "      <td>0.732414</td>\n",
              "      <td>0.332303</td>\n",
              "      <td>0.740661</td>\n",
              "      <td>59</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2546</th>\n",
              "      <td>0.337864</td>\n",
              "      <td>0.445126</td>\n",
              "      <td>0.358200</td>\n",
              "      <td>0.446341</td>\n",
              "      <td>0.569123</td>\n",
              "      <td>0.318504</td>\n",
              "      <td>0.510571</td>\n",
              "      <td>0.374125</td>\n",
              "      <td>0.480640</td>\n",
              "      <td>0.309391</td>\n",
              "      <td>...</td>\n",
              "      <td>0.638895</td>\n",
              "      <td>0.352830</td>\n",
              "      <td>0.644631</td>\n",
              "      <td>0.350808</td>\n",
              "      <td>0.733159</td>\n",
              "      <td>0.334628</td>\n",
              "      <td>0.740569</td>\n",
              "      <td>60</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2547</th>\n",
              "      <td>0.334369</td>\n",
              "      <td>0.441393</td>\n",
              "      <td>0.358173</td>\n",
              "      <td>0.447999</td>\n",
              "      <td>0.570865</td>\n",
              "      <td>0.316519</td>\n",
              "      <td>0.510886</td>\n",
              "      <td>0.367897</td>\n",
              "      <td>0.494650</td>\n",
              "      <td>0.310895</td>\n",
              "      <td>...</td>\n",
              "      <td>0.635436</td>\n",
              "      <td>0.358017</td>\n",
              "      <td>0.645474</td>\n",
              "      <td>0.351226</td>\n",
              "      <td>0.730695</td>\n",
              "      <td>0.334544</td>\n",
              "      <td>0.740200</td>\n",
              "      <td>61</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2548 rows × 28 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8281c985-1fc7-431c-a8c7-80878e36702b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8281c985-1fc7-431c-a8c7-80878e36702b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8281c985-1fc7-431c-a8c7-80878e36702b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8938c93e-d558-4e12-9769-3dc9f448b8c5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8938c93e-d558-4e12-9769-3dc9f448b8c5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8938c93e-d558-4e12-9769-3dc9f448b8c5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_5ec7468f-d333-4f5a-ab0f-f6af2786545e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_all_coord_updated')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5ec7468f-d333-4f5a-ab0f-f6af2786545e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_all_coord_updated');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Calculate the angles for different body parts. We use (Y2-Y1)/(X2-X1) to get the slope between the 2 coordinates"
      ],
      "metadata": {
        "id": "ZdFM5Y9kQmKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def angle_calculator(df,var_from, var_to,angle_var):\n",
        "  x_var_from=var_from+'_x'\n",
        "  y_var_from=var_from+'_y'\n",
        "  x_var_to=var_to+'_x'\n",
        "  y_var_to=var_to+'_y'\n",
        "  print(x_var_from,y_var_from,x_var_to,y_var_to)\n",
        "  df[y_var_to] = df[y_var_to].astype(float)\n",
        "  df[y_var_from] = df[y_var_from].astype(float)\n",
        "  df[x_var_to] = df[x_var_to].astype(float)\n",
        "  df[x_var_from] = df[x_var_from].astype(float)\n",
        "  angle_rad = np.arctan2(df[y_var_to] - df[y_var_from], df[x_var_to] - df[x_var_from])\n",
        "  angle_deg = np.degrees(angle_rad)\n",
        "  df[angle_var]=angle_deg\n",
        "  return df"
      ],
      "metadata": {
        "id": "nYS1PoE-lrK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "angle_calculator(df_all_coord_updated,'Right_shoulder','Right_elbow',  'Right_shoulder_angle')\n",
        "df_all_coord_updated"
      ],
      "metadata": {
        "id": "627L-gmC7Jmy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "outputId": "cda74835-0859-4d05-8e87-fe42c38433c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Right_shoulder_x Right_shoulder_y Right_elbow_x Right_elbow_y\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Left_shoulder_x  Left_shoulder_y  Right_shoulder_x  Right_shoulder_y  \\\n",
              "0            0.000000         0.000000          0.000000          0.000000   \n",
              "1            0.137992         0.567018          0.114047          0.574758   \n",
              "2            0.137748         0.569186          0.115349          0.579705   \n",
              "3            0.135332         0.574709          0.118000          0.584913   \n",
              "4            0.137106         0.581849          0.117793          0.593527   \n",
              "...               ...              ...               ...               ...   \n",
              "2543         0.336772         0.450447          0.361769          0.440221   \n",
              "2544         0.336169         0.446795          0.361282          0.442094   \n",
              "2545         0.336118         0.446699          0.360174          0.445972   \n",
              "2546         0.337864         0.445126          0.358200          0.446341   \n",
              "2547         0.334369         0.441393          0.358173          0.447999   \n",
              "\n",
              "      Left_wrist_y  Left_elbow_x  Left_elbow_y  Right_elbow_x  Right_elbow_y  \\\n",
              "0         0.000000      0.000000      0.000000       0.000000       0.000000   \n",
              "1         0.632627      0.138122      0.620622       0.112386       0.633044   \n",
              "2         0.630857      0.142738      0.619906       0.118926       0.639296   \n",
              "3         0.630535      0.143820      0.624669       0.126229       0.641880   \n",
              "4         0.632422      0.148398      0.628282       0.137886       0.648005   \n",
              "...            ...           ...           ...            ...            ...   \n",
              "2543      0.571684      0.315813      0.510262       0.387930       0.452417   \n",
              "2544      0.569260      0.315534      0.508232       0.381513       0.467133   \n",
              "2545      0.566294      0.317613      0.512701       0.379284       0.479733   \n",
              "2546      0.569123      0.318504      0.510571       0.374125       0.480640   \n",
              "2547      0.570865      0.316519      0.510886       0.367897       0.494650   \n",
              "\n",
              "      Left_wrist_x  ...  Right_knee_x  Right_knee_y  Left_ankle_x  \\\n",
              "0         0.000000  ...      0.000000      0.000000      0.000000   \n",
              "1         0.163240  ...      0.120475      0.763546      0.123502   \n",
              "2         0.169016  ...      0.130295      0.763179      0.125134   \n",
              "3         0.169926  ...      0.135328      0.768395      0.123493   \n",
              "4         0.175129  ...      0.137136      0.777557      0.118015   \n",
              "...            ...  ...           ...           ...           ...   \n",
              "2543      0.306920  ...      0.358902      0.647209      0.351591   \n",
              "2544      0.306491  ...      0.360213      0.645472      0.350392   \n",
              "2545      0.307859  ...      0.357322      0.644855      0.353428   \n",
              "2546      0.309391  ...      0.352830      0.644631      0.350808   \n",
              "2547      0.310895  ...      0.358017      0.645474      0.351226   \n",
              "\n",
              "      Left_ankle_y  Right_ankle_x  Right_ankle_y  frame_number  \\\n",
              "0         0.000000       0.000000       0.000000             1   \n",
              "1         0.825739       0.101721       0.848228             2   \n",
              "2         0.828403       0.102264       0.846033             3   \n",
              "3         0.830647       0.105687       0.852329             4   \n",
              "4         0.833874       0.108978       0.855727             5   \n",
              "...            ...            ...            ...           ...   \n",
              "2543      0.734951       0.334408       0.744310            57   \n",
              "2544      0.734034       0.335498       0.741388            58   \n",
              "2545      0.732414       0.332303       0.740661            59   \n",
              "2546      0.733159       0.334628       0.740569            60   \n",
              "2547      0.730695       0.334544       0.740200            61   \n",
              "\n",
              "                 video  label  Right_shoulder_angle  \n",
              "0     ankur-make-1.mp4      1              0.000000  \n",
              "1     ankur-make-1.mp4      1             91.632777  \n",
              "2     ankur-make-1.mp4      1             86.564595  \n",
              "3     ankur-make-1.mp4      1             81.780484  \n",
              "4     ankur-make-1.mp4      1             69.754535  \n",
              "...                ...    ...                   ...  \n",
              "2543            23.mp4      0             24.993885  \n",
              "2544            23.mp4      0             51.062503  \n",
              "2545            23.mp4      0             60.489315  \n",
              "2546            23.mp4      0             65.094371  \n",
              "2547            23.mp4      0             78.226546  \n",
              "\n",
              "[2548 rows x 29 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a52fabeb-661c-443e-b12f-919ea7a3fc9a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Left_shoulder_x</th>\n",
              "      <th>Left_shoulder_y</th>\n",
              "      <th>Right_shoulder_x</th>\n",
              "      <th>Right_shoulder_y</th>\n",
              "      <th>Left_wrist_y</th>\n",
              "      <th>Left_elbow_x</th>\n",
              "      <th>Left_elbow_y</th>\n",
              "      <th>Right_elbow_x</th>\n",
              "      <th>Right_elbow_y</th>\n",
              "      <th>Left_wrist_x</th>\n",
              "      <th>...</th>\n",
              "      <th>Right_knee_x</th>\n",
              "      <th>Right_knee_y</th>\n",
              "      <th>Left_ankle_x</th>\n",
              "      <th>Left_ankle_y</th>\n",
              "      <th>Right_ankle_x</th>\n",
              "      <th>Right_ankle_y</th>\n",
              "      <th>frame_number</th>\n",
              "      <th>video</th>\n",
              "      <th>label</th>\n",
              "      <th>Right_shoulder_angle</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.137992</td>\n",
              "      <td>0.567018</td>\n",
              "      <td>0.114047</td>\n",
              "      <td>0.574758</td>\n",
              "      <td>0.632627</td>\n",
              "      <td>0.138122</td>\n",
              "      <td>0.620622</td>\n",
              "      <td>0.112386</td>\n",
              "      <td>0.633044</td>\n",
              "      <td>0.163240</td>\n",
              "      <td>...</td>\n",
              "      <td>0.120475</td>\n",
              "      <td>0.763546</td>\n",
              "      <td>0.123502</td>\n",
              "      <td>0.825739</td>\n",
              "      <td>0.101721</td>\n",
              "      <td>0.848228</td>\n",
              "      <td>2</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>91.632777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.137748</td>\n",
              "      <td>0.569186</td>\n",
              "      <td>0.115349</td>\n",
              "      <td>0.579705</td>\n",
              "      <td>0.630857</td>\n",
              "      <td>0.142738</td>\n",
              "      <td>0.619906</td>\n",
              "      <td>0.118926</td>\n",
              "      <td>0.639296</td>\n",
              "      <td>0.169016</td>\n",
              "      <td>...</td>\n",
              "      <td>0.130295</td>\n",
              "      <td>0.763179</td>\n",
              "      <td>0.125134</td>\n",
              "      <td>0.828403</td>\n",
              "      <td>0.102264</td>\n",
              "      <td>0.846033</td>\n",
              "      <td>3</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>86.564595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.135332</td>\n",
              "      <td>0.574709</td>\n",
              "      <td>0.118000</td>\n",
              "      <td>0.584913</td>\n",
              "      <td>0.630535</td>\n",
              "      <td>0.143820</td>\n",
              "      <td>0.624669</td>\n",
              "      <td>0.126229</td>\n",
              "      <td>0.641880</td>\n",
              "      <td>0.169926</td>\n",
              "      <td>...</td>\n",
              "      <td>0.135328</td>\n",
              "      <td>0.768395</td>\n",
              "      <td>0.123493</td>\n",
              "      <td>0.830647</td>\n",
              "      <td>0.105687</td>\n",
              "      <td>0.852329</td>\n",
              "      <td>4</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>81.780484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.137106</td>\n",
              "      <td>0.581849</td>\n",
              "      <td>0.117793</td>\n",
              "      <td>0.593527</td>\n",
              "      <td>0.632422</td>\n",
              "      <td>0.148398</td>\n",
              "      <td>0.628282</td>\n",
              "      <td>0.137886</td>\n",
              "      <td>0.648005</td>\n",
              "      <td>0.175129</td>\n",
              "      <td>...</td>\n",
              "      <td>0.137136</td>\n",
              "      <td>0.777557</td>\n",
              "      <td>0.118015</td>\n",
              "      <td>0.833874</td>\n",
              "      <td>0.108978</td>\n",
              "      <td>0.855727</td>\n",
              "      <td>5</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>69.754535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2543</th>\n",
              "      <td>0.336772</td>\n",
              "      <td>0.450447</td>\n",
              "      <td>0.361769</td>\n",
              "      <td>0.440221</td>\n",
              "      <td>0.571684</td>\n",
              "      <td>0.315813</td>\n",
              "      <td>0.510262</td>\n",
              "      <td>0.387930</td>\n",
              "      <td>0.452417</td>\n",
              "      <td>0.306920</td>\n",
              "      <td>...</td>\n",
              "      <td>0.358902</td>\n",
              "      <td>0.647209</td>\n",
              "      <td>0.351591</td>\n",
              "      <td>0.734951</td>\n",
              "      <td>0.334408</td>\n",
              "      <td>0.744310</td>\n",
              "      <td>57</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>24.993885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2544</th>\n",
              "      <td>0.336169</td>\n",
              "      <td>0.446795</td>\n",
              "      <td>0.361282</td>\n",
              "      <td>0.442094</td>\n",
              "      <td>0.569260</td>\n",
              "      <td>0.315534</td>\n",
              "      <td>0.508232</td>\n",
              "      <td>0.381513</td>\n",
              "      <td>0.467133</td>\n",
              "      <td>0.306491</td>\n",
              "      <td>...</td>\n",
              "      <td>0.360213</td>\n",
              "      <td>0.645472</td>\n",
              "      <td>0.350392</td>\n",
              "      <td>0.734034</td>\n",
              "      <td>0.335498</td>\n",
              "      <td>0.741388</td>\n",
              "      <td>58</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>51.062503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2545</th>\n",
              "      <td>0.336118</td>\n",
              "      <td>0.446699</td>\n",
              "      <td>0.360174</td>\n",
              "      <td>0.445972</td>\n",
              "      <td>0.566294</td>\n",
              "      <td>0.317613</td>\n",
              "      <td>0.512701</td>\n",
              "      <td>0.379284</td>\n",
              "      <td>0.479733</td>\n",
              "      <td>0.307859</td>\n",
              "      <td>...</td>\n",
              "      <td>0.357322</td>\n",
              "      <td>0.644855</td>\n",
              "      <td>0.353428</td>\n",
              "      <td>0.732414</td>\n",
              "      <td>0.332303</td>\n",
              "      <td>0.740661</td>\n",
              "      <td>59</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>60.489315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2546</th>\n",
              "      <td>0.337864</td>\n",
              "      <td>0.445126</td>\n",
              "      <td>0.358200</td>\n",
              "      <td>0.446341</td>\n",
              "      <td>0.569123</td>\n",
              "      <td>0.318504</td>\n",
              "      <td>0.510571</td>\n",
              "      <td>0.374125</td>\n",
              "      <td>0.480640</td>\n",
              "      <td>0.309391</td>\n",
              "      <td>...</td>\n",
              "      <td>0.352830</td>\n",
              "      <td>0.644631</td>\n",
              "      <td>0.350808</td>\n",
              "      <td>0.733159</td>\n",
              "      <td>0.334628</td>\n",
              "      <td>0.740569</td>\n",
              "      <td>60</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>65.094371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2547</th>\n",
              "      <td>0.334369</td>\n",
              "      <td>0.441393</td>\n",
              "      <td>0.358173</td>\n",
              "      <td>0.447999</td>\n",
              "      <td>0.570865</td>\n",
              "      <td>0.316519</td>\n",
              "      <td>0.510886</td>\n",
              "      <td>0.367897</td>\n",
              "      <td>0.494650</td>\n",
              "      <td>0.310895</td>\n",
              "      <td>...</td>\n",
              "      <td>0.358017</td>\n",
              "      <td>0.645474</td>\n",
              "      <td>0.351226</td>\n",
              "      <td>0.730695</td>\n",
              "      <td>0.334544</td>\n",
              "      <td>0.740200</td>\n",
              "      <td>61</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>78.226546</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2548 rows × 29 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a52fabeb-661c-443e-b12f-919ea7a3fc9a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a52fabeb-661c-443e-b12f-919ea7a3fc9a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a52fabeb-661c-443e-b12f-919ea7a3fc9a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e8c1ccf1-368c-4b11-a086-bff8344deec3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e8c1ccf1-368c-4b11-a086-bff8344deec3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e8c1ccf1-368c-4b11-a086-bff8344deec3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_8208de37-4c7d-4f97-b6aa-57755b272553\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_all_coord_updated')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8208de37-4c7d-4f97-b6aa-57755b272553 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_all_coord_updated');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "angle_calculator(df_all_coord_updated, 'Left_shoulder','Left_elbow','Left_Shoulder_angle')\n",
        "df_all_coord_updated"
      ],
      "metadata": {
        "id": "QqYJY8sY7R1z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "outputId": "7643dc8f-618d-4938-e358-3ea67c71735a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Left_shoulder_x Left_shoulder_y Left_elbow_x Left_elbow_y\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Left_shoulder_x  Left_shoulder_y  Right_shoulder_x  Right_shoulder_y  \\\n",
              "0            0.000000         0.000000          0.000000          0.000000   \n",
              "1            0.137992         0.567018          0.114047          0.574758   \n",
              "2            0.137748         0.569186          0.115349          0.579705   \n",
              "3            0.135332         0.574709          0.118000          0.584913   \n",
              "4            0.137106         0.581849          0.117793          0.593527   \n",
              "...               ...              ...               ...               ...   \n",
              "2543         0.336772         0.450447          0.361769          0.440221   \n",
              "2544         0.336169         0.446795          0.361282          0.442094   \n",
              "2545         0.336118         0.446699          0.360174          0.445972   \n",
              "2546         0.337864         0.445126          0.358200          0.446341   \n",
              "2547         0.334369         0.441393          0.358173          0.447999   \n",
              "\n",
              "      Left_wrist_y  Left_elbow_x  Left_elbow_y  Right_elbow_x  Right_elbow_y  \\\n",
              "0         0.000000      0.000000      0.000000       0.000000       0.000000   \n",
              "1         0.632627      0.138122      0.620622       0.112386       0.633044   \n",
              "2         0.630857      0.142738      0.619906       0.118926       0.639296   \n",
              "3         0.630535      0.143820      0.624669       0.126229       0.641880   \n",
              "4         0.632422      0.148398      0.628282       0.137886       0.648005   \n",
              "...            ...           ...           ...            ...            ...   \n",
              "2543      0.571684      0.315813      0.510262       0.387930       0.452417   \n",
              "2544      0.569260      0.315534      0.508232       0.381513       0.467133   \n",
              "2545      0.566294      0.317613      0.512701       0.379284       0.479733   \n",
              "2546      0.569123      0.318504      0.510571       0.374125       0.480640   \n",
              "2547      0.570865      0.316519      0.510886       0.367897       0.494650   \n",
              "\n",
              "      Left_wrist_x  ...  Right_knee_y  Left_ankle_x  Left_ankle_y  \\\n",
              "0         0.000000  ...      0.000000      0.000000      0.000000   \n",
              "1         0.163240  ...      0.763546      0.123502      0.825739   \n",
              "2         0.169016  ...      0.763179      0.125134      0.828403   \n",
              "3         0.169926  ...      0.768395      0.123493      0.830647   \n",
              "4         0.175129  ...      0.777557      0.118015      0.833874   \n",
              "...            ...  ...           ...           ...           ...   \n",
              "2543      0.306920  ...      0.647209      0.351591      0.734951   \n",
              "2544      0.306491  ...      0.645472      0.350392      0.734034   \n",
              "2545      0.307859  ...      0.644855      0.353428      0.732414   \n",
              "2546      0.309391  ...      0.644631      0.350808      0.733159   \n",
              "2547      0.310895  ...      0.645474      0.351226      0.730695   \n",
              "\n",
              "      Right_ankle_x  Right_ankle_y  frame_number             video  label  \\\n",
              "0          0.000000       0.000000             1  ankur-make-1.mp4      1   \n",
              "1          0.101721       0.848228             2  ankur-make-1.mp4      1   \n",
              "2          0.102264       0.846033             3  ankur-make-1.mp4      1   \n",
              "3          0.105687       0.852329             4  ankur-make-1.mp4      1   \n",
              "4          0.108978       0.855727             5  ankur-make-1.mp4      1   \n",
              "...             ...            ...           ...               ...    ...   \n",
              "2543       0.334408       0.744310            57            23.mp4      0   \n",
              "2544       0.335498       0.741388            58            23.mp4      0   \n",
              "2545       0.332303       0.740661            59            23.mp4      0   \n",
              "2546       0.334628       0.740569            60            23.mp4      0   \n",
              "2547       0.334544       0.740200            61            23.mp4      0   \n",
              "\n",
              "      Right_shoulder_angle  Left_Shoulder_angle  \n",
              "0                 0.000000             0.000000  \n",
              "1                91.632777            89.861400  \n",
              "2                86.564595            84.381073  \n",
              "3                81.780484            80.358441  \n",
              "4                69.754535            76.331635  \n",
              "...                    ...                  ...  \n",
              "2543             24.993885           109.311059  \n",
              "2544             51.062503           108.565706  \n",
              "2545             60.489315           105.661801  \n",
              "2546             65.094371           106.478589  \n",
              "2547             78.226546           104.405066  \n",
              "\n",
              "[2548 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0a8e6e07-c32b-4ab1-9fb1-803127f05c7c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Left_shoulder_x</th>\n",
              "      <th>Left_shoulder_y</th>\n",
              "      <th>Right_shoulder_x</th>\n",
              "      <th>Right_shoulder_y</th>\n",
              "      <th>Left_wrist_y</th>\n",
              "      <th>Left_elbow_x</th>\n",
              "      <th>Left_elbow_y</th>\n",
              "      <th>Right_elbow_x</th>\n",
              "      <th>Right_elbow_y</th>\n",
              "      <th>Left_wrist_x</th>\n",
              "      <th>...</th>\n",
              "      <th>Right_knee_y</th>\n",
              "      <th>Left_ankle_x</th>\n",
              "      <th>Left_ankle_y</th>\n",
              "      <th>Right_ankle_x</th>\n",
              "      <th>Right_ankle_y</th>\n",
              "      <th>frame_number</th>\n",
              "      <th>video</th>\n",
              "      <th>label</th>\n",
              "      <th>Right_shoulder_angle</th>\n",
              "      <th>Left_Shoulder_angle</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.137992</td>\n",
              "      <td>0.567018</td>\n",
              "      <td>0.114047</td>\n",
              "      <td>0.574758</td>\n",
              "      <td>0.632627</td>\n",
              "      <td>0.138122</td>\n",
              "      <td>0.620622</td>\n",
              "      <td>0.112386</td>\n",
              "      <td>0.633044</td>\n",
              "      <td>0.163240</td>\n",
              "      <td>...</td>\n",
              "      <td>0.763546</td>\n",
              "      <td>0.123502</td>\n",
              "      <td>0.825739</td>\n",
              "      <td>0.101721</td>\n",
              "      <td>0.848228</td>\n",
              "      <td>2</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>91.632777</td>\n",
              "      <td>89.861400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.137748</td>\n",
              "      <td>0.569186</td>\n",
              "      <td>0.115349</td>\n",
              "      <td>0.579705</td>\n",
              "      <td>0.630857</td>\n",
              "      <td>0.142738</td>\n",
              "      <td>0.619906</td>\n",
              "      <td>0.118926</td>\n",
              "      <td>0.639296</td>\n",
              "      <td>0.169016</td>\n",
              "      <td>...</td>\n",
              "      <td>0.763179</td>\n",
              "      <td>0.125134</td>\n",
              "      <td>0.828403</td>\n",
              "      <td>0.102264</td>\n",
              "      <td>0.846033</td>\n",
              "      <td>3</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>86.564595</td>\n",
              "      <td>84.381073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.135332</td>\n",
              "      <td>0.574709</td>\n",
              "      <td>0.118000</td>\n",
              "      <td>0.584913</td>\n",
              "      <td>0.630535</td>\n",
              "      <td>0.143820</td>\n",
              "      <td>0.624669</td>\n",
              "      <td>0.126229</td>\n",
              "      <td>0.641880</td>\n",
              "      <td>0.169926</td>\n",
              "      <td>...</td>\n",
              "      <td>0.768395</td>\n",
              "      <td>0.123493</td>\n",
              "      <td>0.830647</td>\n",
              "      <td>0.105687</td>\n",
              "      <td>0.852329</td>\n",
              "      <td>4</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>81.780484</td>\n",
              "      <td>80.358441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.137106</td>\n",
              "      <td>0.581849</td>\n",
              "      <td>0.117793</td>\n",
              "      <td>0.593527</td>\n",
              "      <td>0.632422</td>\n",
              "      <td>0.148398</td>\n",
              "      <td>0.628282</td>\n",
              "      <td>0.137886</td>\n",
              "      <td>0.648005</td>\n",
              "      <td>0.175129</td>\n",
              "      <td>...</td>\n",
              "      <td>0.777557</td>\n",
              "      <td>0.118015</td>\n",
              "      <td>0.833874</td>\n",
              "      <td>0.108978</td>\n",
              "      <td>0.855727</td>\n",
              "      <td>5</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>69.754535</td>\n",
              "      <td>76.331635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2543</th>\n",
              "      <td>0.336772</td>\n",
              "      <td>0.450447</td>\n",
              "      <td>0.361769</td>\n",
              "      <td>0.440221</td>\n",
              "      <td>0.571684</td>\n",
              "      <td>0.315813</td>\n",
              "      <td>0.510262</td>\n",
              "      <td>0.387930</td>\n",
              "      <td>0.452417</td>\n",
              "      <td>0.306920</td>\n",
              "      <td>...</td>\n",
              "      <td>0.647209</td>\n",
              "      <td>0.351591</td>\n",
              "      <td>0.734951</td>\n",
              "      <td>0.334408</td>\n",
              "      <td>0.744310</td>\n",
              "      <td>57</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>24.993885</td>\n",
              "      <td>109.311059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2544</th>\n",
              "      <td>0.336169</td>\n",
              "      <td>0.446795</td>\n",
              "      <td>0.361282</td>\n",
              "      <td>0.442094</td>\n",
              "      <td>0.569260</td>\n",
              "      <td>0.315534</td>\n",
              "      <td>0.508232</td>\n",
              "      <td>0.381513</td>\n",
              "      <td>0.467133</td>\n",
              "      <td>0.306491</td>\n",
              "      <td>...</td>\n",
              "      <td>0.645472</td>\n",
              "      <td>0.350392</td>\n",
              "      <td>0.734034</td>\n",
              "      <td>0.335498</td>\n",
              "      <td>0.741388</td>\n",
              "      <td>58</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>51.062503</td>\n",
              "      <td>108.565706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2545</th>\n",
              "      <td>0.336118</td>\n",
              "      <td>0.446699</td>\n",
              "      <td>0.360174</td>\n",
              "      <td>0.445972</td>\n",
              "      <td>0.566294</td>\n",
              "      <td>0.317613</td>\n",
              "      <td>0.512701</td>\n",
              "      <td>0.379284</td>\n",
              "      <td>0.479733</td>\n",
              "      <td>0.307859</td>\n",
              "      <td>...</td>\n",
              "      <td>0.644855</td>\n",
              "      <td>0.353428</td>\n",
              "      <td>0.732414</td>\n",
              "      <td>0.332303</td>\n",
              "      <td>0.740661</td>\n",
              "      <td>59</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>60.489315</td>\n",
              "      <td>105.661801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2546</th>\n",
              "      <td>0.337864</td>\n",
              "      <td>0.445126</td>\n",
              "      <td>0.358200</td>\n",
              "      <td>0.446341</td>\n",
              "      <td>0.569123</td>\n",
              "      <td>0.318504</td>\n",
              "      <td>0.510571</td>\n",
              "      <td>0.374125</td>\n",
              "      <td>0.480640</td>\n",
              "      <td>0.309391</td>\n",
              "      <td>...</td>\n",
              "      <td>0.644631</td>\n",
              "      <td>0.350808</td>\n",
              "      <td>0.733159</td>\n",
              "      <td>0.334628</td>\n",
              "      <td>0.740569</td>\n",
              "      <td>60</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>65.094371</td>\n",
              "      <td>106.478589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2547</th>\n",
              "      <td>0.334369</td>\n",
              "      <td>0.441393</td>\n",
              "      <td>0.358173</td>\n",
              "      <td>0.447999</td>\n",
              "      <td>0.570865</td>\n",
              "      <td>0.316519</td>\n",
              "      <td>0.510886</td>\n",
              "      <td>0.367897</td>\n",
              "      <td>0.494650</td>\n",
              "      <td>0.310895</td>\n",
              "      <td>...</td>\n",
              "      <td>0.645474</td>\n",
              "      <td>0.351226</td>\n",
              "      <td>0.730695</td>\n",
              "      <td>0.334544</td>\n",
              "      <td>0.740200</td>\n",
              "      <td>61</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>78.226546</td>\n",
              "      <td>104.405066</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2548 rows × 30 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0a8e6e07-c32b-4ab1-9fb1-803127f05c7c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0a8e6e07-c32b-4ab1-9fb1-803127f05c7c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0a8e6e07-c32b-4ab1-9fb1-803127f05c7c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-44740efa-22fb-40c0-9a66-634c65c3a4ce\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-44740efa-22fb-40c0-9a66-634c65c3a4ce')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-44740efa-22fb-40c0-9a66-634c65c3a4ce button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_859830f4-2abb-46d8-9924-d4296355e73e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_all_coord_updated')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_859830f4-2abb-46d8-9924-d4296355e73e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_all_coord_updated');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "angle_calculator(df_all_coord_updated, 'Right_elbow','Right_wrist','Right_wrist_angle')\n",
        "df_all_coord_updated"
      ],
      "metadata": {
        "id": "tZzozEMO7lF0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "outputId": "060435c2-8959-4169-dc53-fe6014048ddc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Right_elbow_x Right_elbow_y Right_wrist_x Right_wrist_y\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Left_shoulder_x  Left_shoulder_y  Right_shoulder_x  Right_shoulder_y  \\\n",
              "0            0.000000         0.000000          0.000000          0.000000   \n",
              "1            0.137992         0.567018          0.114047          0.574758   \n",
              "2            0.137748         0.569186          0.115349          0.579705   \n",
              "3            0.135332         0.574709          0.118000          0.584913   \n",
              "4            0.137106         0.581849          0.117793          0.593527   \n",
              "...               ...              ...               ...               ...   \n",
              "2543         0.336772         0.450447          0.361769          0.440221   \n",
              "2544         0.336169         0.446795          0.361282          0.442094   \n",
              "2545         0.336118         0.446699          0.360174          0.445972   \n",
              "2546         0.337864         0.445126          0.358200          0.446341   \n",
              "2547         0.334369         0.441393          0.358173          0.447999   \n",
              "\n",
              "      Left_wrist_y  Left_elbow_x  Left_elbow_y  Right_elbow_x  Right_elbow_y  \\\n",
              "0         0.000000      0.000000      0.000000       0.000000       0.000000   \n",
              "1         0.632627      0.138122      0.620622       0.112386       0.633044   \n",
              "2         0.630857      0.142738      0.619906       0.118926       0.639296   \n",
              "3         0.630535      0.143820      0.624669       0.126229       0.641880   \n",
              "4         0.632422      0.148398      0.628282       0.137886       0.648005   \n",
              "...            ...           ...           ...            ...            ...   \n",
              "2543      0.571684      0.315813      0.510262       0.387930       0.452417   \n",
              "2544      0.569260      0.315534      0.508232       0.381513       0.467133   \n",
              "2545      0.566294      0.317613      0.512701       0.379284       0.479733   \n",
              "2546      0.569123      0.318504      0.510571       0.374125       0.480640   \n",
              "2547      0.570865      0.316519      0.510886       0.367897       0.494650   \n",
              "\n",
              "      Left_wrist_x  ...  Left_ankle_x  Left_ankle_y  Right_ankle_x  \\\n",
              "0         0.000000  ...      0.000000      0.000000       0.000000   \n",
              "1         0.163240  ...      0.123502      0.825739       0.101721   \n",
              "2         0.169016  ...      0.125134      0.828403       0.102264   \n",
              "3         0.169926  ...      0.123493      0.830647       0.105687   \n",
              "4         0.175129  ...      0.118015      0.833874       0.108978   \n",
              "...            ...  ...           ...           ...            ...   \n",
              "2543      0.306920  ...      0.351591      0.734951       0.334408   \n",
              "2544      0.306491  ...      0.350392      0.734034       0.335498   \n",
              "2545      0.307859  ...      0.353428      0.732414       0.332303   \n",
              "2546      0.309391  ...      0.350808      0.733159       0.334628   \n",
              "2547      0.310895  ...      0.351226      0.730695       0.334544   \n",
              "\n",
              "      Right_ankle_y  frame_number             video  label  \\\n",
              "0          0.000000             1  ankur-make-1.mp4      1   \n",
              "1          0.848228             2  ankur-make-1.mp4      1   \n",
              "2          0.846033             3  ankur-make-1.mp4      1   \n",
              "3          0.852329             4  ankur-make-1.mp4      1   \n",
              "4          0.855727             5  ankur-make-1.mp4      1   \n",
              "...             ...           ...               ...    ...   \n",
              "2543       0.744310            57            23.mp4      0   \n",
              "2544       0.741388            58            23.mp4      0   \n",
              "2545       0.740661            59            23.mp4      0   \n",
              "2546       0.740569            60            23.mp4      0   \n",
              "2547       0.740200            61            23.mp4      0   \n",
              "\n",
              "      Right_shoulder_angle  Left_Shoulder_angle  Right_wrist_angle  \n",
              "0                 0.000000             0.000000           0.000000  \n",
              "1                91.632777            89.861400          17.659975  \n",
              "2                86.564595            84.381073           7.643551  \n",
              "3                81.780484            80.358441           0.619993  \n",
              "4                69.754535            76.331635         -15.724972  \n",
              "...                    ...                  ...                ...  \n",
              "2543             24.993885           109.311059         -20.092856  \n",
              "2544             51.062503           108.565706         -28.560092  \n",
              "2545             60.489315           105.661801         -40.917997  \n",
              "2546             65.094371           106.478589         -31.887617  \n",
              "2547             78.226546           104.405066         -41.611827  \n",
              "\n",
              "[2548 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-85fcc010-6acb-4dfa-9e4a-d67c9867fbff\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Left_shoulder_x</th>\n",
              "      <th>Left_shoulder_y</th>\n",
              "      <th>Right_shoulder_x</th>\n",
              "      <th>Right_shoulder_y</th>\n",
              "      <th>Left_wrist_y</th>\n",
              "      <th>Left_elbow_x</th>\n",
              "      <th>Left_elbow_y</th>\n",
              "      <th>Right_elbow_x</th>\n",
              "      <th>Right_elbow_y</th>\n",
              "      <th>Left_wrist_x</th>\n",
              "      <th>...</th>\n",
              "      <th>Left_ankle_x</th>\n",
              "      <th>Left_ankle_y</th>\n",
              "      <th>Right_ankle_x</th>\n",
              "      <th>Right_ankle_y</th>\n",
              "      <th>frame_number</th>\n",
              "      <th>video</th>\n",
              "      <th>label</th>\n",
              "      <th>Right_shoulder_angle</th>\n",
              "      <th>Left_Shoulder_angle</th>\n",
              "      <th>Right_wrist_angle</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.137992</td>\n",
              "      <td>0.567018</td>\n",
              "      <td>0.114047</td>\n",
              "      <td>0.574758</td>\n",
              "      <td>0.632627</td>\n",
              "      <td>0.138122</td>\n",
              "      <td>0.620622</td>\n",
              "      <td>0.112386</td>\n",
              "      <td>0.633044</td>\n",
              "      <td>0.163240</td>\n",
              "      <td>...</td>\n",
              "      <td>0.123502</td>\n",
              "      <td>0.825739</td>\n",
              "      <td>0.101721</td>\n",
              "      <td>0.848228</td>\n",
              "      <td>2</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>91.632777</td>\n",
              "      <td>89.861400</td>\n",
              "      <td>17.659975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.137748</td>\n",
              "      <td>0.569186</td>\n",
              "      <td>0.115349</td>\n",
              "      <td>0.579705</td>\n",
              "      <td>0.630857</td>\n",
              "      <td>0.142738</td>\n",
              "      <td>0.619906</td>\n",
              "      <td>0.118926</td>\n",
              "      <td>0.639296</td>\n",
              "      <td>0.169016</td>\n",
              "      <td>...</td>\n",
              "      <td>0.125134</td>\n",
              "      <td>0.828403</td>\n",
              "      <td>0.102264</td>\n",
              "      <td>0.846033</td>\n",
              "      <td>3</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>86.564595</td>\n",
              "      <td>84.381073</td>\n",
              "      <td>7.643551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.135332</td>\n",
              "      <td>0.574709</td>\n",
              "      <td>0.118000</td>\n",
              "      <td>0.584913</td>\n",
              "      <td>0.630535</td>\n",
              "      <td>0.143820</td>\n",
              "      <td>0.624669</td>\n",
              "      <td>0.126229</td>\n",
              "      <td>0.641880</td>\n",
              "      <td>0.169926</td>\n",
              "      <td>...</td>\n",
              "      <td>0.123493</td>\n",
              "      <td>0.830647</td>\n",
              "      <td>0.105687</td>\n",
              "      <td>0.852329</td>\n",
              "      <td>4</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>81.780484</td>\n",
              "      <td>80.358441</td>\n",
              "      <td>0.619993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.137106</td>\n",
              "      <td>0.581849</td>\n",
              "      <td>0.117793</td>\n",
              "      <td>0.593527</td>\n",
              "      <td>0.632422</td>\n",
              "      <td>0.148398</td>\n",
              "      <td>0.628282</td>\n",
              "      <td>0.137886</td>\n",
              "      <td>0.648005</td>\n",
              "      <td>0.175129</td>\n",
              "      <td>...</td>\n",
              "      <td>0.118015</td>\n",
              "      <td>0.833874</td>\n",
              "      <td>0.108978</td>\n",
              "      <td>0.855727</td>\n",
              "      <td>5</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>69.754535</td>\n",
              "      <td>76.331635</td>\n",
              "      <td>-15.724972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2543</th>\n",
              "      <td>0.336772</td>\n",
              "      <td>0.450447</td>\n",
              "      <td>0.361769</td>\n",
              "      <td>0.440221</td>\n",
              "      <td>0.571684</td>\n",
              "      <td>0.315813</td>\n",
              "      <td>0.510262</td>\n",
              "      <td>0.387930</td>\n",
              "      <td>0.452417</td>\n",
              "      <td>0.306920</td>\n",
              "      <td>...</td>\n",
              "      <td>0.351591</td>\n",
              "      <td>0.734951</td>\n",
              "      <td>0.334408</td>\n",
              "      <td>0.744310</td>\n",
              "      <td>57</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>24.993885</td>\n",
              "      <td>109.311059</td>\n",
              "      <td>-20.092856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2544</th>\n",
              "      <td>0.336169</td>\n",
              "      <td>0.446795</td>\n",
              "      <td>0.361282</td>\n",
              "      <td>0.442094</td>\n",
              "      <td>0.569260</td>\n",
              "      <td>0.315534</td>\n",
              "      <td>0.508232</td>\n",
              "      <td>0.381513</td>\n",
              "      <td>0.467133</td>\n",
              "      <td>0.306491</td>\n",
              "      <td>...</td>\n",
              "      <td>0.350392</td>\n",
              "      <td>0.734034</td>\n",
              "      <td>0.335498</td>\n",
              "      <td>0.741388</td>\n",
              "      <td>58</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>51.062503</td>\n",
              "      <td>108.565706</td>\n",
              "      <td>-28.560092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2545</th>\n",
              "      <td>0.336118</td>\n",
              "      <td>0.446699</td>\n",
              "      <td>0.360174</td>\n",
              "      <td>0.445972</td>\n",
              "      <td>0.566294</td>\n",
              "      <td>0.317613</td>\n",
              "      <td>0.512701</td>\n",
              "      <td>0.379284</td>\n",
              "      <td>0.479733</td>\n",
              "      <td>0.307859</td>\n",
              "      <td>...</td>\n",
              "      <td>0.353428</td>\n",
              "      <td>0.732414</td>\n",
              "      <td>0.332303</td>\n",
              "      <td>0.740661</td>\n",
              "      <td>59</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>60.489315</td>\n",
              "      <td>105.661801</td>\n",
              "      <td>-40.917997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2546</th>\n",
              "      <td>0.337864</td>\n",
              "      <td>0.445126</td>\n",
              "      <td>0.358200</td>\n",
              "      <td>0.446341</td>\n",
              "      <td>0.569123</td>\n",
              "      <td>0.318504</td>\n",
              "      <td>0.510571</td>\n",
              "      <td>0.374125</td>\n",
              "      <td>0.480640</td>\n",
              "      <td>0.309391</td>\n",
              "      <td>...</td>\n",
              "      <td>0.350808</td>\n",
              "      <td>0.733159</td>\n",
              "      <td>0.334628</td>\n",
              "      <td>0.740569</td>\n",
              "      <td>60</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>65.094371</td>\n",
              "      <td>106.478589</td>\n",
              "      <td>-31.887617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2547</th>\n",
              "      <td>0.334369</td>\n",
              "      <td>0.441393</td>\n",
              "      <td>0.358173</td>\n",
              "      <td>0.447999</td>\n",
              "      <td>0.570865</td>\n",
              "      <td>0.316519</td>\n",
              "      <td>0.510886</td>\n",
              "      <td>0.367897</td>\n",
              "      <td>0.494650</td>\n",
              "      <td>0.310895</td>\n",
              "      <td>...</td>\n",
              "      <td>0.351226</td>\n",
              "      <td>0.730695</td>\n",
              "      <td>0.334544</td>\n",
              "      <td>0.740200</td>\n",
              "      <td>61</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>78.226546</td>\n",
              "      <td>104.405066</td>\n",
              "      <td>-41.611827</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2548 rows × 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-85fcc010-6acb-4dfa-9e4a-d67c9867fbff')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-85fcc010-6acb-4dfa-9e4a-d67c9867fbff button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-85fcc010-6acb-4dfa-9e4a-d67c9867fbff');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8eb451fc-c045-438e-861c-36104b697835\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8eb451fc-c045-438e-861c-36104b697835')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8eb451fc-c045-438e-861c-36104b697835 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_47394109-d13b-4197-bdbf-0a87a22d678d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_all_coord_updated')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_47394109-d13b-4197-bdbf-0a87a22d678d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_all_coord_updated');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "angle_calculator(df_all_coord_updated, 'Right_hip', 'Right_knee','Right_thigh_angle')\n",
        "df_all_coord_updated"
      ],
      "metadata": {
        "id": "1IqeOBrf8PuT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "outputId": "375a999e-144f-4f10-ff72-7e6f41eb4545"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Right_hip_x Right_hip_y Right_knee_x Right_knee_y\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Left_shoulder_x  Left_shoulder_y  Right_shoulder_x  Right_shoulder_y  \\\n",
              "0            0.000000         0.000000          0.000000          0.000000   \n",
              "1            0.137992         0.567018          0.114047          0.574758   \n",
              "2            0.137748         0.569186          0.115349          0.579705   \n",
              "3            0.135332         0.574709          0.118000          0.584913   \n",
              "4            0.137106         0.581849          0.117793          0.593527   \n",
              "...               ...              ...               ...               ...   \n",
              "2543         0.336772         0.450447          0.361769          0.440221   \n",
              "2544         0.336169         0.446795          0.361282          0.442094   \n",
              "2545         0.336118         0.446699          0.360174          0.445972   \n",
              "2546         0.337864         0.445126          0.358200          0.446341   \n",
              "2547         0.334369         0.441393          0.358173          0.447999   \n",
              "\n",
              "      Left_wrist_y  Left_elbow_x  Left_elbow_y  Right_elbow_x  Right_elbow_y  \\\n",
              "0         0.000000      0.000000      0.000000       0.000000       0.000000   \n",
              "1         0.632627      0.138122      0.620622       0.112386       0.633044   \n",
              "2         0.630857      0.142738      0.619906       0.118926       0.639296   \n",
              "3         0.630535      0.143820      0.624669       0.126229       0.641880   \n",
              "4         0.632422      0.148398      0.628282       0.137886       0.648005   \n",
              "...            ...           ...           ...            ...            ...   \n",
              "2543      0.571684      0.315813      0.510262       0.387930       0.452417   \n",
              "2544      0.569260      0.315534      0.508232       0.381513       0.467133   \n",
              "2545      0.566294      0.317613      0.512701       0.379284       0.479733   \n",
              "2546      0.569123      0.318504      0.510571       0.374125       0.480640   \n",
              "2547      0.570865      0.316519      0.510886       0.367897       0.494650   \n",
              "\n",
              "      Left_wrist_x  ...  Left_ankle_y  Right_ankle_x  Right_ankle_y  \\\n",
              "0         0.000000  ...      0.000000       0.000000       0.000000   \n",
              "1         0.163240  ...      0.825739       0.101721       0.848228   \n",
              "2         0.169016  ...      0.828403       0.102264       0.846033   \n",
              "3         0.169926  ...      0.830647       0.105687       0.852329   \n",
              "4         0.175129  ...      0.833874       0.108978       0.855727   \n",
              "...            ...  ...           ...            ...            ...   \n",
              "2543      0.306920  ...      0.734951       0.334408       0.744310   \n",
              "2544      0.306491  ...      0.734034       0.335498       0.741388   \n",
              "2545      0.307859  ...      0.732414       0.332303       0.740661   \n",
              "2546      0.309391  ...      0.733159       0.334628       0.740569   \n",
              "2547      0.310895  ...      0.730695       0.334544       0.740200   \n",
              "\n",
              "      frame_number             video  label  Right_shoulder_angle  \\\n",
              "0                1  ankur-make-1.mp4      1              0.000000   \n",
              "1                2  ankur-make-1.mp4      1             91.632777   \n",
              "2                3  ankur-make-1.mp4      1             86.564595   \n",
              "3                4  ankur-make-1.mp4      1             81.780484   \n",
              "4                5  ankur-make-1.mp4      1             69.754535   \n",
              "...            ...               ...    ...                   ...   \n",
              "2543            57            23.mp4      0             24.993885   \n",
              "2544            58            23.mp4      0             51.062503   \n",
              "2545            59            23.mp4      0             60.489315   \n",
              "2546            60            23.mp4      0             65.094371   \n",
              "2547            61            23.mp4      0             78.226546   \n",
              "\n",
              "      Left_Shoulder_angle  Right_wrist_angle  Right_thigh_angle  \n",
              "0                0.000000           0.000000           0.000000  \n",
              "1               89.861400          17.659975          85.636815  \n",
              "2               84.381073           7.643551          80.122440  \n",
              "3               80.358441           0.619993          76.545692  \n",
              "4               76.331635         -15.724972          78.640070  \n",
              "...                   ...                ...                ...  \n",
              "2543           109.311059         -20.092856          90.292186  \n",
              "2544           108.565706         -28.560092          89.391243  \n",
              "2545           105.661801         -40.917997          91.127912  \n",
              "2546           106.478589         -31.887617          92.397735  \n",
              "2547           104.405066         -41.611827          90.403579  \n",
              "\n",
              "[2548 rows x 32 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8e84db5b-66fe-4398-bfa3-d7977ee45280\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Left_shoulder_x</th>\n",
              "      <th>Left_shoulder_y</th>\n",
              "      <th>Right_shoulder_x</th>\n",
              "      <th>Right_shoulder_y</th>\n",
              "      <th>Left_wrist_y</th>\n",
              "      <th>Left_elbow_x</th>\n",
              "      <th>Left_elbow_y</th>\n",
              "      <th>Right_elbow_x</th>\n",
              "      <th>Right_elbow_y</th>\n",
              "      <th>Left_wrist_x</th>\n",
              "      <th>...</th>\n",
              "      <th>Left_ankle_y</th>\n",
              "      <th>Right_ankle_x</th>\n",
              "      <th>Right_ankle_y</th>\n",
              "      <th>frame_number</th>\n",
              "      <th>video</th>\n",
              "      <th>label</th>\n",
              "      <th>Right_shoulder_angle</th>\n",
              "      <th>Left_Shoulder_angle</th>\n",
              "      <th>Right_wrist_angle</th>\n",
              "      <th>Right_thigh_angle</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.137992</td>\n",
              "      <td>0.567018</td>\n",
              "      <td>0.114047</td>\n",
              "      <td>0.574758</td>\n",
              "      <td>0.632627</td>\n",
              "      <td>0.138122</td>\n",
              "      <td>0.620622</td>\n",
              "      <td>0.112386</td>\n",
              "      <td>0.633044</td>\n",
              "      <td>0.163240</td>\n",
              "      <td>...</td>\n",
              "      <td>0.825739</td>\n",
              "      <td>0.101721</td>\n",
              "      <td>0.848228</td>\n",
              "      <td>2</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>91.632777</td>\n",
              "      <td>89.861400</td>\n",
              "      <td>17.659975</td>\n",
              "      <td>85.636815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.137748</td>\n",
              "      <td>0.569186</td>\n",
              "      <td>0.115349</td>\n",
              "      <td>0.579705</td>\n",
              "      <td>0.630857</td>\n",
              "      <td>0.142738</td>\n",
              "      <td>0.619906</td>\n",
              "      <td>0.118926</td>\n",
              "      <td>0.639296</td>\n",
              "      <td>0.169016</td>\n",
              "      <td>...</td>\n",
              "      <td>0.828403</td>\n",
              "      <td>0.102264</td>\n",
              "      <td>0.846033</td>\n",
              "      <td>3</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>86.564595</td>\n",
              "      <td>84.381073</td>\n",
              "      <td>7.643551</td>\n",
              "      <td>80.122440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.135332</td>\n",
              "      <td>0.574709</td>\n",
              "      <td>0.118000</td>\n",
              "      <td>0.584913</td>\n",
              "      <td>0.630535</td>\n",
              "      <td>0.143820</td>\n",
              "      <td>0.624669</td>\n",
              "      <td>0.126229</td>\n",
              "      <td>0.641880</td>\n",
              "      <td>0.169926</td>\n",
              "      <td>...</td>\n",
              "      <td>0.830647</td>\n",
              "      <td>0.105687</td>\n",
              "      <td>0.852329</td>\n",
              "      <td>4</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>81.780484</td>\n",
              "      <td>80.358441</td>\n",
              "      <td>0.619993</td>\n",
              "      <td>76.545692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.137106</td>\n",
              "      <td>0.581849</td>\n",
              "      <td>0.117793</td>\n",
              "      <td>0.593527</td>\n",
              "      <td>0.632422</td>\n",
              "      <td>0.148398</td>\n",
              "      <td>0.628282</td>\n",
              "      <td>0.137886</td>\n",
              "      <td>0.648005</td>\n",
              "      <td>0.175129</td>\n",
              "      <td>...</td>\n",
              "      <td>0.833874</td>\n",
              "      <td>0.108978</td>\n",
              "      <td>0.855727</td>\n",
              "      <td>5</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>69.754535</td>\n",
              "      <td>76.331635</td>\n",
              "      <td>-15.724972</td>\n",
              "      <td>78.640070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2543</th>\n",
              "      <td>0.336772</td>\n",
              "      <td>0.450447</td>\n",
              "      <td>0.361769</td>\n",
              "      <td>0.440221</td>\n",
              "      <td>0.571684</td>\n",
              "      <td>0.315813</td>\n",
              "      <td>0.510262</td>\n",
              "      <td>0.387930</td>\n",
              "      <td>0.452417</td>\n",
              "      <td>0.306920</td>\n",
              "      <td>...</td>\n",
              "      <td>0.734951</td>\n",
              "      <td>0.334408</td>\n",
              "      <td>0.744310</td>\n",
              "      <td>57</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>24.993885</td>\n",
              "      <td>109.311059</td>\n",
              "      <td>-20.092856</td>\n",
              "      <td>90.292186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2544</th>\n",
              "      <td>0.336169</td>\n",
              "      <td>0.446795</td>\n",
              "      <td>0.361282</td>\n",
              "      <td>0.442094</td>\n",
              "      <td>0.569260</td>\n",
              "      <td>0.315534</td>\n",
              "      <td>0.508232</td>\n",
              "      <td>0.381513</td>\n",
              "      <td>0.467133</td>\n",
              "      <td>0.306491</td>\n",
              "      <td>...</td>\n",
              "      <td>0.734034</td>\n",
              "      <td>0.335498</td>\n",
              "      <td>0.741388</td>\n",
              "      <td>58</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>51.062503</td>\n",
              "      <td>108.565706</td>\n",
              "      <td>-28.560092</td>\n",
              "      <td>89.391243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2545</th>\n",
              "      <td>0.336118</td>\n",
              "      <td>0.446699</td>\n",
              "      <td>0.360174</td>\n",
              "      <td>0.445972</td>\n",
              "      <td>0.566294</td>\n",
              "      <td>0.317613</td>\n",
              "      <td>0.512701</td>\n",
              "      <td>0.379284</td>\n",
              "      <td>0.479733</td>\n",
              "      <td>0.307859</td>\n",
              "      <td>...</td>\n",
              "      <td>0.732414</td>\n",
              "      <td>0.332303</td>\n",
              "      <td>0.740661</td>\n",
              "      <td>59</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>60.489315</td>\n",
              "      <td>105.661801</td>\n",
              "      <td>-40.917997</td>\n",
              "      <td>91.127912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2546</th>\n",
              "      <td>0.337864</td>\n",
              "      <td>0.445126</td>\n",
              "      <td>0.358200</td>\n",
              "      <td>0.446341</td>\n",
              "      <td>0.569123</td>\n",
              "      <td>0.318504</td>\n",
              "      <td>0.510571</td>\n",
              "      <td>0.374125</td>\n",
              "      <td>0.480640</td>\n",
              "      <td>0.309391</td>\n",
              "      <td>...</td>\n",
              "      <td>0.733159</td>\n",
              "      <td>0.334628</td>\n",
              "      <td>0.740569</td>\n",
              "      <td>60</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>65.094371</td>\n",
              "      <td>106.478589</td>\n",
              "      <td>-31.887617</td>\n",
              "      <td>92.397735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2547</th>\n",
              "      <td>0.334369</td>\n",
              "      <td>0.441393</td>\n",
              "      <td>0.358173</td>\n",
              "      <td>0.447999</td>\n",
              "      <td>0.570865</td>\n",
              "      <td>0.316519</td>\n",
              "      <td>0.510886</td>\n",
              "      <td>0.367897</td>\n",
              "      <td>0.494650</td>\n",
              "      <td>0.310895</td>\n",
              "      <td>...</td>\n",
              "      <td>0.730695</td>\n",
              "      <td>0.334544</td>\n",
              "      <td>0.740200</td>\n",
              "      <td>61</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>78.226546</td>\n",
              "      <td>104.405066</td>\n",
              "      <td>-41.611827</td>\n",
              "      <td>90.403579</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2548 rows × 32 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e84db5b-66fe-4398-bfa3-d7977ee45280')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8e84db5b-66fe-4398-bfa3-d7977ee45280 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8e84db5b-66fe-4398-bfa3-d7977ee45280');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-28f35694-db2c-47b4-9a07-ec2451e78995\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-28f35694-db2c-47b4-9a07-ec2451e78995')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-28f35694-db2c-47b4-9a07-ec2451e78995 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_692f4397-a64c-4f1f-9570-9571556424fe\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_all_coord_updated')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_692f4397-a64c-4f1f-9570-9571556424fe button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_all_coord_updated');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "angle_calculator( df_all_coord_updated,'Left_hip', 'Left_knee','Left_thigh_angle')\n",
        "df_all_coord_updated"
      ],
      "metadata": {
        "id": "fqz4uQ6J8o2t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "outputId": "90cdb81f-3ca6-4830-805c-677aa7b417d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Left_hip_x Left_hip_y Left_knee_x Left_knee_y\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Left_shoulder_x  Left_shoulder_y  Right_shoulder_x  Right_shoulder_y  \\\n",
              "0            0.000000         0.000000          0.000000          0.000000   \n",
              "1            0.137992         0.567018          0.114047          0.574758   \n",
              "2            0.137748         0.569186          0.115349          0.579705   \n",
              "3            0.135332         0.574709          0.118000          0.584913   \n",
              "4            0.137106         0.581849          0.117793          0.593527   \n",
              "...               ...              ...               ...               ...   \n",
              "2543         0.336772         0.450447          0.361769          0.440221   \n",
              "2544         0.336169         0.446795          0.361282          0.442094   \n",
              "2545         0.336118         0.446699          0.360174          0.445972   \n",
              "2546         0.337864         0.445126          0.358200          0.446341   \n",
              "2547         0.334369         0.441393          0.358173          0.447999   \n",
              "\n",
              "      Left_wrist_y  Left_elbow_x  Left_elbow_y  Right_elbow_x  Right_elbow_y  \\\n",
              "0         0.000000      0.000000      0.000000       0.000000       0.000000   \n",
              "1         0.632627      0.138122      0.620622       0.112386       0.633044   \n",
              "2         0.630857      0.142738      0.619906       0.118926       0.639296   \n",
              "3         0.630535      0.143820      0.624669       0.126229       0.641880   \n",
              "4         0.632422      0.148398      0.628282       0.137886       0.648005   \n",
              "...            ...           ...           ...            ...            ...   \n",
              "2543      0.571684      0.315813      0.510262       0.387930       0.452417   \n",
              "2544      0.569260      0.315534      0.508232       0.381513       0.467133   \n",
              "2545      0.566294      0.317613      0.512701       0.379284       0.479733   \n",
              "2546      0.569123      0.318504      0.510571       0.374125       0.480640   \n",
              "2547      0.570865      0.316519      0.510886       0.367897       0.494650   \n",
              "\n",
              "      Left_wrist_x  ...  Right_ankle_x  Right_ankle_y  frame_number  \\\n",
              "0         0.000000  ...       0.000000       0.000000             1   \n",
              "1         0.163240  ...       0.101721       0.848228             2   \n",
              "2         0.169016  ...       0.102264       0.846033             3   \n",
              "3         0.169926  ...       0.105687       0.852329             4   \n",
              "4         0.175129  ...       0.108978       0.855727             5   \n",
              "...            ...  ...            ...            ...           ...   \n",
              "2543      0.306920  ...       0.334408       0.744310            57   \n",
              "2544      0.306491  ...       0.335498       0.741388            58   \n",
              "2545      0.307859  ...       0.332303       0.740661            59   \n",
              "2546      0.309391  ...       0.334628       0.740569            60   \n",
              "2547      0.310895  ...       0.334544       0.740200            61   \n",
              "\n",
              "                 video  label  Right_shoulder_angle  Left_Shoulder_angle  \\\n",
              "0     ankur-make-1.mp4      1              0.000000             0.000000   \n",
              "1     ankur-make-1.mp4      1             91.632777            89.861400   \n",
              "2     ankur-make-1.mp4      1             86.564595            84.381073   \n",
              "3     ankur-make-1.mp4      1             81.780484            80.358441   \n",
              "4     ankur-make-1.mp4      1             69.754535            76.331635   \n",
              "...                ...    ...                   ...                  ...   \n",
              "2543            23.mp4      0             24.993885           109.311059   \n",
              "2544            23.mp4      0             51.062503           108.565706   \n",
              "2545            23.mp4      0             60.489315           105.661801   \n",
              "2546            23.mp4      0             65.094371           106.478589   \n",
              "2547            23.mp4      0             78.226546           104.405066   \n",
              "\n",
              "      Right_wrist_angle  Right_thigh_angle  Left_thigh_angle  \n",
              "0              0.000000           0.000000          0.000000  \n",
              "1             17.659975          85.636815         81.147934  \n",
              "2              7.643551          80.122440         78.685173  \n",
              "3              0.619993          76.545692         71.493804  \n",
              "4            -15.724972          78.640070         75.378355  \n",
              "...                 ...                ...               ...  \n",
              "2543         -20.092856          90.292186         83.867412  \n",
              "2544         -28.560092          89.391243         83.985483  \n",
              "2545         -40.917997          91.127912         82.837666  \n",
              "2546         -31.887617          92.397735         87.047832  \n",
              "2547         -41.611827          90.403579         84.972179  \n",
              "\n",
              "[2548 rows x 33 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eadcf0c1-5827-433e-b65d-32b11d4299ba\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Left_shoulder_x</th>\n",
              "      <th>Left_shoulder_y</th>\n",
              "      <th>Right_shoulder_x</th>\n",
              "      <th>Right_shoulder_y</th>\n",
              "      <th>Left_wrist_y</th>\n",
              "      <th>Left_elbow_x</th>\n",
              "      <th>Left_elbow_y</th>\n",
              "      <th>Right_elbow_x</th>\n",
              "      <th>Right_elbow_y</th>\n",
              "      <th>Left_wrist_x</th>\n",
              "      <th>...</th>\n",
              "      <th>Right_ankle_x</th>\n",
              "      <th>Right_ankle_y</th>\n",
              "      <th>frame_number</th>\n",
              "      <th>video</th>\n",
              "      <th>label</th>\n",
              "      <th>Right_shoulder_angle</th>\n",
              "      <th>Left_Shoulder_angle</th>\n",
              "      <th>Right_wrist_angle</th>\n",
              "      <th>Right_thigh_angle</th>\n",
              "      <th>Left_thigh_angle</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.137992</td>\n",
              "      <td>0.567018</td>\n",
              "      <td>0.114047</td>\n",
              "      <td>0.574758</td>\n",
              "      <td>0.632627</td>\n",
              "      <td>0.138122</td>\n",
              "      <td>0.620622</td>\n",
              "      <td>0.112386</td>\n",
              "      <td>0.633044</td>\n",
              "      <td>0.163240</td>\n",
              "      <td>...</td>\n",
              "      <td>0.101721</td>\n",
              "      <td>0.848228</td>\n",
              "      <td>2</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>91.632777</td>\n",
              "      <td>89.861400</td>\n",
              "      <td>17.659975</td>\n",
              "      <td>85.636815</td>\n",
              "      <td>81.147934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.137748</td>\n",
              "      <td>0.569186</td>\n",
              "      <td>0.115349</td>\n",
              "      <td>0.579705</td>\n",
              "      <td>0.630857</td>\n",
              "      <td>0.142738</td>\n",
              "      <td>0.619906</td>\n",
              "      <td>0.118926</td>\n",
              "      <td>0.639296</td>\n",
              "      <td>0.169016</td>\n",
              "      <td>...</td>\n",
              "      <td>0.102264</td>\n",
              "      <td>0.846033</td>\n",
              "      <td>3</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>86.564595</td>\n",
              "      <td>84.381073</td>\n",
              "      <td>7.643551</td>\n",
              "      <td>80.122440</td>\n",
              "      <td>78.685173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.135332</td>\n",
              "      <td>0.574709</td>\n",
              "      <td>0.118000</td>\n",
              "      <td>0.584913</td>\n",
              "      <td>0.630535</td>\n",
              "      <td>0.143820</td>\n",
              "      <td>0.624669</td>\n",
              "      <td>0.126229</td>\n",
              "      <td>0.641880</td>\n",
              "      <td>0.169926</td>\n",
              "      <td>...</td>\n",
              "      <td>0.105687</td>\n",
              "      <td>0.852329</td>\n",
              "      <td>4</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>81.780484</td>\n",
              "      <td>80.358441</td>\n",
              "      <td>0.619993</td>\n",
              "      <td>76.545692</td>\n",
              "      <td>71.493804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.137106</td>\n",
              "      <td>0.581849</td>\n",
              "      <td>0.117793</td>\n",
              "      <td>0.593527</td>\n",
              "      <td>0.632422</td>\n",
              "      <td>0.148398</td>\n",
              "      <td>0.628282</td>\n",
              "      <td>0.137886</td>\n",
              "      <td>0.648005</td>\n",
              "      <td>0.175129</td>\n",
              "      <td>...</td>\n",
              "      <td>0.108978</td>\n",
              "      <td>0.855727</td>\n",
              "      <td>5</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>69.754535</td>\n",
              "      <td>76.331635</td>\n",
              "      <td>-15.724972</td>\n",
              "      <td>78.640070</td>\n",
              "      <td>75.378355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2543</th>\n",
              "      <td>0.336772</td>\n",
              "      <td>0.450447</td>\n",
              "      <td>0.361769</td>\n",
              "      <td>0.440221</td>\n",
              "      <td>0.571684</td>\n",
              "      <td>0.315813</td>\n",
              "      <td>0.510262</td>\n",
              "      <td>0.387930</td>\n",
              "      <td>0.452417</td>\n",
              "      <td>0.306920</td>\n",
              "      <td>...</td>\n",
              "      <td>0.334408</td>\n",
              "      <td>0.744310</td>\n",
              "      <td>57</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>24.993885</td>\n",
              "      <td>109.311059</td>\n",
              "      <td>-20.092856</td>\n",
              "      <td>90.292186</td>\n",
              "      <td>83.867412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2544</th>\n",
              "      <td>0.336169</td>\n",
              "      <td>0.446795</td>\n",
              "      <td>0.361282</td>\n",
              "      <td>0.442094</td>\n",
              "      <td>0.569260</td>\n",
              "      <td>0.315534</td>\n",
              "      <td>0.508232</td>\n",
              "      <td>0.381513</td>\n",
              "      <td>0.467133</td>\n",
              "      <td>0.306491</td>\n",
              "      <td>...</td>\n",
              "      <td>0.335498</td>\n",
              "      <td>0.741388</td>\n",
              "      <td>58</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>51.062503</td>\n",
              "      <td>108.565706</td>\n",
              "      <td>-28.560092</td>\n",
              "      <td>89.391243</td>\n",
              "      <td>83.985483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2545</th>\n",
              "      <td>0.336118</td>\n",
              "      <td>0.446699</td>\n",
              "      <td>0.360174</td>\n",
              "      <td>0.445972</td>\n",
              "      <td>0.566294</td>\n",
              "      <td>0.317613</td>\n",
              "      <td>0.512701</td>\n",
              "      <td>0.379284</td>\n",
              "      <td>0.479733</td>\n",
              "      <td>0.307859</td>\n",
              "      <td>...</td>\n",
              "      <td>0.332303</td>\n",
              "      <td>0.740661</td>\n",
              "      <td>59</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>60.489315</td>\n",
              "      <td>105.661801</td>\n",
              "      <td>-40.917997</td>\n",
              "      <td>91.127912</td>\n",
              "      <td>82.837666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2546</th>\n",
              "      <td>0.337864</td>\n",
              "      <td>0.445126</td>\n",
              "      <td>0.358200</td>\n",
              "      <td>0.446341</td>\n",
              "      <td>0.569123</td>\n",
              "      <td>0.318504</td>\n",
              "      <td>0.510571</td>\n",
              "      <td>0.374125</td>\n",
              "      <td>0.480640</td>\n",
              "      <td>0.309391</td>\n",
              "      <td>...</td>\n",
              "      <td>0.334628</td>\n",
              "      <td>0.740569</td>\n",
              "      <td>60</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>65.094371</td>\n",
              "      <td>106.478589</td>\n",
              "      <td>-31.887617</td>\n",
              "      <td>92.397735</td>\n",
              "      <td>87.047832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2547</th>\n",
              "      <td>0.334369</td>\n",
              "      <td>0.441393</td>\n",
              "      <td>0.358173</td>\n",
              "      <td>0.447999</td>\n",
              "      <td>0.570865</td>\n",
              "      <td>0.316519</td>\n",
              "      <td>0.510886</td>\n",
              "      <td>0.367897</td>\n",
              "      <td>0.494650</td>\n",
              "      <td>0.310895</td>\n",
              "      <td>...</td>\n",
              "      <td>0.334544</td>\n",
              "      <td>0.740200</td>\n",
              "      <td>61</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>78.226546</td>\n",
              "      <td>104.405066</td>\n",
              "      <td>-41.611827</td>\n",
              "      <td>90.403579</td>\n",
              "      <td>84.972179</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2548 rows × 33 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eadcf0c1-5827-433e-b65d-32b11d4299ba')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-eadcf0c1-5827-433e-b65d-32b11d4299ba button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-eadcf0c1-5827-433e-b65d-32b11d4299ba');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0b456bdc-0f57-4b1b-b3f5-2e0f714320ef\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0b456bdc-0f57-4b1b-b3f5-2e0f714320ef')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0b456bdc-0f57-4b1b-b3f5-2e0f714320ef button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_441c6e99-d7c2-4889-9443-5a1409ba7c74\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_all_coord_updated')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_441c6e99-d7c2-4889-9443-5a1409ba7c74 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_all_coord_updated');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "angle_calculator(df_all_coord_updated, 'Left_knee', 'Left_ankle','Left_femur_angle')\n",
        "df_all_coord_updated"
      ],
      "metadata": {
        "id": "I-l4qNvv8zfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "outputId": "67d819e4-e48d-41ab-a72a-79caaffc9c60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Left_knee_x Left_knee_y Left_ankle_x Left_ankle_y\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Left_shoulder_x  Left_shoulder_y  Right_shoulder_x  Right_shoulder_y  \\\n",
              "0            0.000000         0.000000          0.000000          0.000000   \n",
              "1            0.137992         0.567018          0.114047          0.574758   \n",
              "2            0.137748         0.569186          0.115349          0.579705   \n",
              "3            0.135332         0.574709          0.118000          0.584913   \n",
              "4            0.137106         0.581849          0.117793          0.593527   \n",
              "...               ...              ...               ...               ...   \n",
              "2543         0.336772         0.450447          0.361769          0.440221   \n",
              "2544         0.336169         0.446795          0.361282          0.442094   \n",
              "2545         0.336118         0.446699          0.360174          0.445972   \n",
              "2546         0.337864         0.445126          0.358200          0.446341   \n",
              "2547         0.334369         0.441393          0.358173          0.447999   \n",
              "\n",
              "      Left_wrist_y  Left_elbow_x  Left_elbow_y  Right_elbow_x  Right_elbow_y  \\\n",
              "0         0.000000      0.000000      0.000000       0.000000       0.000000   \n",
              "1         0.632627      0.138122      0.620622       0.112386       0.633044   \n",
              "2         0.630857      0.142738      0.619906       0.118926       0.639296   \n",
              "3         0.630535      0.143820      0.624669       0.126229       0.641880   \n",
              "4         0.632422      0.148398      0.628282       0.137886       0.648005   \n",
              "...            ...           ...           ...            ...            ...   \n",
              "2543      0.571684      0.315813      0.510262       0.387930       0.452417   \n",
              "2544      0.569260      0.315534      0.508232       0.381513       0.467133   \n",
              "2545      0.566294      0.317613      0.512701       0.379284       0.479733   \n",
              "2546      0.569123      0.318504      0.510571       0.374125       0.480640   \n",
              "2547      0.570865      0.316519      0.510886       0.367897       0.494650   \n",
              "\n",
              "      Left_wrist_x  ...  Right_ankle_y  frame_number             video  label  \\\n",
              "0         0.000000  ...       0.000000             1  ankur-make-1.mp4      1   \n",
              "1         0.163240  ...       0.848228             2  ankur-make-1.mp4      1   \n",
              "2         0.169016  ...       0.846033             3  ankur-make-1.mp4      1   \n",
              "3         0.169926  ...       0.852329             4  ankur-make-1.mp4      1   \n",
              "4         0.175129  ...       0.855727             5  ankur-make-1.mp4      1   \n",
              "...            ...  ...            ...           ...               ...    ...   \n",
              "2543      0.306920  ...       0.744310            57            23.mp4      0   \n",
              "2544      0.306491  ...       0.741388            58            23.mp4      0   \n",
              "2545      0.307859  ...       0.740661            59            23.mp4      0   \n",
              "2546      0.309391  ...       0.740569            60            23.mp4      0   \n",
              "2547      0.310895  ...       0.740200            61            23.mp4      0   \n",
              "\n",
              "      Right_shoulder_angle  Left_Shoulder_angle  Right_wrist_angle  \\\n",
              "0                 0.000000             0.000000           0.000000   \n",
              "1                91.632777            89.861400          17.659975   \n",
              "2                86.564595            84.381073           7.643551   \n",
              "3                81.780484            80.358441           0.619993   \n",
              "4                69.754535            76.331635         -15.724972   \n",
              "...                    ...                  ...                ...   \n",
              "2543             24.993885           109.311059         -20.092856   \n",
              "2544             51.062503           108.565706         -28.560092   \n",
              "2545             60.489315           105.661801         -40.917997   \n",
              "2546             65.094371           106.478589         -31.887617   \n",
              "2547             78.226546           104.405066         -41.611827   \n",
              "\n",
              "      Right_thigh_angle  Left_thigh_angle  Left_femur_angle  \n",
              "0              0.000000          0.000000          0.000000  \n",
              "1             85.636815         81.147934        104.047748  \n",
              "2             80.122440         78.685173        105.756077  \n",
              "3             76.545692         71.493804        111.111186  \n",
              "4             78.640070         75.378355        117.127077  \n",
              "...                 ...               ...               ...  \n",
              "2543          90.292186         83.867412         93.736411  \n",
              "2544          89.391243         83.985483         93.651813  \n",
              "2545          91.127912         82.837666         93.438897  \n",
              "2546          92.397735         87.047832         90.745309  \n",
              "2547          90.403579         84.972179         91.582599  \n",
              "\n",
              "[2548 rows x 34 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b43db273-9ae4-49ac-8b42-100434f47028\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Left_shoulder_x</th>\n",
              "      <th>Left_shoulder_y</th>\n",
              "      <th>Right_shoulder_x</th>\n",
              "      <th>Right_shoulder_y</th>\n",
              "      <th>Left_wrist_y</th>\n",
              "      <th>Left_elbow_x</th>\n",
              "      <th>Left_elbow_y</th>\n",
              "      <th>Right_elbow_x</th>\n",
              "      <th>Right_elbow_y</th>\n",
              "      <th>Left_wrist_x</th>\n",
              "      <th>...</th>\n",
              "      <th>Right_ankle_y</th>\n",
              "      <th>frame_number</th>\n",
              "      <th>video</th>\n",
              "      <th>label</th>\n",
              "      <th>Right_shoulder_angle</th>\n",
              "      <th>Left_Shoulder_angle</th>\n",
              "      <th>Right_wrist_angle</th>\n",
              "      <th>Right_thigh_angle</th>\n",
              "      <th>Left_thigh_angle</th>\n",
              "      <th>Left_femur_angle</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.137992</td>\n",
              "      <td>0.567018</td>\n",
              "      <td>0.114047</td>\n",
              "      <td>0.574758</td>\n",
              "      <td>0.632627</td>\n",
              "      <td>0.138122</td>\n",
              "      <td>0.620622</td>\n",
              "      <td>0.112386</td>\n",
              "      <td>0.633044</td>\n",
              "      <td>0.163240</td>\n",
              "      <td>...</td>\n",
              "      <td>0.848228</td>\n",
              "      <td>2</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>91.632777</td>\n",
              "      <td>89.861400</td>\n",
              "      <td>17.659975</td>\n",
              "      <td>85.636815</td>\n",
              "      <td>81.147934</td>\n",
              "      <td>104.047748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.137748</td>\n",
              "      <td>0.569186</td>\n",
              "      <td>0.115349</td>\n",
              "      <td>0.579705</td>\n",
              "      <td>0.630857</td>\n",
              "      <td>0.142738</td>\n",
              "      <td>0.619906</td>\n",
              "      <td>0.118926</td>\n",
              "      <td>0.639296</td>\n",
              "      <td>0.169016</td>\n",
              "      <td>...</td>\n",
              "      <td>0.846033</td>\n",
              "      <td>3</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>86.564595</td>\n",
              "      <td>84.381073</td>\n",
              "      <td>7.643551</td>\n",
              "      <td>80.122440</td>\n",
              "      <td>78.685173</td>\n",
              "      <td>105.756077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.135332</td>\n",
              "      <td>0.574709</td>\n",
              "      <td>0.118000</td>\n",
              "      <td>0.584913</td>\n",
              "      <td>0.630535</td>\n",
              "      <td>0.143820</td>\n",
              "      <td>0.624669</td>\n",
              "      <td>0.126229</td>\n",
              "      <td>0.641880</td>\n",
              "      <td>0.169926</td>\n",
              "      <td>...</td>\n",
              "      <td>0.852329</td>\n",
              "      <td>4</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>81.780484</td>\n",
              "      <td>80.358441</td>\n",
              "      <td>0.619993</td>\n",
              "      <td>76.545692</td>\n",
              "      <td>71.493804</td>\n",
              "      <td>111.111186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.137106</td>\n",
              "      <td>0.581849</td>\n",
              "      <td>0.117793</td>\n",
              "      <td>0.593527</td>\n",
              "      <td>0.632422</td>\n",
              "      <td>0.148398</td>\n",
              "      <td>0.628282</td>\n",
              "      <td>0.137886</td>\n",
              "      <td>0.648005</td>\n",
              "      <td>0.175129</td>\n",
              "      <td>...</td>\n",
              "      <td>0.855727</td>\n",
              "      <td>5</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>69.754535</td>\n",
              "      <td>76.331635</td>\n",
              "      <td>-15.724972</td>\n",
              "      <td>78.640070</td>\n",
              "      <td>75.378355</td>\n",
              "      <td>117.127077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2543</th>\n",
              "      <td>0.336772</td>\n",
              "      <td>0.450447</td>\n",
              "      <td>0.361769</td>\n",
              "      <td>0.440221</td>\n",
              "      <td>0.571684</td>\n",
              "      <td>0.315813</td>\n",
              "      <td>0.510262</td>\n",
              "      <td>0.387930</td>\n",
              "      <td>0.452417</td>\n",
              "      <td>0.306920</td>\n",
              "      <td>...</td>\n",
              "      <td>0.744310</td>\n",
              "      <td>57</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>24.993885</td>\n",
              "      <td>109.311059</td>\n",
              "      <td>-20.092856</td>\n",
              "      <td>90.292186</td>\n",
              "      <td>83.867412</td>\n",
              "      <td>93.736411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2544</th>\n",
              "      <td>0.336169</td>\n",
              "      <td>0.446795</td>\n",
              "      <td>0.361282</td>\n",
              "      <td>0.442094</td>\n",
              "      <td>0.569260</td>\n",
              "      <td>0.315534</td>\n",
              "      <td>0.508232</td>\n",
              "      <td>0.381513</td>\n",
              "      <td>0.467133</td>\n",
              "      <td>0.306491</td>\n",
              "      <td>...</td>\n",
              "      <td>0.741388</td>\n",
              "      <td>58</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>51.062503</td>\n",
              "      <td>108.565706</td>\n",
              "      <td>-28.560092</td>\n",
              "      <td>89.391243</td>\n",
              "      <td>83.985483</td>\n",
              "      <td>93.651813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2545</th>\n",
              "      <td>0.336118</td>\n",
              "      <td>0.446699</td>\n",
              "      <td>0.360174</td>\n",
              "      <td>0.445972</td>\n",
              "      <td>0.566294</td>\n",
              "      <td>0.317613</td>\n",
              "      <td>0.512701</td>\n",
              "      <td>0.379284</td>\n",
              "      <td>0.479733</td>\n",
              "      <td>0.307859</td>\n",
              "      <td>...</td>\n",
              "      <td>0.740661</td>\n",
              "      <td>59</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>60.489315</td>\n",
              "      <td>105.661801</td>\n",
              "      <td>-40.917997</td>\n",
              "      <td>91.127912</td>\n",
              "      <td>82.837666</td>\n",
              "      <td>93.438897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2546</th>\n",
              "      <td>0.337864</td>\n",
              "      <td>0.445126</td>\n",
              "      <td>0.358200</td>\n",
              "      <td>0.446341</td>\n",
              "      <td>0.569123</td>\n",
              "      <td>0.318504</td>\n",
              "      <td>0.510571</td>\n",
              "      <td>0.374125</td>\n",
              "      <td>0.480640</td>\n",
              "      <td>0.309391</td>\n",
              "      <td>...</td>\n",
              "      <td>0.740569</td>\n",
              "      <td>60</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>65.094371</td>\n",
              "      <td>106.478589</td>\n",
              "      <td>-31.887617</td>\n",
              "      <td>92.397735</td>\n",
              "      <td>87.047832</td>\n",
              "      <td>90.745309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2547</th>\n",
              "      <td>0.334369</td>\n",
              "      <td>0.441393</td>\n",
              "      <td>0.358173</td>\n",
              "      <td>0.447999</td>\n",
              "      <td>0.570865</td>\n",
              "      <td>0.316519</td>\n",
              "      <td>0.510886</td>\n",
              "      <td>0.367897</td>\n",
              "      <td>0.494650</td>\n",
              "      <td>0.310895</td>\n",
              "      <td>...</td>\n",
              "      <td>0.740200</td>\n",
              "      <td>61</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>78.226546</td>\n",
              "      <td>104.405066</td>\n",
              "      <td>-41.611827</td>\n",
              "      <td>90.403579</td>\n",
              "      <td>84.972179</td>\n",
              "      <td>91.582599</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2548 rows × 34 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b43db273-9ae4-49ac-8b42-100434f47028')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b43db273-9ae4-49ac-8b42-100434f47028 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b43db273-9ae4-49ac-8b42-100434f47028');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-53c12c3c-4c53-4b50-a6a2-3ffa785481db\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-53c12c3c-4c53-4b50-a6a2-3ffa785481db')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-53c12c3c-4c53-4b50-a6a2-3ffa785481db button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_bfb4ee5c-98f7-40f3-84d1-e6590da6bb6d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_all_coord_updated')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_bfb4ee5c-98f7-40f3-84d1-e6590da6bb6d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_all_coord_updated');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "angle_calculator(df_all_coord_updated, 'Right_knee', 'Right_ankle','Right_femur_angle')\n",
        "df_all_coord_updated"
      ],
      "metadata": {
        "id": "yh66Qgx187Km",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "outputId": "e653775b-fc0c-4dc7-eaa9-005096e11bc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Right_knee_x Right_knee_y Right_ankle_x Right_ankle_y\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Left_shoulder_x  Left_shoulder_y  Right_shoulder_x  Right_shoulder_y  \\\n",
              "0            0.000000         0.000000          0.000000          0.000000   \n",
              "1            0.137992         0.567018          0.114047          0.574758   \n",
              "2            0.137748         0.569186          0.115349          0.579705   \n",
              "3            0.135332         0.574709          0.118000          0.584913   \n",
              "4            0.137106         0.581849          0.117793          0.593527   \n",
              "...               ...              ...               ...               ...   \n",
              "2543         0.336772         0.450447          0.361769          0.440221   \n",
              "2544         0.336169         0.446795          0.361282          0.442094   \n",
              "2545         0.336118         0.446699          0.360174          0.445972   \n",
              "2546         0.337864         0.445126          0.358200          0.446341   \n",
              "2547         0.334369         0.441393          0.358173          0.447999   \n",
              "\n",
              "      Left_wrist_y  Left_elbow_x  Left_elbow_y  Right_elbow_x  Right_elbow_y  \\\n",
              "0         0.000000      0.000000      0.000000       0.000000       0.000000   \n",
              "1         0.632627      0.138122      0.620622       0.112386       0.633044   \n",
              "2         0.630857      0.142738      0.619906       0.118926       0.639296   \n",
              "3         0.630535      0.143820      0.624669       0.126229       0.641880   \n",
              "4         0.632422      0.148398      0.628282       0.137886       0.648005   \n",
              "...            ...           ...           ...            ...            ...   \n",
              "2543      0.571684      0.315813      0.510262       0.387930       0.452417   \n",
              "2544      0.569260      0.315534      0.508232       0.381513       0.467133   \n",
              "2545      0.566294      0.317613      0.512701       0.379284       0.479733   \n",
              "2546      0.569123      0.318504      0.510571       0.374125       0.480640   \n",
              "2547      0.570865      0.316519      0.510886       0.367897       0.494650   \n",
              "\n",
              "      Left_wrist_x  ...  frame_number             video  label  \\\n",
              "0         0.000000  ...             1  ankur-make-1.mp4      1   \n",
              "1         0.163240  ...             2  ankur-make-1.mp4      1   \n",
              "2         0.169016  ...             3  ankur-make-1.mp4      1   \n",
              "3         0.169926  ...             4  ankur-make-1.mp4      1   \n",
              "4         0.175129  ...             5  ankur-make-1.mp4      1   \n",
              "...            ...  ...           ...               ...    ...   \n",
              "2543      0.306920  ...            57            23.mp4      0   \n",
              "2544      0.306491  ...            58            23.mp4      0   \n",
              "2545      0.307859  ...            59            23.mp4      0   \n",
              "2546      0.309391  ...            60            23.mp4      0   \n",
              "2547      0.310895  ...            61            23.mp4      0   \n",
              "\n",
              "      Right_shoulder_angle  Left_Shoulder_angle  Right_wrist_angle  \\\n",
              "0                 0.000000             0.000000           0.000000   \n",
              "1                91.632777            89.861400          17.659975   \n",
              "2                86.564595            84.381073           7.643551   \n",
              "3                81.780484            80.358441           0.619993   \n",
              "4                69.754535            76.331635         -15.724972   \n",
              "...                    ...                  ...                ...   \n",
              "2543             24.993885           109.311059         -20.092856   \n",
              "2544             51.062503           108.565706         -28.560092   \n",
              "2545             60.489315           105.661801         -40.917997   \n",
              "2546             65.094371           106.478589         -31.887617   \n",
              "2547             78.226546           104.405066         -41.611827   \n",
              "\n",
              "      Right_thigh_angle  Left_thigh_angle  Left_femur_angle  Right_femur_angle  \n",
              "0              0.000000          0.000000          0.000000           0.000000  \n",
              "1             85.636815         81.147934        104.047748         102.487828  \n",
              "2             80.122440         78.685173        105.756077         108.691545  \n",
              "3             76.545692         71.493804        111.111186         109.450115  \n",
              "4             78.640070         75.378355        117.127077         109.809570  \n",
              "...                 ...               ...               ...                ...  \n",
              "2543          90.292186         83.867412         93.736411         104.157638  \n",
              "2544          89.391243         83.985483         93.651813         104.449236  \n",
              "2545          91.127912         82.837666         93.438897         104.635814  \n",
              "2546          92.397735         87.047832         90.745309         100.742641  \n",
              "2547          90.403579         84.972179         91.582599         103.917125  \n",
              "\n",
              "[2548 rows x 35 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1b58c40e-c9d2-42e1-adfd-842587a1c77b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Left_shoulder_x</th>\n",
              "      <th>Left_shoulder_y</th>\n",
              "      <th>Right_shoulder_x</th>\n",
              "      <th>Right_shoulder_y</th>\n",
              "      <th>Left_wrist_y</th>\n",
              "      <th>Left_elbow_x</th>\n",
              "      <th>Left_elbow_y</th>\n",
              "      <th>Right_elbow_x</th>\n",
              "      <th>Right_elbow_y</th>\n",
              "      <th>Left_wrist_x</th>\n",
              "      <th>...</th>\n",
              "      <th>frame_number</th>\n",
              "      <th>video</th>\n",
              "      <th>label</th>\n",
              "      <th>Right_shoulder_angle</th>\n",
              "      <th>Left_Shoulder_angle</th>\n",
              "      <th>Right_wrist_angle</th>\n",
              "      <th>Right_thigh_angle</th>\n",
              "      <th>Left_thigh_angle</th>\n",
              "      <th>Left_femur_angle</th>\n",
              "      <th>Right_femur_angle</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.137992</td>\n",
              "      <td>0.567018</td>\n",
              "      <td>0.114047</td>\n",
              "      <td>0.574758</td>\n",
              "      <td>0.632627</td>\n",
              "      <td>0.138122</td>\n",
              "      <td>0.620622</td>\n",
              "      <td>0.112386</td>\n",
              "      <td>0.633044</td>\n",
              "      <td>0.163240</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>91.632777</td>\n",
              "      <td>89.861400</td>\n",
              "      <td>17.659975</td>\n",
              "      <td>85.636815</td>\n",
              "      <td>81.147934</td>\n",
              "      <td>104.047748</td>\n",
              "      <td>102.487828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.137748</td>\n",
              "      <td>0.569186</td>\n",
              "      <td>0.115349</td>\n",
              "      <td>0.579705</td>\n",
              "      <td>0.630857</td>\n",
              "      <td>0.142738</td>\n",
              "      <td>0.619906</td>\n",
              "      <td>0.118926</td>\n",
              "      <td>0.639296</td>\n",
              "      <td>0.169016</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>86.564595</td>\n",
              "      <td>84.381073</td>\n",
              "      <td>7.643551</td>\n",
              "      <td>80.122440</td>\n",
              "      <td>78.685173</td>\n",
              "      <td>105.756077</td>\n",
              "      <td>108.691545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.135332</td>\n",
              "      <td>0.574709</td>\n",
              "      <td>0.118000</td>\n",
              "      <td>0.584913</td>\n",
              "      <td>0.630535</td>\n",
              "      <td>0.143820</td>\n",
              "      <td>0.624669</td>\n",
              "      <td>0.126229</td>\n",
              "      <td>0.641880</td>\n",
              "      <td>0.169926</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>81.780484</td>\n",
              "      <td>80.358441</td>\n",
              "      <td>0.619993</td>\n",
              "      <td>76.545692</td>\n",
              "      <td>71.493804</td>\n",
              "      <td>111.111186</td>\n",
              "      <td>109.450115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.137106</td>\n",
              "      <td>0.581849</td>\n",
              "      <td>0.117793</td>\n",
              "      <td>0.593527</td>\n",
              "      <td>0.632422</td>\n",
              "      <td>0.148398</td>\n",
              "      <td>0.628282</td>\n",
              "      <td>0.137886</td>\n",
              "      <td>0.648005</td>\n",
              "      <td>0.175129</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>69.754535</td>\n",
              "      <td>76.331635</td>\n",
              "      <td>-15.724972</td>\n",
              "      <td>78.640070</td>\n",
              "      <td>75.378355</td>\n",
              "      <td>117.127077</td>\n",
              "      <td>109.809570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2543</th>\n",
              "      <td>0.336772</td>\n",
              "      <td>0.450447</td>\n",
              "      <td>0.361769</td>\n",
              "      <td>0.440221</td>\n",
              "      <td>0.571684</td>\n",
              "      <td>0.315813</td>\n",
              "      <td>0.510262</td>\n",
              "      <td>0.387930</td>\n",
              "      <td>0.452417</td>\n",
              "      <td>0.306920</td>\n",
              "      <td>...</td>\n",
              "      <td>57</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>24.993885</td>\n",
              "      <td>109.311059</td>\n",
              "      <td>-20.092856</td>\n",
              "      <td>90.292186</td>\n",
              "      <td>83.867412</td>\n",
              "      <td>93.736411</td>\n",
              "      <td>104.157638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2544</th>\n",
              "      <td>0.336169</td>\n",
              "      <td>0.446795</td>\n",
              "      <td>0.361282</td>\n",
              "      <td>0.442094</td>\n",
              "      <td>0.569260</td>\n",
              "      <td>0.315534</td>\n",
              "      <td>0.508232</td>\n",
              "      <td>0.381513</td>\n",
              "      <td>0.467133</td>\n",
              "      <td>0.306491</td>\n",
              "      <td>...</td>\n",
              "      <td>58</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>51.062503</td>\n",
              "      <td>108.565706</td>\n",
              "      <td>-28.560092</td>\n",
              "      <td>89.391243</td>\n",
              "      <td>83.985483</td>\n",
              "      <td>93.651813</td>\n",
              "      <td>104.449236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2545</th>\n",
              "      <td>0.336118</td>\n",
              "      <td>0.446699</td>\n",
              "      <td>0.360174</td>\n",
              "      <td>0.445972</td>\n",
              "      <td>0.566294</td>\n",
              "      <td>0.317613</td>\n",
              "      <td>0.512701</td>\n",
              "      <td>0.379284</td>\n",
              "      <td>0.479733</td>\n",
              "      <td>0.307859</td>\n",
              "      <td>...</td>\n",
              "      <td>59</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>60.489315</td>\n",
              "      <td>105.661801</td>\n",
              "      <td>-40.917997</td>\n",
              "      <td>91.127912</td>\n",
              "      <td>82.837666</td>\n",
              "      <td>93.438897</td>\n",
              "      <td>104.635814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2546</th>\n",
              "      <td>0.337864</td>\n",
              "      <td>0.445126</td>\n",
              "      <td>0.358200</td>\n",
              "      <td>0.446341</td>\n",
              "      <td>0.569123</td>\n",
              "      <td>0.318504</td>\n",
              "      <td>0.510571</td>\n",
              "      <td>0.374125</td>\n",
              "      <td>0.480640</td>\n",
              "      <td>0.309391</td>\n",
              "      <td>...</td>\n",
              "      <td>60</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>65.094371</td>\n",
              "      <td>106.478589</td>\n",
              "      <td>-31.887617</td>\n",
              "      <td>92.397735</td>\n",
              "      <td>87.047832</td>\n",
              "      <td>90.745309</td>\n",
              "      <td>100.742641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2547</th>\n",
              "      <td>0.334369</td>\n",
              "      <td>0.441393</td>\n",
              "      <td>0.358173</td>\n",
              "      <td>0.447999</td>\n",
              "      <td>0.570865</td>\n",
              "      <td>0.316519</td>\n",
              "      <td>0.510886</td>\n",
              "      <td>0.367897</td>\n",
              "      <td>0.494650</td>\n",
              "      <td>0.310895</td>\n",
              "      <td>...</td>\n",
              "      <td>61</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>78.226546</td>\n",
              "      <td>104.405066</td>\n",
              "      <td>-41.611827</td>\n",
              "      <td>90.403579</td>\n",
              "      <td>84.972179</td>\n",
              "      <td>91.582599</td>\n",
              "      <td>103.917125</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2548 rows × 35 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b58c40e-c9d2-42e1-adfd-842587a1c77b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1b58c40e-c9d2-42e1-adfd-842587a1c77b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1b58c40e-c9d2-42e1-adfd-842587a1c77b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-071d5f65-2cc1-42ee-86d8-d9e7db87afb7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-071d5f65-2cc1-42ee-86d8-d9e7db87afb7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-071d5f65-2cc1-42ee-86d8-d9e7db87afb7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e0d47f80-5efb-4827-9b76-19b546c2252d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_all_coord_updated')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e0d47f80-5efb-4827-9b76-19b546c2252d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_all_coord_updated');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "angle_calculator( df_all_coord_updated,'Left_hip', 'Right_hip','hip_angle')\n",
        "df_all_coord_updated"
      ],
      "metadata": {
        "id": "PU8pzFb19FU6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "outputId": "57b8fa47-034e-4b05-e3c5-b85afbd0758e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Left_hip_x Left_hip_y Right_hip_x Right_hip_y\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Left_shoulder_x  Left_shoulder_y  Right_shoulder_x  Right_shoulder_y  \\\n",
              "0            0.000000         0.000000          0.000000          0.000000   \n",
              "1            0.137992         0.567018          0.114047          0.574758   \n",
              "2            0.137748         0.569186          0.115349          0.579705   \n",
              "3            0.135332         0.574709          0.118000          0.584913   \n",
              "4            0.137106         0.581849          0.117793          0.593527   \n",
              "...               ...              ...               ...               ...   \n",
              "2543         0.336772         0.450447          0.361769          0.440221   \n",
              "2544         0.336169         0.446795          0.361282          0.442094   \n",
              "2545         0.336118         0.446699          0.360174          0.445972   \n",
              "2546         0.337864         0.445126          0.358200          0.446341   \n",
              "2547         0.334369         0.441393          0.358173          0.447999   \n",
              "\n",
              "      Left_wrist_y  Left_elbow_x  Left_elbow_y  Right_elbow_x  Right_elbow_y  \\\n",
              "0         0.000000      0.000000      0.000000       0.000000       0.000000   \n",
              "1         0.632627      0.138122      0.620622       0.112386       0.633044   \n",
              "2         0.630857      0.142738      0.619906       0.118926       0.639296   \n",
              "3         0.630535      0.143820      0.624669       0.126229       0.641880   \n",
              "4         0.632422      0.148398      0.628282       0.137886       0.648005   \n",
              "...            ...           ...           ...            ...            ...   \n",
              "2543      0.571684      0.315813      0.510262       0.387930       0.452417   \n",
              "2544      0.569260      0.315534      0.508232       0.381513       0.467133   \n",
              "2545      0.566294      0.317613      0.512701       0.379284       0.479733   \n",
              "2546      0.569123      0.318504      0.510571       0.374125       0.480640   \n",
              "2547      0.570865      0.316519      0.510886       0.367897       0.494650   \n",
              "\n",
              "      Left_wrist_x  ...             video  label  Right_shoulder_angle  \\\n",
              "0         0.000000  ...  ankur-make-1.mp4      1              0.000000   \n",
              "1         0.163240  ...  ankur-make-1.mp4      1             91.632777   \n",
              "2         0.169016  ...  ankur-make-1.mp4      1             86.564595   \n",
              "3         0.169926  ...  ankur-make-1.mp4      1             81.780484   \n",
              "4         0.175129  ...  ankur-make-1.mp4      1             69.754535   \n",
              "...            ...  ...               ...    ...                   ...   \n",
              "2543      0.306920  ...            23.mp4      0             24.993885   \n",
              "2544      0.306491  ...            23.mp4      0             51.062503   \n",
              "2545      0.307859  ...            23.mp4      0             60.489315   \n",
              "2546      0.309391  ...            23.mp4      0             65.094371   \n",
              "2547      0.310895  ...            23.mp4      0             78.226546   \n",
              "\n",
              "      Left_Shoulder_angle  Right_wrist_angle  Right_thigh_angle  \\\n",
              "0                0.000000           0.000000           0.000000   \n",
              "1               89.861400          17.659975          85.636815   \n",
              "2               84.381073           7.643551          80.122440   \n",
              "3               80.358441           0.619993          76.545692   \n",
              "4               76.331635         -15.724972          78.640070   \n",
              "...                   ...                ...                ...   \n",
              "2543           109.311059         -20.092856          90.292186   \n",
              "2544           108.565706         -28.560092          89.391243   \n",
              "2545           105.661801         -40.917997          91.127912   \n",
              "2546           106.478589         -31.887617          92.397735   \n",
              "2547           104.405066         -41.611827          90.403579   \n",
              "\n",
              "      Left_thigh_angle  Left_femur_angle  Right_femur_angle   hip_angle  \n",
              "0             0.000000          0.000000           0.000000    0.000000  \n",
              "1            81.147934        104.047748         102.487828  159.689104  \n",
              "2            78.685173        105.756077         108.691545  156.412974  \n",
              "3            71.493804        111.111186         109.450115  149.968763  \n",
              "4            75.378355        117.127077         109.809570  150.714713  \n",
              "...                ...               ...                ...         ...  \n",
              "2543         83.867412         93.736411         104.157638   -8.234357  \n",
              "2544         83.985483         93.651813         104.449236    0.830669  \n",
              "2545         82.837666         93.438897         104.635814   14.399112  \n",
              "2546         87.047832         90.745309         100.742641   21.186660  \n",
              "2547         84.972179         91.582599         103.917125   25.539175  \n",
              "\n",
              "[2548 rows x 36 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d9a64b9d-49f6-4deb-98b3-ce28852e328e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Left_shoulder_x</th>\n",
              "      <th>Left_shoulder_y</th>\n",
              "      <th>Right_shoulder_x</th>\n",
              "      <th>Right_shoulder_y</th>\n",
              "      <th>Left_wrist_y</th>\n",
              "      <th>Left_elbow_x</th>\n",
              "      <th>Left_elbow_y</th>\n",
              "      <th>Right_elbow_x</th>\n",
              "      <th>Right_elbow_y</th>\n",
              "      <th>Left_wrist_x</th>\n",
              "      <th>...</th>\n",
              "      <th>video</th>\n",
              "      <th>label</th>\n",
              "      <th>Right_shoulder_angle</th>\n",
              "      <th>Left_Shoulder_angle</th>\n",
              "      <th>Right_wrist_angle</th>\n",
              "      <th>Right_thigh_angle</th>\n",
              "      <th>Left_thigh_angle</th>\n",
              "      <th>Left_femur_angle</th>\n",
              "      <th>Right_femur_angle</th>\n",
              "      <th>hip_angle</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.137992</td>\n",
              "      <td>0.567018</td>\n",
              "      <td>0.114047</td>\n",
              "      <td>0.574758</td>\n",
              "      <td>0.632627</td>\n",
              "      <td>0.138122</td>\n",
              "      <td>0.620622</td>\n",
              "      <td>0.112386</td>\n",
              "      <td>0.633044</td>\n",
              "      <td>0.163240</td>\n",
              "      <td>...</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>91.632777</td>\n",
              "      <td>89.861400</td>\n",
              "      <td>17.659975</td>\n",
              "      <td>85.636815</td>\n",
              "      <td>81.147934</td>\n",
              "      <td>104.047748</td>\n",
              "      <td>102.487828</td>\n",
              "      <td>159.689104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.137748</td>\n",
              "      <td>0.569186</td>\n",
              "      <td>0.115349</td>\n",
              "      <td>0.579705</td>\n",
              "      <td>0.630857</td>\n",
              "      <td>0.142738</td>\n",
              "      <td>0.619906</td>\n",
              "      <td>0.118926</td>\n",
              "      <td>0.639296</td>\n",
              "      <td>0.169016</td>\n",
              "      <td>...</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>86.564595</td>\n",
              "      <td>84.381073</td>\n",
              "      <td>7.643551</td>\n",
              "      <td>80.122440</td>\n",
              "      <td>78.685173</td>\n",
              "      <td>105.756077</td>\n",
              "      <td>108.691545</td>\n",
              "      <td>156.412974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.135332</td>\n",
              "      <td>0.574709</td>\n",
              "      <td>0.118000</td>\n",
              "      <td>0.584913</td>\n",
              "      <td>0.630535</td>\n",
              "      <td>0.143820</td>\n",
              "      <td>0.624669</td>\n",
              "      <td>0.126229</td>\n",
              "      <td>0.641880</td>\n",
              "      <td>0.169926</td>\n",
              "      <td>...</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>81.780484</td>\n",
              "      <td>80.358441</td>\n",
              "      <td>0.619993</td>\n",
              "      <td>76.545692</td>\n",
              "      <td>71.493804</td>\n",
              "      <td>111.111186</td>\n",
              "      <td>109.450115</td>\n",
              "      <td>149.968763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.137106</td>\n",
              "      <td>0.581849</td>\n",
              "      <td>0.117793</td>\n",
              "      <td>0.593527</td>\n",
              "      <td>0.632422</td>\n",
              "      <td>0.148398</td>\n",
              "      <td>0.628282</td>\n",
              "      <td>0.137886</td>\n",
              "      <td>0.648005</td>\n",
              "      <td>0.175129</td>\n",
              "      <td>...</td>\n",
              "      <td>ankur-make-1.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>69.754535</td>\n",
              "      <td>76.331635</td>\n",
              "      <td>-15.724972</td>\n",
              "      <td>78.640070</td>\n",
              "      <td>75.378355</td>\n",
              "      <td>117.127077</td>\n",
              "      <td>109.809570</td>\n",
              "      <td>150.714713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2543</th>\n",
              "      <td>0.336772</td>\n",
              "      <td>0.450447</td>\n",
              "      <td>0.361769</td>\n",
              "      <td>0.440221</td>\n",
              "      <td>0.571684</td>\n",
              "      <td>0.315813</td>\n",
              "      <td>0.510262</td>\n",
              "      <td>0.387930</td>\n",
              "      <td>0.452417</td>\n",
              "      <td>0.306920</td>\n",
              "      <td>...</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>24.993885</td>\n",
              "      <td>109.311059</td>\n",
              "      <td>-20.092856</td>\n",
              "      <td>90.292186</td>\n",
              "      <td>83.867412</td>\n",
              "      <td>93.736411</td>\n",
              "      <td>104.157638</td>\n",
              "      <td>-8.234357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2544</th>\n",
              "      <td>0.336169</td>\n",
              "      <td>0.446795</td>\n",
              "      <td>0.361282</td>\n",
              "      <td>0.442094</td>\n",
              "      <td>0.569260</td>\n",
              "      <td>0.315534</td>\n",
              "      <td>0.508232</td>\n",
              "      <td>0.381513</td>\n",
              "      <td>0.467133</td>\n",
              "      <td>0.306491</td>\n",
              "      <td>...</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>51.062503</td>\n",
              "      <td>108.565706</td>\n",
              "      <td>-28.560092</td>\n",
              "      <td>89.391243</td>\n",
              "      <td>83.985483</td>\n",
              "      <td>93.651813</td>\n",
              "      <td>104.449236</td>\n",
              "      <td>0.830669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2545</th>\n",
              "      <td>0.336118</td>\n",
              "      <td>0.446699</td>\n",
              "      <td>0.360174</td>\n",
              "      <td>0.445972</td>\n",
              "      <td>0.566294</td>\n",
              "      <td>0.317613</td>\n",
              "      <td>0.512701</td>\n",
              "      <td>0.379284</td>\n",
              "      <td>0.479733</td>\n",
              "      <td>0.307859</td>\n",
              "      <td>...</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>60.489315</td>\n",
              "      <td>105.661801</td>\n",
              "      <td>-40.917997</td>\n",
              "      <td>91.127912</td>\n",
              "      <td>82.837666</td>\n",
              "      <td>93.438897</td>\n",
              "      <td>104.635814</td>\n",
              "      <td>14.399112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2546</th>\n",
              "      <td>0.337864</td>\n",
              "      <td>0.445126</td>\n",
              "      <td>0.358200</td>\n",
              "      <td>0.446341</td>\n",
              "      <td>0.569123</td>\n",
              "      <td>0.318504</td>\n",
              "      <td>0.510571</td>\n",
              "      <td>0.374125</td>\n",
              "      <td>0.480640</td>\n",
              "      <td>0.309391</td>\n",
              "      <td>...</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>65.094371</td>\n",
              "      <td>106.478589</td>\n",
              "      <td>-31.887617</td>\n",
              "      <td>92.397735</td>\n",
              "      <td>87.047832</td>\n",
              "      <td>90.745309</td>\n",
              "      <td>100.742641</td>\n",
              "      <td>21.186660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2547</th>\n",
              "      <td>0.334369</td>\n",
              "      <td>0.441393</td>\n",
              "      <td>0.358173</td>\n",
              "      <td>0.447999</td>\n",
              "      <td>0.570865</td>\n",
              "      <td>0.316519</td>\n",
              "      <td>0.510886</td>\n",
              "      <td>0.367897</td>\n",
              "      <td>0.494650</td>\n",
              "      <td>0.310895</td>\n",
              "      <td>...</td>\n",
              "      <td>23.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>78.226546</td>\n",
              "      <td>104.405066</td>\n",
              "      <td>-41.611827</td>\n",
              "      <td>90.403579</td>\n",
              "      <td>84.972179</td>\n",
              "      <td>91.582599</td>\n",
              "      <td>103.917125</td>\n",
              "      <td>25.539175</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2548 rows × 36 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d9a64b9d-49f6-4deb-98b3-ce28852e328e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d9a64b9d-49f6-4deb-98b3-ce28852e328e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d9a64b9d-49f6-4deb-98b3-ce28852e328e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-004da407-bc3f-4606-8018-940e8ca48398\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-004da407-bc3f-4606-8018-940e8ca48398')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-004da407-bc3f-4606-8018-940e8ca48398 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_d88b5e00-739b-4eac-a41e-2741fffb2108\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_all_coord_updated')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d88b5e00-739b-4eac-a41e-2741fffb2108 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_all_coord_updated');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}